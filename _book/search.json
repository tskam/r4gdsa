[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R for Geospatial Data Science and Analytics",
    "section": "",
    "text": "Preface\nWelcome to Geospatial Data Science and Analytics with R. This book aims to share with you the theory, the methods and the R tools specially designed to meet the challenges of analysing geographic problems and data."
  },
  {
    "objectID": "chap01.html#learning-outcome",
    "href": "chap01.html#learning-outcome",
    "title": "1  Geospatial Data Science with R",
    "section": "1.1 Learning Outcome",
    "text": "1.1 Learning Outcome\nGeospatial Data Science is a process of importing, wrangling, integrating, and processing geographically referenced data sets. In this hands-on exercise, you will learn how to perform geospatial data science tasks in R by using sf package.\nBy the end of this hands-on exercise, you should acquire the following competencies:\n\ninstalling and loading sf and tidyverse packages into R environment,\nimporting geospatial data by using appropriate functions of sf package,\nimporting aspatial data by using appropriate function of readr package,\nexploring the content of simple feature data frame by using appropriate Base R and sf functions,\nassigning or transforming coordinate systems by using using appropriate sf functions,\nconverting an aspatial data into a sf data frame by using appropriate function of sf package,\nperforming geoprocessing tasks by using appropriate functions of sf package,\nperforming data wrangling tasks by using appropriate functions of dplyr package and\nperforming Exploratory Data Analysis (EDA) by using appropriate functions from ggplot2 package.\n\n\nNote: Students are encouraged to read the reference guide of each function, especially the input data requirements, syntaxt and argument option before using them."
  },
  {
    "objectID": "chap01.html#data-acquisition",
    "href": "chap01.html#data-acquisition",
    "title": "1  Geospatial Data Science with R",
    "section": "1.2 Data Acquisition",
    "text": "1.2 Data Acquisition\nData are key to data analytics including geospatial analytics. Hence, before analysing, we need to assemble the necessary data. In this hands-on exercise, you are required to extract the necessary data sets from the following sources:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb\n\n\nNote: The purpose of this section is not merely extracting the necessary data sets. It also aims to introduce you to public available data sets. Students are encouraged to explore the rest of the available data sets in these three data sources.\n\n\n1.2.1 Extracting the geospatial data sets\nNext, at the Hands-on_Ex01 folder, create a sub-folder called data. Then, inside the data sub-folder, create two sub-folders and name them geospatial and aspatial respectively.\nPlace Master Plan 2014 Subzone Boundary (Web), Pre-Schools Location and Cycling Path zipped files into geospatial sub-folder and unzipped them. Copy the unzipped files from their respective sub-folders and place them inside geospatial sub-folder.\n\n\n1.2.2 Extracting the aspatial data set\nNow, you will extract the downloaded listing data file. At Downloads folder, cut and paste listing.csv into aspatial sub-folder."
  },
  {
    "objectID": "chap01.html#getting-started",
    "href": "chap01.html#getting-started",
    "title": "1  Geospatial Data Science with R",
    "section": "1.3 Getting Started",
    "text": "1.3 Getting Started\nIn this hands-on exercise, two R packages will be used. They are:\n\nsf for importing, managing, and processing geospatial data, and\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nTidyverse consists of a family of R packages. In this hands-on exercise, the following packages will be used:\n\nreadr for importing csv data,\nreadxl for importing Excel worksheet,\ntidyr for manipulating data,\ndplyr for transforming data, and\nggplot2 for visualising data\n\nType the following code chunk.\n\npacman::p_load(sf, tidyverse)\n\nWhat we can learn from the code chunk above:\n\np_load function pf pacman package is used to install and load sf and tidyverse pacages into R environment."
  },
  {
    "objectID": "chap01.html#importing-geospatial-data",
    "href": "chap01.html#importing-geospatial-data",
    "title": "1  Geospatial Data Science with R",
    "section": "1.4 Importing Geospatial Data",
    "text": "1.4 Importing Geospatial Data\nIn this section, you will learn how to import the following geospatial data into R by using st_read() of sf package:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n1.4.1 Importing polygon feature data in shapefile format\nThe code chunk below uses st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a polygon feature data frame. Note that when the input geospatial data is in shapefile format, two arguments will be used, namely: dsn to define the data path and layer to provide the shapefile name. Also note that no extension such as .shp, .dbf, .prj and .shx are needed.\n\nmpsz = st_read(dsn = \"chap01/data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\tskam\\r4gdsa\\chap01\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe message above reveals that the geospatial objects are multipolygon features. There are a total of 323 multipolygon features and 15 fields in mpsz simple feature data frame. mpsz is in svy21 projected coordinates systems. The bounding box provides the x extend and y extend of the data.\n\n\n1.4.2 Importing polyline feature data in shapefile form\nThe code chunk below uses st_read() function of sf package to import CyclingPath shapefile into R as line feature data frame.\n\ncyclingpath = st_read(dsn = \"chap01/data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `D:\\tskam\\r4gdsa\\chap01\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThe message above reveals that there are a total of 2558 features and 2 fields in cyclingpath linestring feature data frame and it is in svy21 projected coordinates system too.\n\n\n1.4.3 Importing GIS data in kml format\nThe PreSchoolsLocation is in kml format. The code chunk below will be used to import the kml into R. Notice that in the code chunk below, the complete path and the kml file extension were provided.\n\npreschool = st_read(\"chap01/data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `D:\\tskam\\r4gdsa\\chap01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe message above reveals that preschool is a point feature data frame. There are a total of 2290 features and 2 fields. Different from the previous two simple feature data frame, preschool is in wgs84 coordinates system."
  },
  {
    "objectID": "chap01.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "chap01.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "1  Geospatial Data Science with R",
    "section": "1.5 Checking the Content of A Simple Feature Data Frame",
    "text": "1.5 Checking the Content of A Simple Feature Data Frame\nIn this sub-section, you will learn different ways to retrieve information related to the content of a simple feature data frame.\n\n1.5.1 Working with st_geometry()\nThe column in the sf data.frame that contains the geometries is a list, of class sfc. We can retrieve the geometry list-column in this case by mpsz$geom or mpsz[[1]], but the more general way uses st_geometry() as shown in the code chunk below.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nNotice that the print only displays basic information of the feature class such as type of geometry, the geographic extent of the features and the coordinate system of the data.\n\n\n1.5.2 Working with glimpse()\nBeside the basic feature information, we also would like to learn more about the associated attribute information in the data frame. This is the time you will find glimpse() of dplyr. very handy as shown in the code chunk below.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nglimpse() report reveals the data type of each fields. For example FMEL-UPD_D field is in date data type and X_ADDR, Y_ADDR, SHAPE_L and SHAPE_AREA fields are all in double-precision values.\n\n\n1.5.3 Working with head()\nSometimes we would like to reveal complete information of a feature object, this is the job of head() of Base R\n\nhead(mpsz, n=5)  \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\nNote: One of the useful argument of head() is it allows user to select the numbers of record to display (i.e. the n argument)."
  },
  {
    "objectID": "chap01.html#plotting-the-geospatial-data",
    "href": "chap01.html#plotting-the-geospatial-data",
    "title": "1  Geospatial Data Science with R",
    "section": "1.6 Plotting the Geospatial Data",
    "text": "1.6 Plotting the Geospatial Data\nIn geospatial data science, by looking at the feature information is not enough. We are also interested to visualise the geospatial features. This is the time you will find plot() of R Graphic comes in very handy as shown in the code chunk below.\n\nplot(mpsz)\n\n\n\n\nThe default plot of an sf object is a multi-plot of all attributes, up to a reasonable maximum as shown above. We can, however, choose to plot only the geometry by using the code chunk below.\n\nplot(st_geometry(mpsz))\n\n\n\n\nAlternatively, we can also choose the plot the sf object by using a specific attribute as shown in the code chunk below.\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\nNote: plot() is mean for plotting the geospatial object for quick look. For high cartographic quality plot, other R package such as tmap should be used."
  },
  {
    "objectID": "chap01.html#working-with-projection",
    "href": "chap01.html#working-with-projection",
    "title": "1  Geospatial Data Science with R",
    "section": "1.7 Working with Projection",
    "text": "1.7 Working with Projection\nMap projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system.\nIn this section, you will learn how to project a simple feature data frame from one coordinate system to another coordinate system. The technical term of this process is called projection transformation.\n\n1.7.1 Assigning EPSG code to a simple feature data frame\nOne of the common issue that can happen during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package as shown in the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in svy21 but when we read until the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414.\nIn order to assign the correct EPSG code to mpsz data frame, st_set_crs() of sf package is used as shown in the code chunk below.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nNow, let us check the CSR again by using the code chunk below.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG code is 3414 now.\n\n\n1.7.2 Transforming the projection of preschool from wgs84 to svy21.\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nLet us take preschool simple feature data frame as an example. The print below reveals that it is in wgs84 coordinate system.\n\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nThis is a scenario that st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathemetically.\nLet us perform the projection transformation by using the code chunk below.\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\n\n\nNote: In practice, we need find out the appropriate project coordinate system to use before performing the projection transformation.\n\nNext, let us display the content of preschool3414 sf data frame as shown below.\n\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nNotice that it is in svy21 projected coordinate system now. Furthermore, if you refer to Bounding box:, the values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems."
  },
  {
    "objectID": "chap01.html#importing-and-converting-an-aspatial-data",
    "href": "chap01.html#importing-and-converting-an-aspatial-data",
    "title": "1  Geospatial Data Science with R",
    "section": "1.8 Importing and Converting An Aspatial Data",
    "text": "1.8 Importing and Converting An Aspatial Data\nIn practice, it is not unusual that we will come across data such as listing of Inside Airbnb. We call this kind of data aspatial data. This is because it is not a geospatial data but among the data fields, there are two fields that capture the x- and y-coordinates of the data points.\nIn this section, you will learn how to import an aspatial data into R environment and save it as a tibble data frame. Next, you will convert it into a simple feature data frame.\nFor the purpose of this exercise, the listings.csv data downloaded from AirBnb will be used.\n\n1.8.1 Importing the aspatial data\nSince listings data set is in csv file format, we will use read_csv() of readr package to import listing.csv as shown the code chunk below. The output R object is called listings and it is a tibble data frame.\n\nlistings &lt;- read_csv(\"chap01/data/aspatial/listings.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() of Base R instead of glimpse() is used to do the job.\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,483 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,473 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nThe output reveals that listing tibble data frame consists of 4252 rows and 16 columns. Two useful fields we are going to use in the next phase are latitude and longitude. Note that they are in decimal degree format. As a best guess, we will assume that the data is in wgs84 Geographic Coordinate System.\n\n\n1.8.2 Creating a simple feature data frame from an aspatial data frame\nThe code chunk below converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nThings to learn from the arguments above:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io.\n%&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\nLet us examine the content of this newly created simple feature data frame.\n\nglimpse(listings_sf)\n\nRows: 3,483\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 150, 80, 80, 55, 69, 220, 85, 75, 45, 7…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              &lt;dbl&gt; 20, 24, 47, 22, 17, 12, 133, 18, 6, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.14, 0.16, 0.31, 0.17, 0.12, 0.09, 0.9…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 52, 52, 5, 7, 52, 52, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 89, 89, 89, 275, 274, 89, 365, 365, 365…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 3, 0, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nTable above shows the content of listing_sf. Notice that a new column called geometry has been added into the data frame. On the other hand, the longitude and latitude columns have been dropped from the data frame."
  },
  {
    "objectID": "chap01.html#geoprocessing-with-sf-package",
    "href": "chap01.html#geoprocessing-with-sf-package",
    "title": "1  Geospatial Data Science with R",
    "section": "1.9 Geoprocessing with sf package",
    "text": "1.9 Geoprocessing with sf package\nBesides providing functions to handling (i.e. importing, exporting, assigning projection, transforming projection etc) geospatial data, sf package also offers a wide range of geoprocessing (also known as GIS analysis) functions.\nIn this section, you will learn how to perform two commonly used geoprocessing functions, namely buffering and point in polygon count.\n\n1.9.1 Buffering\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nThis is followed by calculating the area of the buffers as shown in the code chunk below.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]\n\n\nMission Accomplished!\n\n\n1.9.2 Point-in-polygon count\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nWarning: You should not confuse with st_intersection().\n\nYou can check the summary statistics of the newly derived PreSch Count field by using summary() as shown in the code chunk below.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-school, the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\n\nDIY: Calculate the density of pre-school by planning subzone.\n\nThe solution:\nFirstly, the code chunk below uses st_area() of sf package to derive the area of each planning subzone.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below.\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "chap01.html#exploratory-data-analysis-eda",
    "href": "chap01.html#exploratory-data-analysis-eda",
    "title": "1  Geospatial Data Science with R",
    "section": "1.10 Exploratory Data Analysis (EDA)",
    "text": "1.10 Exploratory Data Analysis (EDA)\nIn practice, many geospatial analytics start with Exploratory Data Analysis. In this section, you will learn how to use appropriate ggplot2 functions to create functional and yet truthful statistical graphs for EDA purposes.\nFirstly, we will plot a histogram to reveal the distribution of PreSch Density. Conventionally, hist() of R Graphics will be used as shown in the code chunk below.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\nAlthough the syntax is very easy to use however the output is far from meeting publication quality. Furthermore, the function has limited room for further customisation.\nIn the code chunk below, appropriate ggplot2 functions will be used.\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\nDIY: Using ggplot2 method, plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\nThe solution:\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")"
  },
  {
    "objectID": "chap02.html#overview",
    "href": "chap02.html#overview",
    "title": "2  Thematic Mapping and GeoVisualisation with R",
    "section": "2.1 Overview",
    "text": "2.1 Overview\nIn general, thematic mapping involves the use of map symbols to visualize selected properties of geographic features that are not naturally visible, such as population, temperature, crime rate, and property prices, just to mention a few of them.\nGeovisualisation, on the other hand, works by providing graphical ideation to render a place, a phenomenon or a process visible, enabling human’s most powerful information-processing abilities – those of spatial cognition associated with our eye–brain vision system – to be directly brought to bear.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called **tmap** package.\n\n2.1.1 Survival Tip\nIt is advisable for you to read the functional description of each function before using them."
  },
  {
    "objectID": "chap02.html#getting-started",
    "href": "chap02.html#getting-started",
    "title": "2  Thematic Mapping and GeoVisualisation with R",
    "section": "2.2 Getting Started",
    "text": "2.2 Getting Started\nIn this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\nNotice that, we only need to install tidyverse instead of readr, tidyr and dplyr individually."
  },
  {
    "objectID": "chap02.html#importing-data-into-r",
    "href": "chap02.html#importing-data-into-r",
    "title": "2  Thematic Mapping and GeoVisualisation with R",
    "section": "2.3 Importing Data into R",
    "text": "2.3 Importing Data into R\n\n2.3.1 The Data\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n2.3.2 Importing Geospatial Data into R\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"chap02/data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\tskam\\r4gdsa\\chap02\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNotice that only the first ten records will be displayed. Do you know why?\n\n\n2.3.3 Importing Attribute Data into R\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popdata.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"chap02/data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n2.3.4 Data Preparation\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n2.3.4.1 Data wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n2.3.4.2 Joining the attribute data and geospatial data\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nwrite_rds(mpsz_pop2020, \"chap02/data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "chap02.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "chap02.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "2  Thematic Mapping and GeoVisualisation with R",
    "section": "2.4 Choropleth Mapping Geospatial Data Using tmap",
    "text": "2.4 Choropleth Mapping Geospatial Data Using tmap\nChoropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n2.4.1 Plotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n2.4.2 Creating a choropleth map by using tmap’s elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n2.4.2.1 Drawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n2.4.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n2.4.2.3 Drawing a choropleth map using tm_fill() and *tm_border()**\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n2.4.3 Data classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n2.4.3.1 Plotting choropleth maps with built-in classification methods\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\nWarning: Maps Lie!\n\n\nDIY: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\n\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\n\n\n\n2.4.3.2 Plotting choropleth map with custome break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n2.4.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n2.4.4.1 Using ColourBrewer palette\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n2.4.5 Map Layouts\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n2.4.5.1 Map Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n2.4.5.2 Map style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n2.4.5.3 Cartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\n\n\n\n2.4.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n2.4.6.1 By assigning multiple values to at least one of the aesthetic arguments\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n2.4.6.2 By defining a group-by variable in tm_facets()\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n2.4.6.3 By creating multiple stand-alone maps with tmap_arrange()\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n2.4.7 Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "chap02.html#reference",
    "href": "chap02.html#reference",
    "title": "2  Thematic Mapping and GeoVisualisation with R",
    "section": "2.5 Reference",
    "text": "2.5 Reference\n\n2.5.1 All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n2.5.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n2.5.3 Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "chap04.html#overview",
    "href": "chap04.html#overview",
    "title": "4  1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.1 Overview",
    "text": "4.1 Overview\nSpatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. The point can be location of:\n\nevents such as crime, traffic accident and disease onset, or\nbusiness services (coffee and fastfood outlets) or facilities such as childcare and eldercare.\n\nUsing appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childecare centres in Singapore.\nThe specific questions we would like to answer are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\n\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "chap04.html#the-data",
    "href": "chap04.html#the-data",
    "title": "4  1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.2 The data",
    "text": "4.2 The data\nTo provide answers to the questions above, three data sets will be used. They are:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from Data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format."
  },
  {
    "objectID": "chap04.html#installing-and-loading-the-r-packages",
    "href": "chap04.html#installing-and-loading-the-r-packages",
    "title": "4  1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.3 Installing and Loading the R packages",
    "text": "4.3 Installing and Loading the R packages\nIn this hands-on exercise, five R packages will be used, they are:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\nmaptools which provides a set of tools for manipulating geographic data. In this hands-on exercise, we mainly use it to convert Spatial objects into ppp format of spatstat.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\nUse the code chunk below to install and launch the five R packages.\n\npacman::p_load(maptools, sf, raster, spatstat, tmap)"
  },
  {
    "objectID": "chap04.html#spatial-data-wrangling",
    "href": "chap04.html#spatial-data-wrangling",
    "title": "4  1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.4 Spatial Data Wrangling",
    "text": "4.4 Spatial Data Wrangling\n\n4.4.1 Importing the spatial data\nIn this section, st_read() of sf package will be used to import these three geospatial data sets into R.\n\nchildcare_sf &lt;- st_read(\"chap04/data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `D:\\tskam\\r4gdsa\\chap04\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nsg_sf &lt;- st_read(dsn = \"chap04/data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source `D:\\tskam\\r4gdsa\\chap04\\data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\nmpsz_sf &lt;- st_read(dsn = \"chap04/data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source `D:\\tskam\\r4gdsa\\chap04\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nBefore we can use these data for analysis, it is important for us to ensure that they are projected in same projection system.\n\nDIY: Using the appropriate sf function you learned in Hands-on Exercise 2, retrieve the referencing system information of these geospatial data.\n\nNotice that except childcare_sf, both mpsz_sf and sg_sf do not have proper crs information.\n\nDIY: Using the method you learned in Lesson 2, assign the correct crs to mpsz_sf and sg_sf simple feature data frames.\n\n\nDIY: If necessary, changing the referencing system to Singapore national projected coordinate system.\n\n\n\n4.4.2 Mapping the geospatial data sets\nAfter checking the referencing system of each geospatial data data frame, it is also useful for us to plot a map to show their spatial patterns.\n\nDIY: Using the mapping methods you learned in Hands-on Exercise 3, prepare a map as shown below.\n\n\n\n\n\n\nNotice that all the geospatial layers are within the same map extend. This shows that their referencing system and coordinate values are referred to similar spatial context. This is very important in any geospatial analysis.\nAlternatively, we can also prepare a pin map by using the code chunk below.\n\ntmap_mode('view')\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\ntmap_mode('plot')\n\nNotice that at the interactive mode, tmap is using leaflet for R API. The advantage of this interactive pin map is it allows us to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, you can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\n\nReminder: Always remember to switch back to plot mode after the interactive map. This is because, each interactive mode will consume a connection. You should also avoid displaying ecessive numbers of interactive maps (i.e. not more than 10) in one RMarkdown document when publish on Netlify."
  },
  {
    "objectID": "chap04.html#geospatial-data-wrangling",
    "href": "chap04.html#geospatial-data-wrangling",
    "title": "4  1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.5 Geospatial Data wrangling",
    "text": "4.5 Geospatial Data wrangling\nAlthough simple feature data frame is gaining popularity again sp’s Spatial* classes, there are, however, many geospatial analysis packages require the input geospatial data in sp’s Spatial* classes. In this section, you will learn how to convert simple feature data frame to sp’s Spatial* class.\n\n4.5.1 Converting sf data frames to sp’s Spatial* class\nThe code chunk below uses as_Spatial() of sf package to convert the three geospatial data from simple feature data frame to sp’s Spatial* class.\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\n\nDIY: Using appropriate function, display the information of these three Spatial* classes as shown below.\n\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\nNotice that the geospatial data have been converted into their respective sp’s Spatial* classes now.\n\n\n4.5.2 Converting the Spatial* class into generic sp format\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. We need to convert the Spatial classes* into Spatial object first.\nThe codes chunk below converts the Spatial* classes into generic sp objects.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nNext, you should display the sp objects properties as shown below.\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \n\n\n\nChallenge: Do you know what are the differences between Spatial* classes and generic sp object?\n\n\n\n4.5.3 Converting the generic sp format into spatstat’s ppp format\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, let us plot childcare_ppp and examine the different.\n\nplot(childcare_ppp)\n\n\n\n\nYou can take a quick look at the summary statistics of the newly created ppp object by using the code chunk below.\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nNotice the warning message about duplicates. In spatial point patterns analysis an issue of significant is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident.\n\n\n4.5.4 Handling duplicated points\nWe can check the duplication in a ppp object by using the code chunk below.\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nTo count the number of co-indicence point, we will use the multiplicity() function as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\nIf we want to know how many locations have more than one point event, we can use the code chunk below.\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 128\n\n\nThe output shows that there are 128 duplicated point events.\nTo view the locations of these duplicate point events, we will plot childcare data by using the code chunk below.\n\ntmap_mode('view')\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\ntmap_mode('plot')\n\n\nChallenge: Do you know how to spot the duplicate points from the map shown above?\n\nThere are three ways to overcome this problem. The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\nThe code chunk below implements the jittering approach.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nDIY: Using the method you learned in previous section, check if any dusplicated point in this geospatial data.\n\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\n4.5.5 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin &lt;- as(sg_sp, \"owin\")\n\nThe ouput object can be displayed by using plot() function\n\nplot(sg_owin)\n\n\n\n\nand summary() function of Base R.\n\nsummary(sg_owin)\n\n\n\n4.5.6 Combining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nsummary(childcareSG_ppp)\n\n\nDIY: Using the method you learned in previous exercise, plot the newly derived childcareSG_ppp as shown below."
  },
  {
    "objectID": "chap04.html#first-order-spatial-point-patterns-analysis",
    "href": "chap04.html#first-order-spatial-point-patterns-analysis",
    "title": "4  1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.6 First-order Spatial Point Patterns Analysis",
    "text": "4.6 First-order Spatial Point Patterns Analysis\nIn this section, you will learn how to perform first-order SPPA by using spatstat package. The hands-on exercise will focus on:\n\nderiving kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes,\nperforming Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics.\n\n\n4.6.1 Kernel Density Estimation\nIn this section, you will learn how to compute the kernel density estimation (KDE) of childcare services in Singapore.\n\n4.6.1.1 Computing kernel density estimation using automatic bandwidth selection method\nThe code chunk below computes a kernel density by using the following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\n\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\n\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nThe plot() function of Base R is then used to display the kernel density derived.\n\nplot(kde_childcareSG_bw)\n\n\n\n\nThe density values of the output range from 0 to 0.000035 which is way too small to comprehend. This is because the default unit of measurement of svy21 is in meter. As a result, the density values computed is in “number of points per square meter”.\nBefore we move on to next section, it is good to know that you can retrieve the bandwidth used to compute the kde layer by using the code chunk below.\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\n4.6.1.2 Rescalling KDE values\nIn the code chunk below, rescale() is used to covert the unit of measurement from meter to kilometer.\n\nchildcareSG_ppp.km &lt;- rescale(childcareSG_ppp, 1000, \"km\")\n\nNow, we can re-run density() using the resale data set and plot the output kde map.\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\nNotice that output image looks identical to the earlier version, the only changes in the data values (refer to the legend).\n\n\n\n4.6.2 Working with different automatic badwidth methods\nBeside bw.diggle(), there are three other spatstat functions can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\nLet us take a look at the bandwidth return by these automatic bandwidth calculation methods by using the code chunk below.\n\n bw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because in ther experience it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of once study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\nThe code chunk beow will be used to compare the output of using bw.diggle and bw.ppl methods.\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n4.6.3 Working with different kernel methods\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics.\nThe code chunk below will be used to compute three more kernel density estimations by using these three kernel function.\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")"
  },
  {
    "objectID": "chap04.html#fixed-and-adaptive-kde",
    "href": "chap04.html#fixed-and-adaptive-kde",
    "title": "4  1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.7 Fixed and Adaptive KDE",
    "text": "4.7 Fixed and Adaptive KDE\n\n4.7.1 Computing KDE by using fixed bandwidth\nNext, you will compute a KDE layer by defining a bandwidth of 600 meter. Notice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n4.7.2 Computing KDE by using adaptive bandwidth\nFixed bandwidth method is very sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\nIn this section, you will learn how to derive adaptive kernel density estimation by using density.adaptive() of spatstat.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n4.7.3 Converting KDE output into grid object.\nThe result is the same, we just convert it so that it is suitable for mapping purposes\n\ngridded_kde_childcareSG_bw &lt;- as.SpatialGridDataFrame.im(kde_childcareSG.bw)\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n4.7.3.1 Converting gridded output into raster\nNext, we will convert the gridded kernal density objects into RasterLayer object by using raster() of raster package.\n\nkde_childcareSG_bw_raster &lt;- raster(gridded_kde_childcareSG_bw)\n\nLet us take a look at the properties of kde_childcareSG_bw_raster RasterLayer.\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nNotice that the crs property is NA.\n\n\n4.7.3.2 Assigning projection systems\nThe code chunk below will be used to include the CRS information on kde_childcareSG_bw_raster RasterLayer.\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nNotice that the crs property is completed.\n\n\n\n4.7.4 Visualising the output in tmap\nFinally, we will display the raster in cartographic quality map using tmap package.\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\nNotice that the raster values are encoded explicitly onto the raster pixel using the values in “v”” field.\n\n\n4.7.5 Comparing Spatial Point Patterns using KDE\nIn this section, you will learn how to compare KDE of childcare at Ponggol, Tampines, Chua Chu Kang and Jurong West planning areas.\n\n4.7.5.1 Extracting study area\nThe code chunk below will be used to extract the target planning areas.\n\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\nPlotting target planning areas\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\nplot(tm, main = \"Tampines\")\nplot(ck, main = \"Choa Chu Kang\")\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n4.7.5.2 Converting the spatial point data frame into generic sp format\nNext, we will convert these SpatialPolygonsDataFrame layers into generic spatialpolygons layers.\n\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")\n\n\n\n4.7.5.3 Creating owin object\nNow, we will convert these SpatialPolygons objects into owin objects that is required by spatstat.\n\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")\n\n\n\n4.7.5.4 Combining childcare points and the study area\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n4.7.5.5 Computing KDE\nThe code chunk below will be used to compute the KDE of these four planning area. bw.diggle method is used to derive the bandwidth of each\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\n\n\n\n\n\n\n4.7.5.6 Computing fixed bandwidth KDE\nFor comparison purposes, we will use 250m as the bandwidth.\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")"
  },
  {
    "objectID": "chap04.html#nearest-neighbour-analysis",
    "href": "chap04.html#nearest-neighbour-analysis",
    "title": "4  1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.8 Nearest Neighbour Analysis",
    "text": "4.8 Nearest Neighbour Analysis\nIn this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat.\nThe test hypotheses are:\nHo = The distribution of childcare services are randomly distributed.\nH1= The distribution of childcare services are not randomly distributed.\nThe 95% confident interval will be used.\n\n4.8.1 Testing spatial point patterns using Clark and Evans Test\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.54756, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nWhat conclusion can you draw from the test result?\n\n\n4.8.2 Clark and Evans Test: Choa Chu Kang planning area\nIn the code chunk below, clarkevans.test() of spatstat is used to performs Clark-Evans test of aggregation for childcare centre in Choa Chu Kang planning area.\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.923, p-value = 0.2499\nalternative hypothesis: two-sided\n\n\n\n\n4.8.3 Clark and Evans Test: Tampines planning area\nIn the code chunk below, the similar test is used to analyse the spatial point patterns of childcare centre in Tampines planning area.\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.784, p-value = 9.686e-05\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "chap05.html#overview",
    "href": "chap05.html#overview",
    "title": "5  2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.1 Overview",
    "text": "5.1 Overview\nSpatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. The point can be location of:\n\nevents such as crime, traffic accident and disease onset, or\nbusiness services (coffee and fastfood outlets) or facilities such as childcare and eldercare.\n\nUsing appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childecare centres in Singapore.\nThe specific questions we would like to answer are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\n\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "chap05.html#the-data",
    "href": "chap05.html#the-data",
    "title": "5  2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.2 The data",
    "text": "5.2 The data\nTo provide answers to the questions above, three data sets will be used. They are:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from Data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format."
  },
  {
    "objectID": "chap05.html#installing-and-loading-the-r-packages",
    "href": "chap05.html#installing-and-loading-the-r-packages",
    "title": "5  2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.3 Installing and Loading the R packages",
    "text": "5.3 Installing and Loading the R packages\nIn this hands-on exercise, five R packages will be used, they are:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\nmaptools which provides a set of tools for manipulating geographic data. In this hands-on exercise, we mainly use it to convert Spatial objects into ppp format of spatstat.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\nUse the code chunk below to install and launch the five R packages.\n\npacman::p_load(maptools, sf, raster, spatstat, tmap)"
  },
  {
    "objectID": "chap05.html#spatial-data-wrangling",
    "href": "chap05.html#spatial-data-wrangling",
    "title": "5  2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.4 Spatial Data Wrangling",
    "text": "5.4 Spatial Data Wrangling\n\n5.4.1 Importing the spatial data\nIn this section, st_read() of sf package will be used to import these three geospatial data sets into R.\n\nchildcare_sf &lt;- st_read(\"chap05/data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `D:\\tskam\\r4gdsa\\chap05\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nsg_sf &lt;- st_read(dsn = \"chap05/data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source `D:\\tskam\\r4gdsa\\chap05\\data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\nmpsz_sf &lt;- st_read(dsn = \"chap05/data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source `D:\\tskam\\r4gdsa\\chap05\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nBefore we can use these data for analysis, it is important for us to ensure that they are projected in same projection system.\n\nDIY: Using the appropriate sf function you learned in Hands-on Exercise 2, retrieve the referencing system information of these geospatial data.\n\nNotice that except childcare_sf, both mpsz_sf and sg_sf do not have proper crs information.\n\nDIY: Using the method you learned in Lesson 2, assign the correct crs to mpsz_sf and sg_sf simple feature data frames.\n\n\nDIY: If necessary, changing the referencing system to Singapore national projected coordinate system.\n\n\n\n5.4.2 Mapping the geospatial data sets\nAfter checking the referencing system of each geospatial data data frame, it is also useful for us to plot a map to show their spatial patterns.\n\nDIY: Using the mapping methods you learned in Hands-on Exercise 3, prepare a map as shown below.\n\n\n\n\n\n\nNotice that all the geospatial layers are within the same map extend. This shows that their referencing system and coordinate values are referred to similar spatial context. This is very important in any geospatial analysis.\nAlternatively, we can also prepare a pin map by using the code chunk below.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nNotice that at the interactive mode, tmap is using leaflet for R API. The advantage of this interactive pin map is it allows us to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, you can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\n\nReminder: Always remember to switch back to plot mode after the interactive map. This is because, each interactive mode will consume a connection. You should also avoid displaying ecessive numbers of interactive maps (i.e. not more than 10) in one RMarkdown document when publish on Netlify."
  },
  {
    "objectID": "chap05.html#geospatial-data-wrangling",
    "href": "chap05.html#geospatial-data-wrangling",
    "title": "5  2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.5 Geospatial Data wrangling",
    "text": "5.5 Geospatial Data wrangling\nAlthough simple feature data frame is gaining popularity again sp’s Spatial* classes, there are, however, many geospatial analysis packages require the input geospatial data in sp’s Spatial* classes. In this section, you will learn how to convert simple feature data frame to sp’s Spatial* class.\n\n5.5.1 Converting sf data frames to sp’s Spatial* class\nThe code chunk below uses as_Spatial() of sf package to convert the three geospatial data from simple feature data frame to sp’s Spatial* class.\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\n\nDIY: Using appropriate function, display the information of these three Spatial* classes as shown below.\n\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\nNotice that the geospatial data have been converted into their respective sp’s Spatial* classes now.\n\n\n5.5.2 Converting the Spatial* class into generic sp format\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. We need to convert the Spatial classes* into Spatial object first.\nThe codes chunk below converts the Spatial* classes into generic sp objects.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nNext, you should display the sp objects properties as shown below.\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \n\n\n\nChallenge: Do you know what are the differences between Spatial* classes and generic sp object?\n\n\n\n5.5.3 Converting the generic sp format into spatstat’s ppp format\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, let us plot childcare_ppp and examine the different.\n\nplot(childcare_ppp)\n\n\n\n\nYou can take a quick look at the summary statistics of the newly created ppp object by using the code chunk below.\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nNotice the warning message about duplicates. In spatial point patterns analysis an issue of significant is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident.\n\n\n5.5.4 Handling duplicated points\nWe can check the duplication in a ppp object by using the code chunk below.\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nTo count the number of co-indicence point, we will use the multiplicity() function as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\nIf we want to know how many locations have more than one point event, we can use the code chunk below.\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 128\n\n\nThe output shows that there are 128 duplicated point events.\nTo view the locations of these duplicate point events, we will plot childcare data by using the code chunk below.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n\nChallenge: Do you know how to spot the duplicate points from the map shown above?\n\nThere are three ways to overcome this problem. The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\nThe code chunk below implements the jittering approach.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nDIY: Using the method you learned in previous section, check if any dusplicated point in this geospatial data.\n\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\n5.5.5 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin &lt;- as(sg_sp, \"owin\")\n\nThe ouput object can be displayed by using plot() function\n\nplot(sg_owin)\n\n\n\n\nand summary() function of Base R.\n\nsummary(sg_owin)\n\n\n\n5.5.6 Combining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nsummary(childcareSG_ppp)\n\n\nDIY: Using the method you learned in previous exercise, plot the newly derived childcareSG_ppp as shown below.\n\n\n\n\n\n\n\n5.5.6.1 Extracting study area\nThe code chunk below will be used to extract the target planning areas.\n\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\nPlotting target planning areas\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\nplot(tm, main = \"Tampines\")\nplot(ck, main = \"Choa Chu Kang\")\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n5.5.6.2 Converting the spatial point data frame into generic sp format\nNext, we will convert these SpatialPolygonsDataFrame layers into generic spatialpolygons layers.\n\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")\n\n\n\n5.5.6.3 Creating owin object\nNow, we will convert these SpatialPolygons objects into owin objects that is required by spatstat.\n\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")\n\n\n\n5.5.6.4 Combining childcare points and the study area\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")"
  },
  {
    "objectID": "chap05.html#second-order-spatial-point-patterns-analysis",
    "href": "chap05.html#second-order-spatial-point-patterns-analysis",
    "title": "5  2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.6 Second-order Spatial Point Patterns Analysis",
    "text": "5.6 Second-order Spatial Point Patterns Analysis"
  },
  {
    "objectID": "chap05.html#analysing-spatial-point-process-using-g-function",
    "href": "chap05.html#analysing-spatial-point-process-using-g-function",
    "title": "5  2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.7 Analysing Spatial Point Process Using G-Function",
    "text": "5.7 Analysing Spatial Point Process Using G-Function\nThe G function measures the distribution of the distances from an arbitrary event to its nearest event. In this section, you will learn how to compute G-function estimation by using Gest() of spatstat package. You will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\n\n5.7.1 Choa Chu Kang planning area\n\n5.7.1.1 Computing G-function estimation\nThe code chunk below is used to compute G-function using Gest() of spatat package.\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n5.7.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-fucntion\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n5.7.2 Tampines planning area\n\n5.7.2.1 Computing G-function estimation\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n5.7.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_tm.csr)"
  },
  {
    "objectID": "chap05.html#analysing-spatial-point-process-using-f-function",
    "href": "chap05.html#analysing-spatial-point-process-using-f-function",
    "title": "5  2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.8 Analysing Spatial Point Process Using F-Function",
    "text": "5.8 Analysing Spatial Point Process Using F-Function\nThe F function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape. In this section, you will learn how to compute F-function estimation by using Fest() of spatstat package. You will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\n\n5.8.1 Choa Chu Kang planning area\n\n5.8.1.1 Computing F-function estimation\nThe code chunk below is used to compute F-function using Fest() of spatat package.\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n\n5.8.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-fucntion\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(F_CK.csr)\n\n\n\n\n\n\n5.8.3 Tampines planning area\n\n5.8.3.1 Computing F-function estimation\nMonte Carlo test with F-fucntion\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n5.8.3.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(F_tm.csr)"
  },
  {
    "objectID": "chap05.html#analysing-spatial-point-process-using-k-function",
    "href": "chap05.html#analysing-spatial-point-process-using-k-function",
    "title": "5  2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.9 Analysing Spatial Point Process Using K-Function",
    "text": "5.9 Analysing Spatial Point Process Using K-Function\nK-function measures the number of events found up to a given distance of any particular event. In this section, you will learn how to compute K-function estimates by using Kest() of spatstat package. You will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\n\n5.9.1 Choa Chu Kang planning area\n\n5.9.1.1 Computing K-fucntion estimate\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n5.9.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n5.9.2 Tampines planning area\n\n5.9.2.1 Computing K-fucntion estimation\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n5.9.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "chap05.html#analysing-spatial-point-process-using-l-function",
    "href": "chap05.html#analysing-spatial-point-process-using-l-function",
    "title": "5  2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.10 Analysing Spatial Point Process Using L-Function",
    "text": "5.10 Analysing Spatial Point Process Using L-Function\nIn this section, you will learn how to compute L-function estimation by using Lest() of spatstat package. You will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\n\n5.10.1 Choa Chu Kang planning area\n\n5.10.1.1 Computing L Fucntion estimation\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n5.10.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n5.10.2 Tampines planning area\n\n5.10.2.1 Computing L-fucntion estimate\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n5.10.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below will be used to perform the hypothesis testing.\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\nThen, plot the model output by using the code chun below.\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "chap06.html#overview",
    "href": "chap06.html#overview",
    "title": "6  Analysing Marked Point Patterns",
    "section": "6.1 Overview",
    "text": "6.1 Overview\nAs discussed in class, a point pattern dataset contains a complete enumeration of events (i.e., objects of interest) occurring in a defined study region. These events could represent anything with a measurable location including traffic accidents, crime occurrences, social service location, business establishment locations, etc. In addition to locational information, each event could have an associated continuous (e.g., number of students, volume of sales) or categorical measurement (e.g., type of schools, operators of the fast food chains). The measurements are called marks and the events with marks are called a marked point pattern.\nMarked point patterns have first-order properties, which are related to the intensity (i.e., density) of events and associated marks across the study region, and second-order properties, which are related to the spatial dependence (i.e., spatial arrangement) of the events and associated marks across the study area.\n\n6.1.1 The research questions\nThe specific question we would like to answer is:\n\nare the locations of childcare centre by different business groups (i.e. NT, PT, RC, ST) spatial independent?\nIf the answer is NO, are there any phenomena of attraction or repulsion?\n\n\n\n6.1.2 The data\nTo provide answer to the questions above, two data sets will be used. They are:\n\nChildcare centre: The original data is in KML format. It has been converted into ESRI shapefile format.\nURA Master Plan Subzone 2014: It is in ESRI shapefile format.\n\nBoth data sets were downloaded from Data.gov."
  },
  {
    "objectID": "chap06.html#installing-and-loading-the-r-packages",
    "href": "chap06.html#installing-and-loading-the-r-packages",
    "title": "6  Analysing Marked Point Patterns",
    "section": "6.2 Installing and Loading the R packages",
    "text": "6.2 Installing and Loading the R packages\nFor the purpose of this study, five R packages will be used. They are:\n\nrgdal for importing geospatial data in GIS file format such as shapefile into R and save them as Spatial*DataFrame,\nmaptools for converting Spatial* object into ppp object,\nraster for handling raster data in R,\nspatstat for performing Spatial Point Patterns Analysis such as kcross, Lcross, etc., and\ntmap for producing cartographic quality thematic maps.\n\n\npacman::p_load(rgdal, maptools, raster, spatstat, tmap)"
  },
  {
    "objectID": "chap06.html#importing-the-geospatial-data",
    "href": "chap06.html#importing-the-geospatial-data",
    "title": "6  Analysing Marked Point Patterns",
    "section": "6.3 Importing the Geospatial Data",
    "text": "6.3 Importing the Geospatial Data\nThe code chunk below uses readOGR() of rgdal package toimport both geospatial data files (i.e. shapefile) into R.\n\nchildcare &lt;- readOGR(dsn = \"chap06/data/geospatial\", layer=\"CHILDCARE\")\n\nOGR data source with driver: ESRI Shapefile \nSource: \"D:\\tskam\\r4gdsa\\chap06\\data\\geospatial\", layer: \"CHILDCARE\"\nwith 1885 features\nIt has 1 fields\n\nmpsz = readOGR(dsn = \"chap06/data/geospatial\", layer=\"MP14_SUBZONE_WEB_PL\")\n\nOGR data source with driver: ESRI Shapefile \nSource: \"D:\\tskam\\r4gdsa\\chap06\\data\\geospatial\", layer: \"MP14_SUBZONE_WEB_PL\"\nwith 323 features\nIt has 15 fields\n\n\nSince, readOGR() of rgdal package is used, the output R objectswill be in SpatialPointsDataframe and SpatialPolygonsDataframe classes respectively.\nNext str() of Base R will be used to check the data type of childcare SpatialPointsDataFrame. This is necessary because the marked field must be in factor data type if its values are categorical.\n\nstr(childcare)\n\nFormal class 'SpatialPointsDataFrame' [package \"sp\"] with 5 slots\n  ..@ data       :'data.frame': 1885 obs. of  1 variable:\n  .. ..$ Type: chr [1:1885] \"PT\" \"PT\" \"ST\" \"ST\" ...\n  ..@ coords.nrs : num(0) \n  ..@ coords     : num [1:1885, 1:2] 11227 11783 11894 11961 12128 ...\n  .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. ..$ : NULL\n  .. .. ..$ : chr [1:2] \"coords.x1\" \"coords.x2\"\n  ..@ bbox       : num [1:2, 1:2] 11227 25524 44936 49308\n  .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. ..$ : chr [1:2] \"coords.x1\" \"coords.x2\"\n  .. .. ..$ : chr [1:2] \"min\" \"max\"\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n  .. .. ..@ projargs: chr \"+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +to\"| __truncated__\n  .. .. ..$ comment: chr \"PROJCRS[\\\"SVY21 / Singapore TM\\\",\\n    BASEGEOGCRS[\\\"SVY21\\\",\\n        DATUM[\\\"SVY21\\\",\\n            ELLIPSOID[\"| __truncated__\n\n\nThe output above shows that Type field is in character data type and not in factor data type as required by spatstat package. Hence, the code chunk below will be used to convert Type field to factor data type.\n\nchildcare@data$Type &lt;- as.factor(childcare@data$Type)\n\n\nDIY: Using the skill you learned from previous step, check to ensure that Type field is in factor data type now."
  },
  {
    "objectID": "chap06.html#mapping-the-geospatial-layers",
    "href": "chap06.html#mapping-the-geospatial-layers",
    "title": "6  Analysing Marked Point Patterns",
    "section": "6.4 Mapping the geospatial layers",
    "text": "6.4 Mapping the geospatial layers\nNext, let us take a quick look at the distribution of the geospatial data. In the code chunk below, mapping functions of tmap package is used. tmap_mode(\"view\") is used to plot an interactive map by using leaflet api.\n\ntmap_mode(\"view\")\ntm_shape(mpsz) +\n  tm_borders(alpha = 0.5) +\n  tmap_options(check.and.fix = TRUE) +\ntm_shape(childcare) +\n  tm_dots(col = 'Type', size = 0.02)\n\n\n\n\n\ntmap_mode(\"plot\")\n\nAlternatively, we can use the code chunk below to create four small point maps by using tm_facets() of tmap pckage.\n\ntm_shape(mpsz) +\n  tm_borders(alpha = 0.5) +\ntm_shape(childcare) +\n  tm_dots(col = 'Type', \n          size = 0.5) +\ntm_facets(by=\"Type\")"
  },
  {
    "objectID": "chap06.html#spatial-data-wrangling",
    "href": "chap06.html#spatial-data-wrangling",
    "title": "6  Analysing Marked Point Patterns",
    "section": "6.5 Spatial Data Wrangling",
    "text": "6.5 Spatial Data Wrangling\nTable below shows spatstat functions for wrangling geospatial data. It is advisable for students to familiarise yourself with each of them before you continue.\n\n\n6.5.1 Converting the SpatialPointsDataFrame into ppp format\nThe code chunk below uses as.(x, “ppp”) or as.ppp(x) of maptools package to convert an object x of class SpatialPointsDataFrame to a spatial point pattern in spatstat. In this conversion, the additional field in x data frame will become the marks of the point pattern z.\n\nchildcare_ppp &lt;- as(childcare, \"ppp\")\nplot(childcare_ppp)\n\n\n\n\nFigure above reveals that there are four sub-types in the marks list. They are: NT, PT, RC and ST.\nTo examine the summary statistics of this spatial object, summary() of Base R will be used as shown in the code chunk below.\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1885 points\nAverage intensity 2.351049e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nMultitype:\n   frequency proportion    intensity\nNT       138 0.07320955 1.721193e-07\nPT      1183 0.62758620 1.475486e-06\nRC       200 0.10610080 2.494482e-07\nST       364 0.19310340 4.539957e-07\n\nWindow: rectangle = [11226.55, 44936.07] x [25523.51, 49308.17] units\n                    (33710 x 23780 units)\nWindow area = 801770000 square units\n\n\nThe report above reveals that PT is the largest childcare operator in Singapore with a market share of 63%. This is followed by ST, RC and NT.\nIt is also important to node that the spatial point object contains duplicated points. The quality of our analysis will be compromised if we failed to resolve this data issue.\n\n\n6.5.2 Avoiding duplicated spatial point event by using jittering method\nThe code chunk below resolves the duplicated spatial point events issue by using the jittering approach.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, retry=TRUE, nsim=1, drop=TRUE)\n\nLet us check the output to ensure that there is no more duplicated spatial point events in the data.\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\nThe output shows that the duplicated points issue has been resolved.\n\n\n6.5.3 Creating owin\nWhen analysing spatial point patterns, it is a good practice to confine the analysis within a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nBefore we going ahead to create owin object, however, it is important to understand the geography of the study area. Figure below reveals that the distribution of settlements in our country are constrained by natural such as central water catchment and western reserved area and strategic location such as airports.\n\nIn view of this, it is wiser for us to narrow down the study area by more appropriate geographical area such as by planning area.\n\n\n6.5.4 Extracting study area\nFor the purpose of this study, we will focus of Jurong West planning area. The code chunk below will be used to extract the target planning areas.\n\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n6.5.5 Converting the spatial point data frame into generic sp format\nNext, we will convert these SpatialPolygonsDataFrame layers into generic spatialpolygons layers by using as.SpatialPolygons.tess(x) of maptools package.\n\njw_sp = as(jw, \"SpatialPolygons\")\nstr(jw_sp)\n\nFormal class 'SpatialPolygons' [package \"sp\"] with 4 slots\n  ..@ polygons   :List of 9\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. .. .. ..@ Polygons :List of 1\n  .. .. .. .. ..$ :Formal class 'Polygon' [package \"sp\"] with 5 slots\n  .. .. .. .. .. .. ..@ labpt  : num [1:2] 12930 34858\n  .. .. .. .. .. .. ..@ area   : num 2098176\n  .. .. .. .. .. .. ..@ hole   : logi FALSE\n  .. .. .. .. .. .. ..@ ringDir: int 1\n  .. .. .. .. .. .. ..@ coords : num [1:105, 1:2] 14212 14156 14122 14085 14067 ...\n  .. .. .. ..@ plotOrder: int 1\n  .. .. .. ..@ labpt    : num [1:2] 12930 34858\n  .. .. .. ..@ ID       : chr \"142\"\n  .. .. .. ..@ area     : num 2098176\n  .. .. .. ..$ comment: chr \"0\"\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. .. .. ..@ Polygons :List of 1\n  .. .. .. .. ..$ :Formal class 'Polygon' [package \"sp\"] with 5 slots\n  .. .. .. .. .. .. ..@ labpt  : num [1:2] 11290 35200\n  .. .. .. .. .. .. ..@ area   : num 1524551\n  .. .. .. .. .. .. ..@ hole   : logi FALSE\n  .. .. .. .. .. .. ..@ ringDir: int 1\n  .. .. .. .. .. .. ..@ coords : num [1:93, 1:2] 11769 11774 11901 11925 11934 ...\n  .. .. .. ..@ plotOrder: int 1\n  .. .. .. ..@ labpt    : num [1:2] 11290 35200\n  .. .. .. ..@ ID       : chr \"143\"\n  .. .. .. ..@ area     : num 1524551\n  .. .. .. ..$ comment: chr \"0\"\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. .. .. ..@ Polygons :List of 1\n  .. .. .. .. ..$ :Formal class 'Polygon' [package \"sp\"] with 5 slots\n  .. .. .. .. .. .. ..@ labpt  : num [1:2] 15522 35189\n  .. .. .. .. .. .. ..@ area   : num 1484296\n  .. .. .. .. .. .. ..@ hole   : logi FALSE\n  .. .. .. .. .. .. ..@ ringDir: int 1\n  .. .. .. .. .. .. ..@ coords : num [1:95, 1:2] 15941 15935 15924 15922 15921 ...\n  .. .. .. ..@ plotOrder: int 1\n  .. .. .. ..@ labpt    : num [1:2] 15522 35189\n  .. .. .. ..@ ID       : chr \"145\"\n  .. .. .. ..@ area     : num 1484296\n  .. .. .. ..$ comment: chr \"0\"\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. .. .. ..@ Polygons :List of 1\n  .. .. .. .. ..$ :Formal class 'Polygon' [package \"sp\"] with 5 slots\n  .. .. .. .. .. .. ..@ labpt  : num [1:2] 13397 35812\n  .. .. .. .. .. .. ..@ area   : num 1404537\n  .. .. .. .. .. .. ..@ hole   : logi FALSE\n  .. .. .. .. .. .. ..@ ringDir: int 1\n  .. .. .. .. .. .. ..@ coords : num [1:65, 1:2] 13673 13657 12785 12776 12776 ...\n  .. .. .. ..@ plotOrder: int 1\n  .. .. .. ..@ labpt    : num [1:2] 13397 35812\n  .. .. .. ..@ ID       : chr \"151\"\n  .. .. .. ..@ area     : num 1404537\n  .. .. .. ..$ comment: chr \"0\"\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. .. .. ..@ Polygons :List of 1\n  .. .. .. .. ..$ :Formal class 'Polygon' [package \"sp\"] with 5 slots\n  .. .. .. .. .. .. ..@ labpt  : num [1:2] 14632 35241\n  .. .. .. .. .. .. ..@ area   : num 1287950\n  .. .. .. .. .. .. ..@ hole   : logi FALSE\n  .. .. .. .. .. .. ..@ ringDir: int 1\n  .. .. .. .. .. .. ..@ coords : num [1:57, 1:2] 14106 14097 14085 14070 14065 ...\n  .. .. .. ..@ plotOrder: int 1\n  .. .. .. ..@ labpt    : num [1:2] 14632 35241\n  .. .. .. ..@ ID       : chr \"157\"\n  .. .. .. ..@ area     : num 1287950\n  .. .. .. ..$ comment: chr \"0\"\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. .. .. ..@ Polygons :List of 1\n  .. .. .. .. ..$ :Formal class 'Polygon' [package \"sp\"] with 5 slots\n  .. .. .. .. .. .. ..@ labpt  : num [1:2] 14404 36445\n  .. .. .. .. .. .. ..@ area   : num 906317\n  .. .. .. .. .. .. ..@ hole   : logi FALSE\n  .. .. .. .. .. .. ..@ ringDir: int 1\n  .. .. .. .. .. .. ..@ coords : num [1:41, 1:2] 14220 14209 14157 14090 13766 ...\n  .. .. .. ..@ plotOrder: int 1\n  .. .. .. ..@ labpt    : num [1:2] 14404 36445\n  .. .. .. ..@ ID       : chr \"171\"\n  .. .. .. ..@ area     : num 906317\n  .. .. .. ..$ comment: chr \"0\"\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. .. .. ..@ Polygons :List of 1\n  .. .. .. .. ..$ :Formal class 'Polygon' [package \"sp\"] with 5 slots\n  .. .. .. .. .. .. ..@ labpt  : num [1:2] 15508 36890\n  .. .. .. .. .. .. ..@ area   : num 1793464\n  .. .. .. .. .. .. ..@ hole   : logi FALSE\n  .. .. .. .. .. .. ..@ ringDir: int 1\n  .. .. .. .. .. .. ..@ coords : num [1:173, 1:2] 16296 16297 16297 16297 16297 ...\n  .. .. .. ..@ plotOrder: int 1\n  .. .. .. ..@ labpt    : num [1:2] 15508 36890\n  .. .. .. ..@ ID       : chr \"176\"\n  .. .. .. ..@ area     : num 1793464\n  .. .. .. ..$ comment: chr \"0\"\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. .. .. ..@ Polygons :List of 1\n  .. .. .. .. ..$ :Formal class 'Polygon' [package \"sp\"] with 5 slots\n  .. .. .. .. .. .. ..@ labpt  : num [1:2] 13954 37533\n  .. .. .. .. .. .. ..@ area   : num 1974943\n  .. .. .. .. .. .. ..@ hole   : logi FALSE\n  .. .. .. .. .. .. ..@ ringDir: int 1\n  .. .. .. .. .. .. ..@ coords : num [1:44, 1:2] 13849 13735 13710 13616 13596 ...\n  .. .. .. ..@ plotOrder: int 1\n  .. .. .. ..@ labpt    : num [1:2] 13954 37533\n  .. .. .. ..@ ID       : chr \"186\"\n  .. .. .. ..@ area     : num 1974943\n  .. .. .. ..$ comment: chr \"0\"\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. .. .. ..@ Polygons :List of 1\n  .. .. .. .. ..$ :Formal class 'Polygon' [package \"sp\"] with 5 slots\n  .. .. .. .. .. .. ..@ labpt  : num [1:2] 12593 36300\n  .. .. .. .. .. .. ..@ area   : num 2206305\n  .. .. .. .. .. .. ..@ hole   : logi FALSE\n  .. .. .. .. .. .. ..@ ringDir: int 1\n  .. .. .. .. .. .. ..@ coords : num [1:106, 1:2] 12671 12711 12723 12726 12732 ...\n  .. .. .. ..@ plotOrder: int 1\n  .. .. .. ..@ labpt    : num [1:2] 12593 36300\n  .. .. .. ..@ ID       : chr \"192\"\n  .. .. .. ..@ area     : num 2206305\n  .. .. .. ..$ comment: chr \"0\"\n  ..@ plotOrder  : int [1:9] 9 1 8 7 2 3 4 5 6\n  ..@ bbox       : num [1:2, 1:2] 10373 33982 16297 38489\n  .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. ..$ : chr [1:2] \"x\" \"y\"\n  .. .. ..$ : chr [1:2] \"min\" \"max\"\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n  .. .. ..@ projargs: chr \"+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs\"\n  .. .. ..$ comment: chr \"PROJCRS[\\\"SVY21\\\",\\n    BASEGEOGCRS[\\\"SVY21[WGS84]\\\",\\n        DATUM[\\\"World Geodetic System 1984\\\",\\n         \"| __truncated__\n  ..$ comment: chr \"TRUE\"\n\n\n\nBest Practice: It is always recommended to review the structure of the output object by using either the UI of RStudio or str() function.\n\n\n\n6.5.6 Creating owin object\nNow, we will convert these SpatialPolygons objects into owin objects that is required by spatstat.\n\njw_owin = as(jw_sp, \"owin\")\nstr(jw_owin)\n\nList of 5\n $ type  : chr \"polygonal\"\n $ xrange: num [1:2] 10373 16297\n $ yrange: num [1:2] 33982 38489\n $ bdry  :List of 9\n  ..$ :List of 2\n  .. ..$ x: num [1:104] 14212 14240 14250 14250 14243 ...\n  .. ..$ y: num [1:104] 35397 35520 35596 35689 35740 ...\n  ..$ :List of 2\n  .. ..$ x: num [1:92] 11769 11764 11760 11756 11688 ...\n  .. ..$ y: num [1:92] 35484 35486 35489 35493 35582 ...\n  ..$ :List of 2\n  .. ..$ x: num [1:94] 15941 15944 15944 15945 15950 ...\n  .. ..$ y: num [1:94] 34916 34979 34995 35012 35161 ...\n  ..$ :List of 2\n  .. ..$ x: num [1:64] 13673 13689 13704 13733 13747 ...\n  .. ..$ y: num [1:64] 35226 35229 35233 35245 35252 ...\n  ..$ :List of 2\n  .. ..$ x: num [1:56] 14106 14195 14305 14329 14353 ...\n  .. ..$ y: num [1:56] 34492 34512 34537 34542 34548 ...\n  ..$ :List of 2\n  .. ..$ x: num [1:40] 14220 14444 14878 14938 14945 ...\n  .. ..$ y: num [1:40] 35850 35933 36095 36113 36145 ...\n  ..$ :List of 2\n  .. ..$ x: num [1:172] 16296 16296 16296 16296 16296 ...\n  .. ..$ y: num [1:172] 36694 36695 36696 36697 36698 ...\n  ..$ :List of 2\n  .. ..$ x: num [1:43] 13849 14496 14639 14684 14723 ...\n  .. ..$ y: num [1:43] 36652 37092 37190 37216 37242 ...\n  ..$ :List of 2\n  .. ..$ x: num [1:105] 12671 12648 12605 12637 12678 ...\n  .. ..$ y: num [1:105] 35650 35702 35777 35827 35882 ...\n $ units :List of 3\n  ..$ singular  : chr \"unit\"\n  ..$ plural    : chr \"units\"\n  ..$ multiplier: num 1\n  ..- attr(*, \"class\")= chr \"unitname\"\n - attr(*, \"class\")= chr \"owin\"\n\n\n\n\n6.5.7 Combining childcare points and the study area\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\n\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, summary() is used to reveal the data object as shown in the code chunk below.\n\nsummary(childcare_jw_ppp)\n\nMarked planar point pattern:  114 points\nAverage intensity 7.765382e-06 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nMultitype:\n   frequency proportion    intensity\nNT        16  0.1403509 1.089878e-06\nPT        58  0.5087719 3.950808e-06\nRC        12  0.1052632 8.174086e-07\nST        28  0.2456140 1.907287e-06\n\nWindow: polygonal boundary\n9 separate polygons (no holes)\n           vertices    area relative.area\npolygon 1       104 2098180        0.1430\npolygon 2        92 1524550        0.1040\npolygon 3        94 1484300        0.1010\npolygon 4        64 1404540        0.0957\npolygon 5        56 1287950        0.0877\npolygon 6        40  906317        0.0617\npolygon 7       172 1793460        0.1220\npolygon 8        43 1974940        0.1350\npolygon 9       105 2206310        0.1500\nenclosing rectangle: [10373.179, 16297.184] x [33981.5, 38488.61] units\n                     (5924 x 4507 units)\nWindow area = 14680500 square units\nFraction of frame area: 0.55\n\n\n\nDIY: By referring to previous discussion, describe the content of the output.\n\n\n\n6.5.8 Plotting childcare points and the study area\nLastly, we will plot the combined childcare point and the study area to ensure that the spatial point events are indeed contained within the study area.\n\nplot(childcare_jw_ppp)"
  },
  {
    "objectID": "chap06.html#analysing-marked-point-patterns",
    "href": "chap06.html#analysing-marked-point-patterns",
    "title": "6  Analysing Marked Point Patterns",
    "section": "6.6 Analysing Marked Point Patterns",
    "text": "6.6 Analysing Marked Point Patterns\n\n6.6.1 First-order Spatial Point Patterns Analysis\nIn the code chunk below, density() of spatstat package is used to compute the kernel density objects. Then, plot() is used to plot the output kernel density objects derived. Instead of writing them in two seperate lines, the code chunk below shows how they can be combined into one single line code chunk. However, for clarity purpose, it is nothing wrong if you prefer to keep them as two seperate lines of code.\n\nplot(density(split(rescale(childcare_jw_ppp, 1000))))\n\n\n\n\n\nQuestion: Can you recall what is the purpose of rescale() and why it is used in our case?\n\n\nDIY: What observations can you draw from the figure above?\n\nNext, intensity() of spatstat package is used to reveal the density of childcare centres by operators as shown the code chunk below.\n\nintensity(rescale(childcare_jw_ppp, 1000))\n\n       NT        PT        RC        ST \n1.0898782 3.9508083 0.8174086 1.9072868 \n\n\nThe output reveals that childcare centres operate by PT has the highest density of 3.95 units per km square. This is followed by 1.91 units per km square, 1.09 unit per km square and 0.82 unit per km square for ST, NT and RC respectively.\n\n\n6.6.2 Second-order Multi-tpye Point Patterns Analysis: Cross K-Function\nNow, we will analyse the relationship of PT and ST by using Kcross() of spatstat package.\n\nchildcare_Kcross &lt;- Kcross(childcare_jw_ppp, \n                           i=\"PT\", j=\"ST\",\n                           correction='border')\nplot(childcare_Kcross)\n\n\n\n\nThe plot above reveals that there is a sign that the marked spatial point events are not independent spatially. However, a hypothesis test is required to confirm the observation statistically.\n\n\n6.6.3 Performing CSR testing on the Cross K-Function\nThe hypothesis and test are as follows:\nHo = The distribution of ST childcare centres and NT chilcare centres are spatially independent.\nH1= The distribution of ST childcare centres and NT chilcare centres are NOT at spatially independent.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001 (i.e. at 99.9% confident interval).\nIn order to perform the CSR test, the envelope() of spatstat package will be used.\n\nchildcare_Kcross.csr &lt;- envelope(childcare_jw_ppp, Kcross, i=\"PT\", j=\"ST\", correction='border', nsim=999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(childcare_Kcross.csr, xlab=\"distance(m)\", xlim=c(0,500))\n\n\n\n\n\nQuestion: Why nsim=999 is used?\n\nThe plot above reveals that the are signs that the distribution of childcare centres operate by NT and ST are not independent spatially. Unfortunately, we failed to reject the null hypothesis because the empirical k-cross line is within the envelop of the 99.9% confident interval.\n\n\n6.6.4 Second-order Multi-tpye Point Patterns Analysis: Cross L-Function\nIn the code chunk below, Lcross() of spatstat package is used to compute Cross L-function.\n\nchildcare_Lcross &lt;- Lcross(childcare_jw_ppp, i=\"PT\", j=\"ST\", correction='border')\nplot(childcare_Lcross, . -r ~ r, \n     xlab = \"distance(m)\", \n     xlim=c(0, 500))\n\n\n\n\n\nDIY: With reference to discussion in the earlier section, what observation(s) can you draw from the plot above?\n\n\n\n6.6.5 Performing CSR testing on the Cross L-Function\n\nDIY: With reference to the example given in previous section, define the hypothesis null, hypothesis alternative and rejection criterion.\n\nSimilar to Cross-K-Function, we can perform the CSR test by using envelope() of spatstat package will be used.\n\nchildcare_Lcross.csr &lt;- envelope(childcare_jw_ppp, Lcross, i=\"PT\", j=\"ST\", correction='border', nsim=999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(childcare_Lcross.csr, . -r ~ r, xlab=\"distance(m)\", xlim=c(0,500))\n\n\n\n\n\nDIY: Intepret the analysis result and draw conclusion with reference to the statistical testing result."
  },
  {
    "objectID": "chap07.html#overview",
    "href": "chap07.html#overview",
    "title": "7  Network Constrained Spatial Point Patterns Analysis",
    "section": "7.1 Overview",
    "text": "7.1 Overview\nNetwork constrained Spatial Point Patterns Analysis (NetSPAA) is a collection of spatial point patterns analysis methods special developed for analysing spatial point event occurs on or alongside network. The spatial point event can be locations of traffic accident or childcare centre for example. The network, on the other hand can be a road network or river network.\nIn this hands-on exercise, you are going to gain hands-on experience on using appropriate functions of spNetwork package:\n\nto derive network constrained kernel density estimation (NetKDE), and\nto perform network G-function and k-function analysis"
  },
  {
    "objectID": "chap07.html#the-data",
    "href": "chap07.html#the-data",
    "title": "7  Network Constrained Spatial Point Patterns Analysis",
    "section": "7.2 The Data",
    "text": "7.2 The Data\nIn this study, we will analyse the spatial distribution of childcare centre in Punggol planning area. For the purpose of this study, two geospatial data sets will be used. They are:\n\nPunggol_St, a line features geospatial data which store the road network within Punggol Planning Area.\nPunggol_CC, a point feature geospatial data which store the location of childcare centres within Punggol Planning Area.\n\nBoth data sets are in ESRI shapefile format."
  },
  {
    "objectID": "chap07.html#installing-and-launching-the-r-packages",
    "href": "chap07.html#installing-and-launching-the-r-packages",
    "title": "7  Network Constrained Spatial Point Patterns Analysis",
    "section": "7.3 Installing and launching the R packages",
    "text": "7.3 Installing and launching the R packages\nIn this hands-on exercise, four R packages will be used, they are:\n\nspNetwork, which provides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It also can be used to build spatial matrices (‘listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\nrgdal, which provides bindings to the ‘Geospatial’ Data Abstraction Library (GDAL) (&gt;= 1.11.4) and access to projection/transformation operations from the PROJ library. In this exercise, rgdal will be used to import geospatial data in R and store as sp objects.\nsp, which provides classes and methods for dealing with spatial data in R. In this exercise, it will be used to manage SpatialPointsDataFrame and SpatiaLinesDataFrame, and for performing projection transformation.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\nUse the code chunk below to install and launch the four R packages.\n\npacman::p_load(sp, sf, rgdal, spNetwork, tmap)"
  },
  {
    "objectID": "chap07.html#data-import-and-preparation",
    "href": "chap07.html#data-import-and-preparation",
    "title": "7  Network Constrained Spatial Point Patterns Analysis",
    "section": "7.4 Data Import and Preparation",
    "text": "7.4 Data Import and Preparation\nThe code chunk below uses st_read() of sf package to important Punggol_St and Punggol_CC geospatial data sets into RStudio as sf data frames.\n\nnetwork &lt;- st_read(dsn=\"chap07/data/geospatial\", \n                   layer=\"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `D:\\tskam\\r4gdsa\\chap07\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\nchildcare &lt;- st_read(dsn=\"chap07/data/geospatial\",\n                     layer=\"Punggol_CC\")\n\nReading layer `Punggol_CC' from data source \n  `D:\\tskam\\r4gdsa\\chap07\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\nWe can examine the structure of the output SpatialDataFrame in RStudio. Alternative, code chunk below can be used to print the content of network SpatialLineDataFrame and childcare SpatialPointsDataFrame by using the code chunk below.\n\nstr(network)\nstr(childcare)\n\nWhen I exploring spNetwork’s functions, it came to my attention that spNetwork is expecting the geospatial data contains complete CRS information.\nIn the code chunk below, spTransform() of sp package is used to assign EPSG code to the SpatialDataFrames. The epsg:3414 is the code for svy21.\n\nchildcare &lt;-spTransform(childcare,\n                        CRS(\"+init=epsg:3414\"))\nnetwork &lt;- spTransform(network,\n                       CRS(\"+init=epsg:3414\"))"
  },
  {
    "objectID": "chap07.html#visualising-the-geospatial-data",
    "href": "chap07.html#visualising-the-geospatial-data",
    "title": "7  Network Constrained Spatial Point Patterns Analysis",
    "section": "7.5 Visualising the Geospatial Data",
    "text": "7.5 Visualising the Geospatial Data\nBefore we jump into the analysis, it is a good practice to visualise the geospatial data. There are at least two ways to visualise the geospatial data. One way is by using plot() of Base R as shown in the code chunk below.\n\nplot(network)\nplot(childcare,add=T,col='red',pch = 19)\n\n\n\n\nTo visualise the geospatial data with high cartographic quality and interactive manner, the mapping function of tmap package can be used as shown in the code chunk below.\n\ntmap_mode('view')\ntm_shape(childcare) + \n  tm_dots() + \n  tm_shape(network) +\n  tm_lines()\n\n\n\n\n\ntmap_mode('plot')"
  },
  {
    "objectID": "chap07.html#network-constrained-kde-netkde-analysis",
    "href": "chap07.html#network-constrained-kde-netkde-analysis",
    "title": "7  Network Constrained Spatial Point Patterns Analysis",
    "section": "7.6 Network Constrained KDE (NetKDE) Analysis",
    "text": "7.6 Network Constrained KDE (NetKDE) Analysis\nIn this section, we will perform NetKDE analysis by using appropriate functions provided in spNetwork package.\n\n7.6.1 Preparing the lixels objects\nBefore computing NetKDE, the SpatialLines object need to be cut into lixels with a specified minimal distance. This task can be performed by using with lixelize_lines() of spNetwork as shown in the code chunk below.\n\nlixels &lt;- lixelize_lines(network, \n                         700, \n                         mindist = 350)\n\nWhat can we learned from the code chunk above:\n\nThe length of a lixel, lx_length is set to 700m, and\nThe minimum length of a lixel, mindist is set to 350m.\n\nAfter cut, if the length of the final lixel is shorter than the minimum distance, then it is added to the previous lixel. If NULL, then mindist = maxdist/10. Also note that the segments that are already shorter than the minimum distance are not modified\nNote: There is another function called lixelize_lines.mc() which provide multicore support.\n\n\n7.6.2 Generating line centre points\nNext, lines_center() of spNetwork will be used to generate a SpatialPointsDataFrame (i.e. samples) with line centre points as shown in the code chunk below.\n\nsamples &lt;- lines_center(lixels)\n\nThe points are located at center of the line based on the length of the line.\n\n\n7.6.3 Performing NetKDE\nWe are ready to computer the NetKDE by using the code chunk below.\n\ndensities &lt;- nkde(network, \n                  events = childcare,\n                  w = rep(1,nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, #we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n\nWhat can we learn from the code chunk above?\n\nkernel_name argument indicates that quartic kernel is used. Are possible kernel methods supported by spNetwork are: triangle, gaussian, scaled gaussian, tricube, cosine ,triweight, epanechnikov or uniform.\nmethod argument indicates that simple method is used to calculate the NKDE. Currently, spNetwork support three popular methods, they are:\n\nmethod=“simple”. This first method was presented by Xie et al. (2008) and proposes an intuitive solution. The distances between events and sampling points are replaced by network distances, and the formula of the kernel is adapted to calculate the density over a linear unit instead of an areal unit.\nmethod=“discontinuous”. The method is proposed by Okabe et al (2008), which equally “divides” the mass density of an event at intersections of lixels.\nmethod=“continuous”. If the discontinuous method is unbiased, it leads to a discontinuous kernel function which is a bit counter-intuitive. Okabe et al (2008) proposed another version of the kernel, that divide the mass of the density at intersection but adjusts the density before the intersection to make the function continuous.\n\n\nThe user guide of spNetwork package provide a comprehensive discussion of nkde(). You should read them at least once to have a basic understanding of the various parameters that can be used to calibrate the NetKDE model.\n\n7.6.3.1 Visualising NetKDE\nBefore we can visualise the NetKDE values, code chunk below will be used to insert the computed density values (i.e. densities) into samples and lixels objects as density field.\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\nSince svy21 projection system is in meter, the computed density values are very small i.e. 0.0000005. The code chunk below is used to resale the density values from number of events per meter to number of events per kilometer.\n\n# rescaling to help the mapping\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\nThe code below uses appropriate functions of tmap package to prepare interactive and high cartographic quality map visualisation.\n\ntmap_mode('view')\ntm_shape(lixels)+\n  tm_lines(col=\"density\")+\ntm_shape(childcare)+\n  tm_dots()\n\n\n\n\n\ntmap_mode('plot')\n\nThe interactive map above effectively reveals road segments (darker color) with relatively higher density of childcare centres than road segments with relatively lower density of childcare centres (lighter color)"
  },
  {
    "objectID": "chap07.html#network-constrained-g--and-k-function-analysis",
    "href": "chap07.html#network-constrained-g--and-k-function-analysis",
    "title": "7  Network Constrained Spatial Point Patterns Analysis",
    "section": "7.7 Network Constrained G- and K-Function Analysis",
    "text": "7.7 Network Constrained G- and K-Function Analysis\nIn this section, we are going to perform complete spatial randomness (CSR) test by using kfunctions() of spNetwork package. The null hypothesis is defined as:\nHo: The observed spatial point events (i.e distribution of childcare centres) are uniformly distributed over a street network in Punggol Planning Area.\nThe CSR test is based on the assumption of the binomial point process which implies the hypothesis that the childcare centres are randomly and independently distributed over the street network.\nIf this hypothesis is rejected, we may infer that the distribution of childcare centres are spatially interacting and dependent on each other; as a result, they may form nonrandom patterns.\n\nkfun_childcare &lt;- kfunctions(network, \n                             childcare,\n                             start = 0, \n                             end = 1000, \n                             step = 50, \n                             width = 50, \n                             nsim = 50, \n                             resolution = 50,\n                             verbose = FALSE, \n                             conf_int = 0.05)\n\nWhat can we learn from the code chunk above?\nThere are ten arguments used in the code chunk above they are:\n\nlines: A SpatialLinesDataFrame with the sampling points. The geometries must be a SpatialLinesDataFrame (may crash if some geometries are invalid).\npoints: A SpatialPointsDataFrame representing the points on the network. These points will be snapped on the network.\nstart: A double, the start value for evaluating the k and g functions.\nend: A double, the last value for evaluating the k and g functions.\nstep: A double, the jump between two evaluations of the k and g function.\nwidth: The width of each donut for the g-function.\nnsim: An integer indicating the number of Monte Carlo simulations required. In the above example, 50 simulation was performed. Note: most of the time, more simulations are required for inference\nresolution: When simulating random points on the network, selecting a resolution will reduce greatly the calculation time. When resolution is null the random points can occur everywhere on the graph. If a value is specified, the edges are split according to this value and the random points are selected vertices on the new network.\nconf_int: A double indicating the width confidence interval (default = 0.05).\n\nFor the usage of other arguments, you should refer to the user guide of spNetwork package.\nThe output of kfunctions() is a list with the following values:\n\nplotkA, a ggplot2 object representing the values of the k-function\nplotgA, a ggplot2 object representing the values of the g-function\nvaluesA, a DataFrame with the values used to build the plots\n\nFor example, we can visualise the ggplot2 object of k-function by using the code chunk below.\n\nkfun_childcare$plotk\n\n\n\n\nThe blue line is the empirical network K-function of the childcare centres in Punggol planning area. The gray envelop represents the results of the 50 simulations in the interval 2.5% - 97.5%. Because the blue line between the distance of 250m-400m are below the gray area, we can infer that the childcare centres in Punggol planning area resemble regular pattern at the distance of 250m-400m."
  },
  {
    "objectID": "chap07.html#references",
    "href": "chap07.html#references",
    "title": "7  Network Constrained Spatial Point Patterns Analysis",
    "section": "7.8 References",
    "text": "7.8 References\n\nspNetwork: Spatial Analysis on Network\nNetwork Kernel Density Estimate\nDetails about NKDE\nNetwork k Functions"
  },
  {
    "objectID": "chap08.html#overview",
    "href": "chap08.html#overview",
    "title": "8  Spatial Weights and Applications",
    "section": "8.1 Overview",
    "text": "8.1 Overview\nIn this hands-on exercise, you will learn how to compute spatial weights using R. By the end to this hands-on exercise, you will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep package."
  },
  {
    "objectID": "chap08.html#the-study-area-and-data",
    "href": "chap08.html#the-study-area-and-data",
    "title": "8  Spatial Weights and Applications",
    "section": "8.2 The Study Area and Data",
    "text": "8.2 The Study Area and Data\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n8.2.1 Getting Started\nBefore we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are currently installed in your R.\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "chap08.html#getting-the-data-into-r-environment",
    "href": "chap08.html#getting-the-data-into-r-environment",
    "title": "8  Spatial Weights and Applications",
    "section": "8.3 Getting the Data Into R Environment",
    "text": "8.3 Getting the Data Into R Environment\nIn this section, you will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\n8.3.1 Import shapefile into r environment\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"chap08/data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source `D:\\tskam\\r4gdsa\\chap08\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n8.3.2 Import csv file into r environment\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R dataframe class.\n\nhunan2012 &lt;- read_csv(\"chap08/data/aspatial/Hunan_2012.csv\")\n\n\n\n8.3.3 Performing relational join\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan,hunan2012)%&gt;%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "chap08.html#visualising-regional-development-indicator",
    "href": "chap08.html#visualising-regional-development-indicator",
    "title": "8  Spatial Weights and Applications",
    "section": "8.4 Visualising Regional Development Indicator",
    "text": "8.4 Visualising Regional Development Indicator\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "chap08.html#computing-contiguity-spatial-weights",
    "href": "chap08.html#computing-contiguity-spatial-weights",
    "title": "8  Spatial Weights and Applications",
    "section": "8.5 Computing Contiguity Spatial Weights",
    "text": "8.5 Computing Contiguity Spatial Weights\nIn this section, you will learn how to use poly2nb() of spdep package to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\n\n8.5.1 Computing (QUEEN) contiguity based neighbours\nThe code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one heighbours.\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, type:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\nWe can retrive the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\nTo reveal the county names of the five neighboring polygons, the code chunk will be used:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\nYou can display the complete weight matrix by using str().\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\nBe warned: The output might cut across several pages. Save the trees if you are going to print out the report.\n\n\n8.5.2 Creating (ROOK) contiguity based neighbours\nThe code chunk below is used to compute Rook contiguity weight matrix.\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connect area unit has 10 neighbours. There are two area units with only one heighbours.\n\n\n8.5.3 Visualising contiguity weights\nA connectivity graph takes a point and displays a line to each neighboring point. We are working with polygons at the moment, so we will need to get points in order to make our connectivity graphs. The most typically method for this will be polygon centroids. We will calculate these in the sf package before moving onto the graphs. Getting Latitude and Longitude of Polygon Centroids\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid. We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\nWe check the first few observations to see if things are formatted correctly.\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n8.5.3.1 Plotting Queen contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n8.5.3.2 Plotting Rook contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n8.5.3.3 Plotting both Queen and Rook contiguity based neighbours maps\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "chap08.html#computing-distance-based-neighbours",
    "href": "chap08.html#computing-distance-based-neighbours",
    "title": "8  Spatial Weights and Applications",
    "section": "8.6 Computing distance based neighbours",
    "text": "8.6 Computing distance based neighbours\nIn this section, you will learn how to derive distance-based weight matrices by using dnearneigh() of spdep package.\nThe function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds= argument. If unprojected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and longlat=TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\n8.6.1 Determine the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n8.6.2 Computing fixed distance weight matrix\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nQuiz: What is the meaning of “Average number of links: 3.681818” shown above?\nNext, we will use str() to display the content of wm_d62 weight matrix.\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep.\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\n8.6.2.1 Plotting fixed distance weight matrix\nNext, we will plot the distance weight matrix by using the code chunk below.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\n8.6.3 Computing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSimilarly, we can display the content of the matrix by using str().\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\nNotice that each county has six neighbours, no less no more!\n\n8.6.3.1 Plotting distance based neighbours\nWe can plot the weight matrix using the code chunk below.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "chap08.html#weights-based-on-idw",
    "href": "chap08.html#weights-based-on-idw",
    "title": "8  Spatial Weights and Applications",
    "section": "8.7 Weights based on IDW",
    "text": "8.7 Weights based on IDW\nIn this section, you will learn how to derive a spatial weight matrix based on Inversed Distance method.\nFirst, we will compute the distances between areas by using nbdists() of spdep.\n\ndist &lt;- nbdists(wm_q, coords, longlat = TRUE)\nids &lt;- lapply(dist, function(x) 1/(x))\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034\n\n\n\n8.7.1 Row-standardised weights matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error.\nTo see the weight of the first polygon’s eight neighbors type:\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nEach neighbor is assigned a 0.125 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.2 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix by using the code chunk below.\n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "chap08.html#application-of-spatial-weight-matrix",
    "href": "chap08.html#application-of-spatial-weight-matrix",
    "title": "8  Spatial Weights and Applications",
    "section": "8.8 Application of Spatial Weight Matrix",
    "text": "8.8 Application of Spatial Weight Matrix\nIn this section, you will learn how to create four different spatial lagged variables, they are:\n\nspatial lag with row-standardized weights,\nspatial lag as a sum of neighbouring values,\nspatial window average, and\nspatial window sum.\n\n\n8.8.1 Spatial lag with row-standardized weights\nFinally, we’ll compute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nRecalled in the previous section, we retrieved the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\nQuestion: Can you see the meaning of Spatial lag with row-standardized weights now?\n\nWe can append the spatially lag GDPPC values onto hunan sf data frame by using the code chunk below.\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\n\nThe following table shows the average neighboring income values (stored in the Inc.lag object) for each county.\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n8.8.2 Spatial lag as a sum of neighboring values\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, which we have been using to manipulate the neighbors structure throughout the past notebooks. Basically it applies a function across each value in the neighbors structure.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC.\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\nFirst, let us examine the result by using the code chunk below.\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\n\nQuestion: Can you understand the meaning of Spatial lag as a sum of neighboring values now?\n\nNext, we will append the lag_sum GDPPC field into hunan sf data frame by using the code chunk below.\n\nhunan &lt;- left_join(hunan, lag.res)\n\nNow, We can plot both the GDPPC and Spatial Lag Sum GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n8.8.3 Spatial window average\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\n\nNotice that the Number of nonzero links, Percentage nonzero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909\nLet us take a good look at the neighbour list of area [1] by using the code chunk below.\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\nNotice that now [1] has six neighbours instead of five.\nNow we obtain weights with nb2listw()\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nNote: The third command line on the code chunk above renames the field names of lag_wm_q1.res object into NAME_3 and lag_window_avg GDPPC respectively.\nNext, the code chunk below will be used to append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan %&gt;%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\nNote: For more effective comparison, it is advicible to use the core tmap mapping functions.\n\n\n8.8.4 Spatial window sum\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNext, we will assign binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nNotice that now [1] has six neighbours instead of five.\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw().\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\nNote: The second command line on the code chunk above renames the field names of w_sum_gdppc.res object into NAME_3 and w_sum GDPPC respectively.\nNext, the code chunk below will be used to append w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)\n\n\n\n\nNote: For more effective comparison, it is advicible to use the core tmap mapping functions."
  },
  {
    "objectID": "chap08.html#references",
    "href": "chap08.html#references",
    "title": "8  Spatial Weights and Applications",
    "section": "8.9 References",
    "text": "8.9 References\n\nCreating Neighbours using sf objects"
  },
  {
    "objectID": "chap09.html#overview",
    "href": "chap09.html#overview",
    "title": "9  Global Measures of Spatial Autocorrelation",
    "section": "9.1 Overview",
    "text": "9.1 Overview\nIn this hands-on exercise, you will learn how to compute Global and Local Measure of Spatial Autocorrelation (GLSA) by using spdep package. By the end to this hands-on exercise, you will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\ncompute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions spdep package;\ncompute Getis-Ord’s Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of spdep package; and\nto visualise the analysis output by using tmap package."
  },
  {
    "objectID": "chap09.html#getting-started",
    "href": "chap09.html#getting-started",
    "title": "9  Global Measures of Spatial Autocorrelation",
    "section": "9.2 Getting Started",
    "text": "9.2 Getting Started\n\n9.2.1 The analytical question\nIn spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.(https://en.wikipedia.org/wiki/Hunan)\n\n\n9.2.2 The Study Area and Data\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n9.2.3 Setting the Analytical Toolls\nBefore we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are currently installed in your R.\n\nsf is use for importing and handling geospatial data in R,\ntidyverse is mainly use for wrangling attribute data in R,\nspdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\ntmap will be used to prepare cartographic quality chropleth map.\n\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will installed the missing packages,\n\nlaunching the packages into R environment.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "chap09.html#getting-the-data-into-r-environment",
    "href": "chap09.html#getting-the-data-into-r-environment",
    "title": "9  Global Measures of Spatial Autocorrelation",
    "section": "9.3 Getting the Data Into R Environment",
    "text": "9.3 Getting the Data Into R Environment\nIn this section, you will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\n9.3.1 Import shapefile into r environment\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"chap09/data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source `D:\\tskam\\r4gdsa\\chap09\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n9.3.2 Import csv file into r environment\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R data frame class.\n\nhunan2012 &lt;- read_csv(\"chap09/data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n9.3.3 Performing relational join\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\n\n9.3.4 Visualising Regional Development Indicator\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "chap09.html#global-spatial-autocorrelation",
    "href": "chap09.html#global-spatial-autocorrelation",
    "title": "9  Global Measures of Spatial Autocorrelation",
    "section": "9.4 Global Spatial Autocorrelation",
    "text": "9.4 Global Spatial Autocorrelation\nIn this section, you will learn how to compute global spatial autocorrelation statistics and to perform spatial complete randomness test for global spatial autocorrelation.\n\n9.4.1 Computing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nIn the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\nMore specifically, the code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours.\n\n\n9.4.2 Row-standardised weights matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.\n\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.\n\n\n\n9.4.3 Global Spatial Autocorrelation: Moran’s I\nIn this section, you will learn how to perform Moran’s I statistics testing by using moran.test() of spdep.\n\n\n9.4.4 Maron’s I test\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep.\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\n\n9.4.4.1 Computing Monte Carlo Moran’s I\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 1000 simulation will be performed.\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\nQuestion: What statistical conclustion can you draw fro mthe output above?\n\n\n\n9.4.4.2 Visualising Monte Carlo Moran’s I\nIt is always a good practice for us the examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below.\nIn the code chunk below hist() and abline() of R Graphics are used.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\nQuestion: What statistical observation can you draw fro mthe output above?\n\n\nChallenge: Instead of using Base Graph to plot the values, plot the values by using ggplot2 package.\n\n\n\n\n9.4.5 Global Spatial Autocorrelation: Geary’s\nIn this section, you will learn how to perform Geary’s c statistics testing by using appropriate functions of spdep package.\n\n9.4.5.1 Geary’s C test\nThe code chunk below performs Geary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\n\n\n9.4.5.2 Computing Monte Carlo Geary’s C\nThe code chunk below performs permutation test for Geary’s C statistic by using geary.mc() of spdep.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\n\n\n9.4.5.3 Visualising the Monte Carlo Geary’s C\nNext, we will plot a histogram to reveal the distribution of the simulated values by using the code chunk below.\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\") \n\n\n\n\n\nQuestion: What statistical observation can you draw from the output?"
  },
  {
    "objectID": "chap09.html#spatial-correlogram",
    "href": "chap09.html#spatial-correlogram",
    "title": "9  Global Measures of Spatial Autocorrelation",
    "section": "9.5 Spatial Correlogram",
    "text": "9.5 Spatial Correlogram\nSpatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\n\n9.5.1 Compute Moran’s I correlogram\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran’s I. The plot() of base Graph is then used to plot the output.\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\nBy plotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nQuestion: What statistical observation can you draw from the plot above?\n\n\n\n9.5.2 Compute Geary’s C correlogram and plot\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\nSimilar to the previous step, we will print out the analysis report by using the code chunk below.\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "chap10.html#overview",
    "href": "chap10.html#overview",
    "title": "10  Local Measures of Spatial Autocorrelation",
    "section": "10.1 Overview",
    "text": "10.1 Overview\nIn this hands-on exercise, you will learn how to compute Global and Local Measure of Spatial Autocorrelation (GLSA) by using spdep package. By the end to this hands-on exercise, you will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\ncompute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions spdep package;\ncompute Getis-Ord’s Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of spdep package; and\nto visualise the analysis output by using tmap package."
  },
  {
    "objectID": "chap10.html#getting-started",
    "href": "chap10.html#getting-started",
    "title": "10  Local Measures of Spatial Autocorrelation",
    "section": "10.2 Getting Started",
    "text": "10.2 Getting Started\n\n10.2.1 The analytical question\nIn spatial policy, one of the main development objective of the local govenment and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.(https://en.wikipedia.org/wiki/Hunan)\n\n\n10.2.2 The Study Area and Data\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n10.2.3 Setting the Analytical Toolls\nBefore we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are currently installed in your R.\n\nsf is use for importing and handling geospatial data in R,\ntidyverse is mainly use for wrangling attribute data in R,\nspdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\ntmap will be used to prepare cartographic quality chropleth map.\n\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will installed the missing packages,\n\nlaunching the packages into R environment.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "chap10.html#getting-the-data-into-r-environment",
    "href": "chap10.html#getting-the-data-into-r-environment",
    "title": "10  Local Measures of Spatial Autocorrelation",
    "section": "10.3 Getting the Data Into R Environment",
    "text": "10.3 Getting the Data Into R Environment\nIn this section, you will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\n10.3.1 Import shapefile into r environment\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"chap10/data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source `D:\\tskam\\r4gdsa\\chap10\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n10.3.2 Import csv file into r environment\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R data frame class.\n\nhunan2012 &lt;- read_csv(\"chap10/data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n10.3.3 Performing relational join\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\n\n10.3.4 Visualising Regional Development Indicator\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "chap10.html#global-spatial-autocorrelation",
    "href": "chap10.html#global-spatial-autocorrelation",
    "title": "10  Local Measures of Spatial Autocorrelation",
    "section": "10.4 Global Spatial Autocorrelation",
    "text": "10.4 Global Spatial Autocorrelation\nIn this section, you will learn how to compute global spatial autocorrelation statistics and to perform spatial complete randomness test for global spatial autocorrelation.\n\n10.4.1 Computing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nIn the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\nMore specifically, the code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours.\n\n\n10.4.2 Row-standardised weights matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.\n\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.\n\n\n\n10.4.3 Global Spatial Autocorrelation: Moran’s I\nIn this section, you will learn how to perform Moran’s I statistics testing by using moran.test() of spdep.\n\n\n10.4.4 Maron’s I test\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep.\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\n\n10.4.4.1 Computing Monte Carlo Moran’s I\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 1000 simulation will be performed.\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\nQuestion: What statistical conclustion can you draw fro mthe output above?\n\n\n\n10.4.4.2 Visualising Monte Carlo Moran’s I\nIt is always a good practice for us the examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below.\nIn the code chunk below hist() and abline() of R Graphics are used.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\nQuestion: What statistical observation can you draw fro mthe output above?\n\n\nChallenge: Instead of using Base Graph to plot the values, plot the values by using ggplot2 package.\n\n\n\n\n10.4.5 Global Spatial Autocorrelation: Geary’s\nIn this section, you will learn how to perform Geary’s c statistics testing by using appropriate functions of spdep package.\n\n10.4.5.1 Geary’s C test\nThe code chunk below performs Geary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\n\n\n10.4.5.2 Computing Monte Carlo Geary’s C\nThe code chunk below performs permutation test for Geary’s C statistic by using geary.mc() of spdep.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\n\n\n10.4.5.3 Visualising the Monte Carlo Geary’s C\nNext, we will plot a histogram to reveal the distribution of the simulated values by using the code chunk below.\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\") \n\n\n\n\n\nQuestion: What statistical observation can you draw from the output?"
  },
  {
    "objectID": "chap10.html#spatial-correlogram",
    "href": "chap10.html#spatial-correlogram",
    "title": "10  Local Measures of Spatial Autocorrelation",
    "section": "10.5 Spatial Correlogram",
    "text": "10.5 Spatial Correlogram\nSpatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\n\n10.5.1 Compute Moran’s I correlogram\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran’s I. The plot() of base Graph is then used to plot the output.\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\nBy plotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nQuestion: What statistical observation can you draw from the plot above?\n\n\n\n10.5.2 Compute Geary’s C correlogram and plot\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\nSimilar to the previous step, we will print out the analysis report by using the code chunk below.\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "chap10.html#cluster-and-outlier-analysis",
    "href": "chap10.html#cluster-and-outlier-analysis",
    "title": "10  Local Measures of Spatial Autocorrelation",
    "section": "10.6 Cluster and Outlier Analysis",
    "text": "10.6 Cluster and Outlier Analysis\nLocal Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters in the spatial arrangement of a given variable. For instance if we are studying cancer rates among census tracts in a given city local clusters in the rates mean that there are areas that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.\nIn this section, you will learn how to apply appropriate Local Indicators for Spatial Association (LISA), especially local Moran’I to detect cluster and/or outlier from GDP per capita 2012 of Hunan Province, PRC.\n\n10.6.1 Computing local Moran’s I\nTo compute local Moran’s I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\nThe code chunks below are used to compute local Moran’s I of GDPPC2012 at the county level.\n\nfips &lt;- order(hunan$County)\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\nThe code chunk below list the content of the local Moran matrix derived by using printCoefmat().\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]),\n  check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n10.6.1.1 Mapping the local Moran’s I\nBefore mapping the local Moran’s I map, it is wise to append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame. The code chunks below can be used to perform the task. The out SpatialPolygonDataFrame is called hunan.localMI.\n\nhunan.localMI &lt;- cbind(hunan,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n10.6.1.2 Mapping local Moran’s I values\nUsing choropleth mapping functions of tmap package, we can plot the local Moran’s I values by using the code chinks below.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n10.6.1.3 Mapping local Moran’s I p-values\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.\nThe code chunks below produce a choropleth map of Moran’s I p-values by using functions of tmap package.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n10.6.1.4 Mapping both local Moran’s I values and p-values\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "chap10.html#creating-a-lisa-cluster-map",
    "href": "chap10.html#creating-a-lisa-cluster-map",
    "title": "10  Local Measures of Spatial Autocorrelation",
    "section": "10.7 Creating a LISA Cluster Map",
    "text": "10.7 Creating a LISA Cluster Map\nThe LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.\n\n10.7.1 Plotting Moran scatterplot\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nThe code chunk below plots the Moran scatterplot of GDPPC 2012 by using moran.plot() of spdep.\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\nNotice that the plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. This are the high-high locations in the lesson slide.\n\n\n10.7.2 Plotting Moran scatterplot with standardised variable\nFirst we will use scale() to centers and scales the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \n\nThe as.vector() added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.\nNow, we are ready to plot the Moran scatterplot again by using the code chunk below.\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")\n\n\n\n\n\n\n10.7.3 Preparing LISA map classes\nThe code chunks below show the steps to prepare a LISA cluster map.\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\nNext, derives the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.\n\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \n\nThis is follow by centering the local Moran’s around the mean.\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\nNext, we will set a statistical significance level for the local Moran.\n\nsignif &lt;- 0.05       \n\nThese four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.\n\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4      \n\nLastly, places non-significant Moran in the category 0.\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\nIn fact, we can combined all the steps into one single code chunk as shown below:\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I &lt;- localMI[,1]   \nsignif &lt;- 0.05       \nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4    \nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\n\n\n10.7.4 Plotting LISA map\nNow, we can build the LISA map by using the code chunks below.\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\nWe can also include the local Moran’s I map and p-value map as shown below for easy comparison.\n\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\nQuestion: What statistical observations can you draw from the LISA map above?"
  },
  {
    "objectID": "chap10.html#hot-spot-and-cold-spot-area-analysis",
    "href": "chap10.html#hot-spot-and-cold-spot-area-analysis",
    "title": "10  Local Measures of Spatial Autocorrelation",
    "section": "10.8 Hot Spot and Cold Spot Area Analysis",
    "text": "10.8 Hot Spot and Cold Spot Area Analysis\nBeside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.\nThe term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).\n\n10.8.1 Getis and Ord’s G-Statistics\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics\n\n\n\n10.8.2 Deriving distance-based weight matrix\nFirst, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\n\n10.8.2.1 Deriving the centroid\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid(). We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid() function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\n\n\n10.8.2.2 Determine the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n10.8.2.3 Computing fixed distance weight matrix\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\nThe output spatial weights object is called wm62_lw.\n\n\n\n10.8.3 Computing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "chap10.html#computing-gi-statistics",
    "href": "chap10.html#computing-gi-statistics",
    "title": "10  Local Measures of Spatial Autocorrelation",
    "section": "10.9 Computing Gi statistics",
    "text": "10.9 Computing Gi statistics\n\n10.9.1 Gi statistics using fixed distance\n\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding hunan sf data frame by using the code chunk below.\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nIn fact, the code chunk above performs three tasks. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join hunan@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().\n\n\n10.9.2 Mapping Gi values with fixed distance weights\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\nQuestion: What statistical observation can you draw from the Gi map above?\n\n\n\n10.9.3 Gi statistics using adaptive distance\nThe code chunk below are used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw).\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\n10.9.4 Mapping Gi values with adaptive distance weights\nIt is time for us to visualise the locations of hot spot and cold spot areas. The choropleth mapping functions of tmap package will be used to map the Gi values.\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\nQuestion: What statistical observation can you draw from the Gi map above?"
  },
  {
    "objectID": "chap12.html#overview",
    "href": "chap12.html#overview",
    "title": "12  Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "12.1 Overview",
    "text": "12.1 Overview\nIn this hands-on exercise, you will gain hands-on experience on how to delineate homogeneous region by using geographically referenced multivariate data. There are two major analysis, namely:\n\nhierarchical cluster analysis; and\nspatially constrained cluster analysis.\n\n\n12.1.1 Learning Outcome\nBy the end of this hands-on exercise, you will able:\n\nto convert GIS polygon data into R’s simple feature data.frame by using appropriate functions of sf package of R;\nto convert simple feature data.frame into R’s SpatialPolygonDataFrame object by using appropriate sf of package of R;\nto perform custer analysis by using hclust() of Base R;\nto perform spatially constrained cluster analysis using skater() of Base R; and\nto visualise the analysis output by using ggplot2 and tmap package."
  },
  {
    "objectID": "chap12.html#getting-started",
    "href": "chap12.html#getting-started",
    "title": "12  Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "12.2 Getting Started",
    "text": "12.2 Getting Started\n\n12.2.1 The analytical question\nIn geobusiness and spatial policy, it is a common practice to delineate the market or planning area into homogeneous regions by using multivariate data. In this hands-on exercise, we are interested to delineate Shan State, Myanmar into homogeneous regions by using multiple Information and Communication technology (ICT) measures, namely: Radio, Television, Land line phone, Mobile phone, Computer, and Internet at home."
  },
  {
    "objectID": "chap12.html#the-data",
    "href": "chap12.html#the-data",
    "title": "12  Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "12.3 The data",
    "text": "12.3 The data\nTwo data sets will be used in this study. They are:\n\nMyanmar Township Boundary Data (i.e. myanmar_township_boundaries) : This is a GIS data in ESRI shapefile format. It consists of township boundary information of Myanmar. The spatial data are captured in polygon features.\nShan-ICT.csv: This is an extract of The 2014 Myanmar Population and Housing Census Myanmar at the township level.\n\nBoth data sets are download from Myanmar Information Management Unit (MIMU)\n\n12.3.1 Installing and loading R packages\nBefore we get started, it is important for us to install the necessary R packages into R and launch these R packages into R environment.\nThe R packages needed for this exercise are as follows:\n\nSpatial data handling\n\nsf, rgdal and spdep\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\nMultivariate data visualisation and analysis\n\ncoorplot, ggpubr, and heatmaply\n\nCluster analysis\n\ncluster\nClustGeo\n\n\nThe code chunks below installs and launches these R packages into R environment.\n\npacman::p_load(rgdal, spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)\n\nNote: With tidyverse, we do not have to install readr, ggplot2 and dplyr packages separately. In fact, tidyverse also installs other very useful R packages such as tidyr."
  },
  {
    "objectID": "chap12.html#data-import-and-prepatation",
    "href": "chap12.html#data-import-and-prepatation",
    "title": "12  Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "12.4 Data Import and Prepatation",
    "text": "12.4 Data Import and Prepatation\n\n12.4.1 Importing geospatial data into R environment\nIn this section, you will import Myanmar Township Boundary GIS data and its associated attrbiute table into R environment.\nThe Myanmar Township Boundary GIS data is in ESRI shapefile format. It will be imported into R environment by using the st_read() function of sf.\nThe code chunks used are shown below:\n\nshan_sf &lt;- st_read(dsn = \"chap12/data/geospatial\", \n                   layer = \"myanmar_township_boundaries\") %&gt;%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  select(c(2:7))\n\nReading layer `myanmar_township_boundaries' from data source \n  `D:\\tskam\\r4gdsa\\chap12\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\nThe imported township boundary object is called shan_sf. It is saved in simple feature data.frame format. We can view the content of the newly created shan_sf simple features data.frame by using the code chunk below.\n\nshan_sf\n\nSimple feature collection with 55 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 96.15107 ymin: 19.29932 xmax: 101.1699 ymax: 24.15907\nGeodetic CRS:  WGS 84\nFirst 10 features:\n             ST ST_PCODE       DT   DT_PCODE        TS  TS_PCODE\n1  Shan (North)   MMR015  Mongmit MMR015D008   Mongmit MMR015017\n2  Shan (South)   MMR014 Taunggyi MMR014D001   Pindaya MMR014006\n3  Shan (South)   MMR014 Taunggyi MMR014D001   Ywangan MMR014007\n4  Shan (South)   MMR014 Taunggyi MMR014D001  Pinlaung MMR014009\n5  Shan (North)   MMR015  Mongmit MMR015D008    Mabein MMR015018\n6  Shan (South)   MMR014 Taunggyi MMR014D001     Kalaw MMR014005\n7  Shan (South)   MMR014 Taunggyi MMR014D001     Pekon MMR014010\n8  Shan (South)   MMR014 Taunggyi MMR014D001  Lawksawk MMR014008\n9  Shan (North)   MMR015  Kyaukme MMR015D003 Nawnghkio MMR015013\n10 Shan (North)   MMR015  Kyaukme MMR015D003   Kyaukme MMR015012\n                         geometry\n1  MULTIPOLYGON (((96.96001 23...\n2  MULTIPOLYGON (((96.7731 21....\n3  MULTIPOLYGON (((96.78483 21...\n4  MULTIPOLYGON (((96.49518 20...\n5  MULTIPOLYGON (((96.66306 24...\n6  MULTIPOLYGON (((96.49518 20...\n7  MULTIPOLYGON (((97.14738 19...\n8  MULTIPOLYGON (((96.94981 22...\n9  MULTIPOLYGON (((96.75648 22...\n10 MULTIPOLYGON (((96.95498 22...\n\n\nNotice that sf.data.frame is conformed to Hardy Wickham’s tidy framework.\nSince shan_sf is conformed to tidy framework, we can also glimpse() to reveal the data type of it’s fields.\n\nglimpse(shan_sf)\n\nRows: 55\nColumns: 7\n$ ST       &lt;chr&gt; \"Shan (North)\", \"Shan (South)\", \"Shan (South)\", \"Shan (South)…\n$ ST_PCODE &lt;chr&gt; \"MMR015\", \"MMR014\", \"MMR014\", \"MMR014\", \"MMR015\", \"MMR014\", \"…\n$ DT       &lt;chr&gt; \"Mongmit\", \"Taunggyi\", \"Taunggyi\", \"Taunggyi\", \"Mongmit\", \"Ta…\n$ DT_PCODE &lt;chr&gt; \"MMR015D008\", \"MMR014D001\", \"MMR014D001\", \"MMR014D001\", \"MMR0…\n$ TS       &lt;chr&gt; \"Mongmit\", \"Pindaya\", \"Ywangan\", \"Pinlaung\", \"Mabein\", \"Kalaw…\n$ TS_PCODE &lt;chr&gt; \"MMR015017\", \"MMR014006\", \"MMR014007\", \"MMR014009\", \"MMR01501…\n$ geometry &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((96.96001 23..., MULTIPOLYGON (((…\n\n\n\n\n12.4.2 Importing aspatial data into R environment\nThe csv file will be import using read_csv function of readr package.\nThe code chunks used are shown below:\n\nict &lt;- read_csv (\"chap12/data/aspatial/Shan-ICT.csv\")\n\nThe imported InfoComm variables are extracted from The 2014 Myanmar Population and Housing Census Myanmar. The attribute data set is called ict. It is saved in R’s * tibble data.frame* format.\nThe code chunk below reveal the summary statistics of ict data.frame.\n\nsummary(ict)\n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\nThere are a total of eleven fields and 55 observation in the tibble data.frame.\n\n\n12.4.3 Derive new variables using dplyr package\nThe unit of measurement of the values are number of household. Using these values directly will be bias by the underlying total number of households. In general, the townships with relatively higher total number of households will also have higher number of households owning radio, TV, etc.\nIn order to overcome this problem, we will derive the penetration rate of each ICT variable by using the code chunk below.\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %&gt;%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\nLet us review the summary statistics of the newly derived penetration rates using the code chunk below.\n\nsummary(ict_derived)\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 21.05  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:138.95  \n Median : 3559   Median : 244.0   Median : 316.0   Median :210.95  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :215.68  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:268.07  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :484.52  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :116.0   Min.   :  2.78   Min.   : 36.42   Min.   : 3.278  \n 1st Qu.:450.2   1st Qu.: 22.84   1st Qu.:190.14   1st Qu.:11.832  \n Median :517.2   Median : 37.59   Median :305.27   Median :18.970  \n Mean   :509.5   Mean   : 51.09   Mean   :314.05   Mean   :24.393  \n 3rd Qu.:606.4   3rd Qu.: 69.72   3rd Qu.:428.43   3rd Qu.:29.897  \n Max.   :842.5   Max.   :181.49   Max.   :735.43   Max.   :92.402  \n  INTERNET_PR     \n Min.   :  1.041  \n 1st Qu.:  8.617  \n Median : 22.829  \n Mean   : 30.644  \n 3rd Qu.: 41.281  \n Max.   :117.985  \n\n\nNotice that six new fields have been added into the data.frame. They are RADIO_PR, TV_PR, LLPHONE_PR, MPHONE_PR, COMPUTER_PR, and INTERNET_PR."
  },
  {
    "objectID": "chap12.html#exploratory-data-analysis-eda",
    "href": "chap12.html#exploratory-data-analysis-eda",
    "title": "12  Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "12.5 Exploratory Data Analysis (EDA)",
    "text": "12.5 Exploratory Data Analysis (EDA)\n\n12.5.1 EDA using statistical graphics\nWe can plot the distribution of the variables (i.e. Number of households with radio) by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\nHistogram is useful to identify the overall distribution of the data values (i.e. left skew, right skew or normal distribution)\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\nBoxplot is useful to detect if there are outliers.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\nNext, we will also plotting the distribution of the newly derived variables (i.e. Radio penetration rate) by using the code chunk below.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\nWhat can you observed from the distributions reveal in the histogram and boxplot.\nIn the figure below, multiple histograms are plotted to reveal the distribution of the selected variables in the ict_derived data.frame.\n\n\n\n\n\nThe code chunks below are used to create the data visualisation. They consist of two main parts. First, we will create the individual histograms using the code chunk below.\n\nradio &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ntv &lt;- ggplot(data=ict_derived, \n             aes(x= `TV_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nllphone &lt;- ggplot(data=ict_derived, \n             aes(x= `LLPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nmphone &lt;- ggplot(data=ict_derived, \n             aes(x= `MPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ncomputer &lt;- ggplot(data=ict_derived, \n             aes(x= `COMPUTER_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ninternet &lt;- ggplot(data=ict_derived, \n             aes(x= `INTERNET_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nNext, the ggarrange() function of ggpubr package is used to group these histograms together.\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)\n\n\n\n12.5.2 EDA using choropleth map\n\n12.5.2.1 Joining geospatial data with aspatial data\nBefore we can prepare the choropleth map, we need to combine both the geospatial data object (i.e. shan_sf) and aspatial data.frame object (i.e. ict_derived) into one. This will be performed by using the left_join function of dplyr package. The shan_sf simple feature data.frame will be used as the base data object and the ict_derived data.frame will be used as the join table.\nThe code chunks below is used to perform the task. The unique identifier used to join both data objects is TS_PCODE.\n\nshan_sf &lt;- left_join(shan_sf, \n                     ict_derived, by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n  \nwrite_rds(shan_sf, \"chap12/data/rds/shan_sf.rds\")\n\nThe message above shows that TS_CODE field is the common field used to perform the left-join.\nIt is important to note that there is no new output data been created. Instead, the data fields from ict_derived data frame are now updated into the data frame of shan_sf.\n\nshan_sf &lt;- read_rds(\"chap12/data/rds/shan_sf.rds\")\n\n\n\n12.5.2.2 Preparing a choropleth map\nTo have a quick look at the distribution of Radio penetration rate of Shan State at township level, a choropleth map will be prepared.\nThe code chunks below are used to prepare the choroplethby using the qtm() function of tmap package.\n\nqtm(shan_sf, \"RADIO_PR\")\n\n\n\n\nIn order to reveal the distribution shown in the choropleth map above are bias to the underlying total number of households at the townships, we will create two choropleth maps, one for the total number of households (i.e. TT_HOUSEHOLDS.map) and one for the total number of household with Radio (RADIO.map) by using the code chunk below.\n\nTT_HOUSEHOLDS.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp=NA, ncol=2)\n\n\n\n\nNotice that the choropleth maps above clearly show that townships with relatively larger number ot households are also showing relatively higher number of radio ownership.\nNow let us plot the choropleth maps showing the dsitribution of total number of households and Radio penetration rate by using the code chunk below.\n\ntm_shape(shan_sf) +\n    tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n                style=\"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins=0, asp=0)\n\n\n\n\nCan you identify the differences?"
  },
  {
    "objectID": "chap12.html#correlation-analysis",
    "href": "chap12.html#correlation-analysis",
    "title": "12  Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "12.6 Correlation Analysis",
    "text": "12.6 Correlation Analysis\nBefore we perform cluster analysis, it is important for us to ensure that the cluster variables are not highly correlated.\nIn this section, you will learn how to use corrplot.mixed() function of corrplot package to visualise and analyse the correlation of the input variables.\n\ncluster_vars.cor = cor(ict_derived[,12:17])\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nThe correlation plot above shows that COMPUTER_PR and INTERNET_PR are highly correlated. This suggest that only one of them should be used in the cluster analysis instead of both."
  },
  {
    "objectID": "chap12.html#hierarchy-cluster-analysis",
    "href": "chap12.html#hierarchy-cluster-analysis",
    "title": "12  Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "12.7 Hierarchy Cluster Analysis",
    "text": "12.7 Hierarchy Cluster Analysis\nIn this section, you will learn how to perform hierarchical cluster analysis. The analysis consists of four major steps:\n\n12.7.1 Extracting clustering variables\nThe code chunk below will be used to extract the clustering variables from the shan_sf simple feature object into data.frame.\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNotice that the final clustering variables list does not include variable INTERNET_PR because it is highly correlated with variable COMPUTER_PR.\nNext, we need to change the rows by township name instead of row number by using the code chunk below\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNotice that the row number has been replaced into the township name.\nNow, we will delete the TS.x field by using the code chunk below.\n\nshan_ict &lt;- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\n\n12.7.2 Data Standardisation\nIn general, multiple variables will be used in cluster analysis. It is not unusual their values range are different. In order to avoid the cluster analysis result is baised to clustering variables with large values, it is useful to standardise the input variables before performing cluster analysis.\n\n\n12.7.3 Min-Max standardisation\nIn the code chunk below, normalize() of heatmaply package is used to stadardisation the clustering variables by using Min-Max method. The summary() is then used to display the summary statistics of the standardised clustering variables.\n\nshan_ict.std &lt;- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\nNotice that the values range of the Min-max standardised clustering variables are 0-1 now.\n\n\n12.7.4 Z-score standardisation\nZ-score standardisation can be performed easily by using scale() of Base R. The code chunk below will be used to stadardisation the clustering variables by using Z-score method.\n\nshan_ict.z &lt;- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\nNotice the mean and standard deviation of the Z-score standardised clustering variables are 0 and 1 respectively.\nNote: describe() of psych package is used here instead of summary() of Base R because the earlier provides standard deviation.\nWarning: Z-score standardisation method should only be used if we would assume all variables come from some normal distribution.\n\n\n12.7.5 Visualising the standardised clustering variables\nBeside reviewing the summary statistics of the standardised clustering variables, it is also a good practice to visualise their distribution graphical.\nThe code chunk below plot the scaled Radio_PR field.\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\nWhat statistical conclusion can you draw from the histograms above?\n\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n12.7.6 Computing proximity matrix\nIn R, many packages provide functions to calculate distance matrix. We will compute the proximity matrix by using dist() of R.\ndist() supports six distance proximity calculations, they are: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is euclidean proximity matrix.\nThe code chunk below is used to compute the proximity matrix using euclidean method.\n\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\n\nThe code chunk below can then be used to list the content of proxmat for visual inspection.\n\nproxmat\n\n\n\n12.7.7 Computing hierarchical clustering\nIn R, there are several packages provide hierarchical clustering function. In this hands-on exercise, hclust() of R stats will be used.\nhclust() employed agglomeration method to compute the cluster. Eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC).\nThe code chunk below performs hierarchical cluster analysis using ward.D method. The hierarchical clustering output is stored in an object of class hclust which describes the tree produced by the clustering process.\n\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\nWe can then plot the tree by using plot() of R Graphics as shown in the code chunk below.\n\nplot(hclust_ward, cex = 0.6)\n\n\n\n\n\n\n12.7.8 Selecting the optimal clustering algorithm\nOne of the challenge in performing hierarchical clustering is to identify stronger clustering structures. The issue can be solved by using use agnes() function of cluster package. It functions like hclus(), however, with the agnes() function you can also get the agglomerative coefficient, which measures the amount of clustering structure found (values closer to 1 suggest strong clustering structure).\nThe code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.\n\nm &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\nWith reference to the output above, we can see that Ward’s method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward’s method will be used.\n\n\n12.7.9 Determining Optimal Clusters\nAnother technical challenge face by data analyst in performing clustering analysis is to determine the optimal clusters to retain.\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow Method\nAverage Silhouette Method\nGap Statistic Method\n\n\n12.7.9.1 Gap Statistic Method\nThe gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.\nTo compute the gap statistic, clusGap() of cluster package will be used.\n\nset.seed(12345)\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\nAlso note that the hcut function used is from factoextra package.\nNext, we can visualise the plot by using fviz_gap_stat() of factoextra package.\n\nfviz_gap_stat(gap_stat)\n\n\n\n\nWith reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examine the gap statistic graph, the 6-cluster gives the largest gap statistic and should be the next best cluster to pick.\nNote: In addition to these commonly used approaches, the NbClust package, published by Charrad et al., 2014, provides 30 indices for determining the relevant number of clusters and proposes to users the best clustering scheme from the different results obtained by varying all combinations of number of clusters, distance measures, and clustering methods.\n\n\n\n12.7.10 Interpreting the dendrograms\nIn the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.\nThe height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Note that, conclusions about the proximity of two observations can be drawn only based on the height where branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.\nIt’s also possible to draw the dendrogram with a border around the selected clusters by using rect.hclust() of R stats. The argument border is used to specify the border colors for the rectangles.\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n12.7.11 Visually-driven hierarchical clustering analysis\nIn this section, we will learn how to perform visually-driven hiearchical clustering analysis by using heatmaply package.\nWith heatmaply, we are able to build both highly interactive cluster heatmap or static cluster heatmap.\n\n12.7.11.1 Transforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform shan_ict data frame into a data matrix.\n\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\n\n\n12.7.11.2 Plotting interactive cluster heatmap using heatmaply()\nIn the code chunk below, the heatmaply() of heatmaply package is used to build an interactive cluster heatmap.\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )\n\n\n\n\n\n\n\n\n12.7.12 Mapping the clusters formed\nWith closed examination of the dendragram above, we have decided to retain six clusters.\ncutree() of R Base will be used in the code chunk below to derive a 6-cluster model.\n\ngroups &lt;- as.factor(cutree(hclust_ward, k=6))\n\nThe output is called groups. It is a list object.\nIn order to visualise the clusters, the groups object need to be appended onto shan_sf simple feature object.\nThe code chunk below form the join in three steps:\n\nthe groups list object will be converted into a matrix;\ncbind() is used to append groups matrix onto shan_sf to produce an output simple feature object called shan_sf_cluster; and\nrename of dplyr package is used to rename as.matrix.groups field as CLUSTER.\n\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nNext, qtm() of tmap package is used to plot the choropleth map showing the cluster formed.\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\nThe choropleth map above reveals the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used."
  },
  {
    "objectID": "chap12.html#spatially-constrained-clustering-skater-approach",
    "href": "chap12.html#spatially-constrained-clustering-skater-approach",
    "title": "12  Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "12.8 Spatially Constrained Clustering: SKATER approach",
    "text": "12.8 Spatially Constrained Clustering: SKATER approach\nIn this section, you will learn how to derive spatially constrained cluster by using skater() method of spdep package.\n\n12.8.1 Converting into SpatialPolygonsDataFrame\nFirst, we need to convert shan_sf into SpatialPolygonsDataFrame. This is because SKATER function only support sp objects such as SpatialPolygonDataFrame.\nThe code chunk below uses as_Spatial() of sf package to convert shan_sf into a SpatialPolygonDataFrame called shan_sp.\n\nshan_sp &lt;- as_Spatial(shan_sf)\n\n\n\n12.8.2 Computing Neighbour List\nNext, poly2nd() of spdep package will be used to compute the neighbours list from polygon list.\n\nshan.nb &lt;- poly2nb(shan_sp)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\nWe can plot the neighbours list on shan_sp by using the code chunk below. Since we now can plot the community area boundaries as well, we plot this graph on top of the map. The first plot command gives the boundaries. This is followed by the plot of the neighbor list object, with coordinates applied to the original SpatialPolygonDataFrame (Shan state township boundaries) to extract the centroids of the polygons. These are used as the nodes for the graph representation. We also set the color to blue and specify add=TRUE to plot the network on top of the boundaries.\n\nplot(shan_sp, \n     border=grey(.5))\nplot(shan.nb, \n     coordinates(shan_sp), \n     col=\"blue\", \n     add=TRUE)\n\n\n\n\nNote that if you plot the network first and then the boundaries, some of the areas will be clipped. This is because the plotting area is determined by the characteristics of the first plot. In this example, because the boundary map extends further than the graph, we plot it first.\n\n\n12.8.3 Computing minimum spanning tree\n\n12.8.3.1 Calculating edge costs\nNext, nbcosts() of spdep package is used to compute the cost of each edge. It is the distance between it nodes. This function compute this distance using a data.frame with observations vector in each node.\nThe code chunk below is used to compute the cost of each edge.\n\nlcosts &lt;- nbcosts(shan.nb, shan_ict)\n\nFor each observation, this gives the pairwise dissimilarity between its values on the five variables and the values for the neighbouring observation (from the neighbour list). Basically, this is the notion of a generalised weight for a spatial weights matrix.\nNext, We will incorporate these costs into a weights object in the same way as we did in the calculation of inverse of distance weights. In other words, we convert the neighbour list to a list weights object by specifying the just computed lcosts as the weights.\nIn order to achieve this, nb2listw() of spdep package is used as shown in the code chunk below.\nNote that we specify the style as B to make sure the cost values are not row-standardised.\n\nshan.w &lt;- nb2listw(shan.nb, \n                   lcosts, \n                   style=\"B\")\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n\n\n\n\n\n12.8.4 Computing minimum spanning tree\nThe minimum spanning tree is computed by mean of the mstree() of spdep package as shown in the code chunk below.\n\nshan.mst &lt;- mstree(shan.w)\n\nAfter computing the MST, we can check its class and dimension by using the code chunk below.\n\nclass(shan.mst)\n\n[1] \"mst\"    \"matrix\"\n\ndim(shan.mst)\n\n[1] 54  3\n\n\nNote that the dimension is 54 and not 55. This is because the minimum spanning tree consists on n-1 edges (links) in order to traverse all the nodes.\nWe can display the content of shan.mst by using head() as shown in the code chunk below.\n\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]   54   48  47.79331\n[2,]   54   17 109.08506\n[3,]   54   45 127.42203\n[4,]   45   52 146.78891\n[5,]   52   13 110.55197\n[6,]   13   28  92.79567\n\n\nThe plot method for the MST include a way to show the observation numbers of the nodes in addition to the edge. As before, we plot this together with the township boundaries. We can see how the initial neighbour list is simplified to just one edge connecting each of the nodes, while passing through all the nodes.\n\nplot(shan_sp, border=gray(.5))\nplot.mst(shan.mst, \n         coordinates(shan_sp), \n         col=\"blue\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)\n\n\n\n\n\n\n12.8.5 Computing spatially constrained clusters using SKATER method\nThe code chunk below compute the spatially constrained cluster using skater() of spdep package.\n\nclust6 &lt;- spdep::skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\n\nThe skater() takes three mandatory arguments: - the first two columns of the MST matrix (i.e. not the cost), - the data matrix (to update the costs as units are being grouped), and - the number of cuts. Note: It is set to one less than the number of clusters. So, the value specified is not the number of clusters, but the number of cuts in the graph, one less than the number of clusters.\nThe result of the skater() is an object of class skater. We can examine its contents by using the code chunk below.\n\nstr(clust6)\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 52 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 25 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 1458\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\nThe most interesting component of this list structure is the groups vector containing the labels of the cluster to which each observation belongs (as before, the label itself is arbitary). This is followed by a detailed summary for each of the clusters in the edges.groups list. Sum of squares measures are given as ssto for the total and ssw to show the effect of each of the cuts on the overall criterion.\nWe can check the cluster assignment by using the conde chunk below.\n\nccs6 &lt;- clust6$groups\nccs6\n\n [1] 3 3 6 3 3 3 3 3 3 3 2 1 1 1 2 1 1 1 2 4 1 2 5 1 1 1 2 1 2 2 1 2 2 1 1 3 1 2\n[39] 2 2 2 2 2 4 1 3 2 1 1 1 2 1 2 1 1\n\n\nWe can find out how many observations are in each cluster by means of the table command. Parenthetially, we can also find this as the dimension of each vector in the lists contained in edges.groups. For example, the first list has node with dimension 12, which is also the number of observations in the first cluster.\n\ntable(ccs6)\n\nccs6\n 1  2  3  4  5  6 \n22 18 11  2  1  1 \n\n\nLastly, we can also plot the pruned tree that shows the five clusters on top of the townshop area.\n\nplot(shan_sp, border=gray(.5))\nplot(clust6, \n     coordinates(shan_sp), \n     cex.lab=.7,\n     groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"pink\"),\n     cex.circles=0.005, \n     add=TRUE)\n\n\n\n\n\n\n12.8.6 Visualising the clusters in choropleth map\nThe code chunk below is used to plot the newly derived clusters by using SKATER method.\n\ngroups_mat &lt;- as.matrix(clust6$groups)\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\n\nFor easy comparison, it will be better to place both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other.\n\nhclust.map &lt;- qtm(shan_sf_cluster,\n                  \"CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\nshclust.map &lt;- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(hclust.map, shclust.map,\n             asp=NA, ncol=2)"
  },
  {
    "objectID": "chap12.html#spatially-constrained-clustering-clustgeo-method",
    "href": "chap12.html#spatially-constrained-clustering-clustgeo-method",
    "title": "12  Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "12.9 Spatially Constrained Clustering: ClustGeo Method",
    "text": "12.9 Spatially Constrained Clustering: ClustGeo Method\nIn this section, you will gain hands-on experience on using functions provided by ClustGeo package to perform non-spatially constrained hierarchical cluster analysis and spatially constrained cluster analysis.\n\n12.9.1 A short note about ClustGeo package\nClustGeo package is an R package specially designed to support the need of performing spatially constrained cluster analysis. More specifically, it provides a Ward-like hierarchical clustering algorithm called hclustgeo() including spatial/geographical constraints.\nIn the nutshell, the algorithm uses two dissimilarity matrices D0 and D1 along with a mixing parameter alpha, whereby the value of alpha must be a real number between [0, 1]. D0 can be non-Euclidean and the weights of the observations can be non-uniform. It gives the dissimilarities in the attribute/clustering variable space. D1, on the other hand, gives the dissimilarities in the constraint space. The criterion minimised at each stage is a convex combination of the homogeneity criterion calculated with D0 and the homogeneity criterion calculated with D1.\nThe idea is then to determine a value of alpha which increases the spatial contiguity without deteriorating too much the quality of the solution based on the variables of interest. This need is supported by a function called choicealpha().\n\n\n12.9.2 Ward-like hierarchical clustering: ClustGeo\nClustGeo package provides function called hclustgeo() to perform a typical Ward-like hierarchical clustering just like hclust() you learned in previous section.\nTo perform non-spatially constrained hierarchical clustering, we only need to provide the function a dissimilarity matrix as shown in the code chunk below.\n\nnongeo_cluster &lt;- hclustgeo(proxmat)\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster, \n            k = 6, \n            border = 2:5)\n\n\n\n\nNote that the dissimilarity matrix must be an object of class dist, i.e. an object obtained with the function dist(). For sample code chunk, please refer to 5.7.6 Computing proximity matrix\n\n12.9.2.1 Mapping the clusters formed\nSimilarly, we can plot the clusters on a categorical area shaded map by using the steps we learned in 5.7.12 Mapping the clusters formed.\n\ngroups &lt;- as.factor(cutree(nongeo_cluster, k=6))\n\n\nshan_sf_ngeo_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\n\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n12.9.3 Spatially Constrained Hierarchical Clustering\nBefore we can performed spatially constrained hierarchical clustering, a spatial distance matrix will be derived by using st_distance() of sf package.\n\ndist &lt;- st_distance(shan_sf, shan_sf)\ndistmat &lt;- as.dist(dist)\n\nNotice that as.dist() is used to convert the data frame into matrix.\nNext, choicealpha() will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below.\n\ncr &lt;- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)\n\n\n\n\n\n\n\nWith reference to the graphs above, alpha = 0.3 will be used as shown in the code chunk below.\n\nclustG &lt;- hclustgeo(proxmat, distmat, alpha = 0.3)\n\nNext, cutree() is used to derive the cluster objecct.\n\ngroups &lt;- as.factor(cutree(clustG, k=6))\n\nWe will then join back the group list with shan_sf polygon feature data frame by using the code chunk below.\n\nshan_sf_Gcluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nWe can now plot the map of the newly delineated spatially constrained clusters.\n\nqtm(shan_sf_Gcluster, \"CLUSTER\")"
  },
  {
    "objectID": "chap12.html#visual-interpretation-of-clusters",
    "href": "chap12.html#visual-interpretation-of-clusters",
    "title": "12  Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "12.10 Visual Interpretation of Clusters",
    "text": "12.10 Visual Interpretation of Clusters\n\n12.10.1 Visualising individual clustering variable\nCode chunk below is used to reveal the distribution of a clustering variable (i.e RADIO_PR) by cluster.\n\nggplot(data = shan_sf_ngeo_cluster,\n       aes(x = CLUSTER, y = RADIO_PR)) +\n  geom_boxplot()\n\n\n\n\nThe boxplot reveals Cluster 3 displays the highest mean Radio Ownership Per Thousand Household. This is followed by Cluster 2, 1, 4, 6 and 5.\n\n\n12.10.2 Multivariate Visualisation\nPast studies shown that parallel coordinate plot can be used to reveal clustering variables by cluster very effectively. In the code chunk below, ggparcoord() of GGally package\n\nggparcoord(data = shan_sf_ngeo_cluster, \n           columns = c(17:21), \n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\nThe parallel coordinate plot above reveals that households in Cluster 4 townships tend to own the highest number of TV and mobile-phone. On the other hand, households in Cluster 5 tends to own the lowest of all the five ICT.\nNote that the scale argument of ggparcoor() provide several methods to scale the clustering variables. They are:\n\nstd: univariately, subtract mean and divide by standard deviation.\nrobust: univariately, subtract median and divide by median absolute deviation.\nuniminmax: univariately, scale so the minimum of the variable is zero, and the maximum is one.\nglobalminmax: no scaling is done; the range of the graphs is defined by the global minimum and the global maximum.\ncenter: use uniminmax to standardize vertical height, then center each variable at a value specified by the scaleSummary param.\ncenterObs: use uniminmax to standardize vertical height, then center each variable at the value of the observation specified by the centerObsID param\n\nThere is no one best scaling method to use. You should explore them and select the one that best meet your analysis need.\nLast but not least, we can also compute the summary statistics such as mean, median, sd, etc to complement the visual interpretation.\nIn the code chunk below, group_by() and summarise() of dplyr are used to derive mean values of the clustering variables.\n\nshan_sf_ngeo_cluster %&gt;% \n  st_set_geometry(NULL) %&gt;%\n  group_by(CLUSTER) %&gt;%\n  summarise(mean_RADIO_PR = mean(RADIO_PR),\n            mean_TV_PR = mean(TV_PR),\n            mean_LLPHONE_PR = mean(LLPHONE_PR),\n            mean_MPHONE_PR = mean(MPHONE_PR),\n            mean_COMPUTER_PR = mean(COMPUTER_PR))\n\n# A tibble: 6 × 6\n  CLUSTER mean_RADIO_PR mean_TV_PR mean_LLPHONE_PR mean_MPHONE_PR\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n1 1               221.        521.            44.2           246.\n2 2               237.        402.            23.9           134.\n3 3               300.        611.            52.2           392.\n4 4               196.        744.            99.0           651.\n5 5               124.        224.            38.0           132.\n6 6                98.6       499.            74.5           468.\n# ℹ 1 more variable: mean_COMPUTER_PR &lt;dbl&gt;"
  },
  {
    "objectID": "chap13.html#overview",
    "href": "chap13.html#overview",
    "title": "13  Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "13.1 Overview",
    "text": "13.1 Overview\nGeographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, you will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational."
  },
  {
    "objectID": "chap13.html#the-data",
    "href": "chap13.html#the-data",
    "title": "13  Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "13.2 The Data",
    "text": "13.2 The Data\nTwo data sets will be used in this model building exercise, they are:\n\nURA Master Plan subzone boundary in shapefile format (i.e. MP14_SUBZONE_WEB_PL)\ncondo_resale_2015 in csv format (i.e. condo_resale_2015.csv)"
  },
  {
    "objectID": "chap13.html#getting-started",
    "href": "chap13.html#getting-started",
    "title": "13  Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "13.3 Getting Started",
    "text": "13.3 Getting Started\nBefore we get started, it is important for us to install the necessary R packages into R and launch these R packages into R environment.\nThe R packages needed for this exercise are as follows:\n\nR package for building OLS and performing diagnostics tests\n\nolsrr\n\nR package for calibrating geographical weighted family of models\n\nGWmodel\n\nR package for multivariate data visualisation and analysis\n\ncorrplot\n\nSpatial data handling\n\nsf\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\n\nThe code chunks below installs and launches these R packages into R environment.\n\npacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)"
  },
  {
    "objectID": "chap13.html#a-short-note-about-gwmodel",
    "href": "chap13.html#a-short-note-about-gwmodel",
    "title": "13  Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "13.4 A short note about GWmodel",
    "text": "13.4 A short note about GWmodel\nGWmodel package provides a collection of localised spatial statistical methods, namely: GW summary statistics, GW principal components analysis, GW discriminant analysis and various forms of GW regression; some of which are provided in basic and robust (outlier resistant) forms. Commonly, outputs or parameters of the GWmodel are mapped to provide a useful exploratory tool, which can often precede (and direct) a more traditional or sophisticated statistical analysis."
  },
  {
    "objectID": "chap13.html#geospatial-data-wrangling",
    "href": "chap13.html#geospatial-data-wrangling",
    "title": "13  Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "13.5 Geospatial Data Wrangling",
    "text": "13.5 Geospatial Data Wrangling\n\n13.5.1 Importing geospatial data\nThe geospatial data used in this hands-on exercise is called MP14_SUBZONE_WEB_PL. It is in ESRI shapefile format. The shapefile consists of URA Master Plan 2014’s planning subzone boundaries. Polygon features are used to represent these geographic boundaries. The GIS data is in svy21 projected coordinates systems.\nThe code chunk below is used to import MP_SUBZONE_WEB_PL shapefile by using st_read() of sf packages.\n\nmpsz = st_read(dsn = \"chap13/data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\tskam\\r4gdsa\\chap13\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe report above shows that the R object used to contain the imported MP14_SUBZONE_WEB_PL shapefile is called mpsz and it is a simple feature object. The geometry type is multipolygon. it is also important to note that mpsz simple feature object does not have EPSG information.\n\n\n13.5.2 Updating CRS information\nThe code chunk below updates the newly imported mpsz with the correct ESPG code (i.e. 3414)\n\nmpsz_svy21 &lt;- st_transform(mpsz, 3414)\n\nAfter transforming the projection metadata, you can varify the projection of the newly transformed mpsz_svy21 by using st_crs() of sf package.\nThe code chunk below will be used to varify the newly transformed mpsz_svy21.\n\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG: is indicated as 3414 now.\nNext, you will reveal the extent of mpsz_svy21 by using st_bbox() of sf package.\n\nst_bbox(mpsz_svy21) #view extent\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "chap13.html#aspatial-data-wrangling",
    "href": "chap13.html#aspatial-data-wrangling",
    "title": "13  Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "13.6 Aspatial Data Wrangling",
    "text": "13.6 Aspatial Data Wrangling\n\n13.6.1 Importing the aspatial data\nThe condo_resale_2015 is in csv file format. The codes chunk below uses read_csv() function of readr package to import condo_resale_2015 into R as a tibble data frame called condo_resale.\n\ncondo_resale = read_csv(\"chap13/data/aspatial/Condo_resale_2015.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe codes chunks below uses glimpse() to display the data structure of will do the job.\n\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             &lt;dbl&gt; 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            &lt;dbl&gt; 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\nhead(condo_resale$LONGITUDE) #see the data in XCOORD column\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\nhead(condo_resale$LATITUDE) #see the data in YCOORD column\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\nNext, summary() of base R is used to display the summary statistics of cond_resale tibble data frame.\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\n\n13.6.2 Converting aspatial data frame into a sf object\nCurrently, the condo_resale tibble data frame is aspatial. We will convert it to a sf object. The code chunk below converts condo_resale data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %&gt;%\n  st_transform(crs=3414)\n\nNotice that st_transform() of sf package is used to convert the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414).\nNext, head() is used to list the content of condo_resale.sf object.\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1   118635       3000000      309    30     7.94          0.166            2.52 \n2   288420       3880000      290    32     6.61          0.280            1.93 \n3   267833       3325000      248    33     6.90          0.429            0.502\n4   258380       4250000      127     7     4.04          0.395            1.99 \n5   467169       1400000      145    28    11.8           0.119            1.12 \n6   466472       1320000      139    22    10.3           0.125            0.789\n# ℹ 15 more variables: PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\nNotice that the output is in point feature data frame."
  },
  {
    "objectID": "chap13.html#exploratory-data-analysis-eda",
    "href": "chap13.html#exploratory-data-analysis-eda",
    "title": "13  Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "13.7 Exploratory Data Analysis (EDA)",
    "text": "13.7 Exploratory Data Analysis (EDA)\nIn the section, you will learn how to use statistical graphics functions of ggplot2 package to perform EDA.\n\n13.7.1 EDA using statistical graphics\nWe can plot the distribution of SELLING_PRICE by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\n\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\nThe figure above reveals a right skewed distribution. This means that more condominium units were transacted at relative lower prices.\nStatistically, the skewed dsitribution can be normalised by using log transformation. The code chunk below is used to derive a new variable called LOG_SELLING_PRICE by using a log transformation on the variable SELLING_PRICE. It is performed using mutate() of dplyr package.\n\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nNow, you can plot the LOG_SELLING_PRICE using the code chunk below.\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\nNotice that the distribution is relatively less skewed after the transformation.\n\n\n13.7.2 Multiple Histogram Plots distribution of variables\nIn this section, you will learn how to draw a small multiple histograms (also known as trellis plot) by using ggarrange() of ggpubr package.\nThe code chunk below is used to create 12 histograms. Then, ggarrange() is used to organised these histogram into a 3 columns by 4 rows small multiple plot.\n\nAREA_SQM &lt;- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE &lt;- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)\n\n\n\n\n\n\n13.7.3 Drawing Statistical Point Map\nLastly, we want to reveal the geospatial distribution condominium resale prices in Singapore. The map will be prepared by using tmap package.\nFirst, we will turn on the interactive mode of tmap by using the code chunk below.\n\ntmap_mode(\"view\")\n\nNext, the code chunks below is used to create an interactive point symbol map.\n\ntm_shape(mpsz_svy21)+\n  tm_polygons() +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\nNotice that tm_dots() is used instead of tm_bubbles().\nset.zoom.limits argument of tm_view() sets the minimum and maximum zoom level to 11 and 14 respectively.\nBefore moving on to the next section, the code below will be used to turn R display into plot mode.\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "chap13.html#hedonic-pricing-modelling-in-r",
    "href": "chap13.html#hedonic-pricing-modelling-in-r",
    "title": "13  Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "13.8 Hedonic Pricing Modelling in R",
    "text": "13.8 Hedonic Pricing Modelling in R\nIn this section, you will learn how to building hedonic pricing models for condominium resale units using lm() of R base.\n\n13.8.1 Simple Linear Regression Method\nFirst, we will build a simple linear regression model by using SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable.\n\ncondo.slr &lt;- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nlm() returns an object of class “lm” or for multiple responses of class c(“mlm”, “lm”).\nThe functions summary() and anova() can be used to obtain and print a summary and analysis of variance table of the results. The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by lm.\n\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\nThe output report reveals that the SELLING_PRICE can be explained by using the formula:\n      *y = -258121.1 + 14719x1*\nThe R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince p-value is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.\nThe Coefficients: section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.\nTo visualise the best fit curve on a scatterplot, we can incorporate lm() as a method function in ggplot’s geometry as shown in the code chunk below.\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\nFigure above reveals that there are a few statistical outliers with relatively high selling prices.\n\n\n13.8.2 Multiple Linear Regression Method\n\n13.8.2.1 Visualising the relationships of the independent variables\nBefore building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other. If these highly correlated independent variables are used in building a regression model by mistake, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. Beside the pairs() of R, there are many packages support the display of a correlation matrix. In this section, the corrplot package will be used.\nThe code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in condo_resale data.frame.\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, LEASE_99YEAR is excluded in the subsequent model building.\n\n\n\n13.8.3 Building a hedonic pricing model using multiple linear regression method\nThe code chunk below using lm() to calibrate the multiple linear regression model.\n\ncondo.mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n13.8.4 Preparing Publication Quality Table: olsrr method\nWith reference to the report above, it is clear that not all the independent variables are statistically significant. We will revised the model by removing those variables which are not statistically significant.\nNow, we are ready to calibrate the revised model by using the code chunk below.\n\ncondo.mlr1 &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n                             Model Summary                               \n------------------------------------------------------------------------\nR                       0.807       RMSE                     755957.289 \nR-Squared               0.651       Coef. Var                    43.168 \nAdj. R-Squared          0.647       MSE                571471422208.591 \nPred R-Squared          0.638       MAE                      414819.628 \n------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\n\n13.8.5 Preparing Publication Quality Table: gtsummary method\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R.\nIn the code chunk below, tbl_regression() is used to create a well formatted regression report.\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nWith gtsummary package, model statistics can be included in the report by either appending them to the report table by using add_glance_table() or adding as a table source note by using add_glance_source_note() as shown in the code chunk below.\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %&gt;% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = &lt;0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nFor more customisation options, refer to Tutorial: tbl_regression\n\n13.8.5.1 Checking for multicolinearity\nIn this section, we would like to introduce you a fantastic R package specially programmed for performing OLS regression. It is called olsrr. It provides a collection of very useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\ncollinearity diagnostics\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\nIn the code chunk below, the ols_vif_tol() of olsrr package is used to test if there are sign of multicollinearity.\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nSince the VIF of the independent variables are less than 10. We can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n\n13.8.5.2 Test for Non-Linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\nThe figure above reveals that most of the data poitns are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n13.8.5.3 Test for Normality Assumption\nLastly, the code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\nIf you prefer formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chun below.\n\nols_test_normality(condo.mlr1)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.\n\n\n13.8.5.4 Testing for Spatial Autocorrelation\nThe hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.\nIn order to perform spatial autocorrelation test, we need to convert condo_resale.sf from sf data frame into a SpatialPointsDataFrame.\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame.\n\nmlr.output &lt;- as.data.frame(condo.mlr1$residuals)\n\nNext, we will join the newly created data frame with condo_resale.sf object.\n\ncondo_resale.res.sf &lt;- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %&gt;%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\nNext, we will convert condo_resale.res.sf from simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\nThe code chunk below will be used to perform the data conversion process.\n\ncondo_resale.sp &lt;- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\nThe code chunks below is used to create an interactive point symbol map.\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\nRemember to switch back to “plot” mode before continue.\n\ntmap_mode(\"plot\")\n\nThe figure above reveal that there is sign of spatial autocorrelation.\nTo proof that our observation is indeed true, the Moran’s I test will be performed\nFirst, we will compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\nnb &lt;- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nNext, nb2listw() of spdep packge will be used to convert the output neighbours lists (i.e. nb) into a spatial weights.\n\nnb_lw &lt;- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nNext, lm.morantest() of spdep package will be used to perform Moran’s I test for residual spatial autocorrelation\n\nlm.morantest(condo.mlr1, nb_lw)\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.1424418 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "chap13.html#building-hedonic-pricing-models-using-gwmodel",
    "href": "chap13.html#building-hedonic-pricing-models-using-gwmodel",
    "title": "13  Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "13.9 Building Hedonic Pricing Models using GWmodel",
    "text": "13.9 Building Hedonic Pricing Models using GWmodel\nIn this section, you are going to learn how to modelling hedonic pricing using both the fixed and adaptive bandwidth schemes\n\n13.9.1 Building Fixed Bandwidth GWR Model\n\n13.9.1.1 Computing fixed bandwith\nIn the code chunk below bw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Notice that the argument adaptive is set to FALSE indicates that we are interested to compute the fixed bandwidth.\nThere are two possible approaches can be uused to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using approach argeement.\n\nbw.fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\nThe result shows that the recommended bandwidth is 971.3405 metres. (Quiz: Do you know why it is in metre?)\n\n\n13.9.1.2 GWModel method - fixed bandwith\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\n\ngwr.fixed &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                         FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\nThe output is saved in a list of class “gwrm”. The code below can be used to display the model output.\n\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2023-11-29 22:27:48.841237 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2023-11-29 22:27:49.584951 \n\n\nThe report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the globel multiple linear regression model of 42967.1.\n\n\n\n13.9.2 Building Adaptive Bandwidth GWR Model\nIn this section, we will calibrate the gwr-based hedonic pricing model by using adaptive bandwidth approach.\n\n13.9.2.1 Computing the adaptive bandwidth\nSimilar to the earlier section, we will first use bw.gwr() to determine the recommended data point to use.\nThe code chunk used look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to TRUE.\n\nbw.adaptive &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nThe result shows that the 30 is the recommended data points to be used.\n\n\n13.9.2.2 Constructing the adaptive bandwidth gwr model\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\n\ngwr.adaptive &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale.sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\nThe code below can be used to display the model output.\n\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2023-11-29 22:27:55.443413 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2023-11-29 22:27:56.471124 \n\n\nThe report shows that the AICc the adaptive distance gwr is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61.\n\n\n\n13.9.3 Visualising GWR Output\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:\n\nCondition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.\nLocal R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\nPredicted: these are the estimated (or fitted) y values 3. computed by GWR.\nResiduals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produce by using these values.\nCoefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.\n\nThey are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called SDF of the output list.\n\n\n13.9.4 Converting SDF into sf data.frame\nTo visualise the fields in SDF, we need to first covert it into sf data.frame by using the code chunk below.\n\ncondo_resale.sf.adaptive &lt;- st_as_sf(gwr.adaptive$SDF) %&gt;%\n  st_transform(crs=3414)\n\n\ncondo_resale.sf.adaptive.svy21 &lt;- st_transform(condo_resale.sf.adaptive, 3414)\ncondo_resale.sf.adaptive.svy21  \n\n\ngwr.adaptive.output &lt;- as.data.frame(gwr.adaptive$SDF)\ncondo_resale.sf.adaptive &lt;- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\nNext, glimpse() is used to display the content of condo_resale.sf.adaptive sf data frame.\n\nglimpse(condo_resale.sf.adaptive)\n\nRows: 1,436\nColumns: 52\n$ Intercept               &lt;dbl&gt; 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM                &lt;dbl&gt; 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE                     &lt;dbl&gt; -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD                &lt;dbl&gt; -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE          &lt;dbl&gt; 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT                &lt;dbl&gt; -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK               &lt;dbl&gt; -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP           &lt;dbl&gt; 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS             &lt;dbl&gt; 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD                &lt;dbl&gt; 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                &lt;dbl&gt; 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            &lt;dbl&gt; 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             &lt;dbl&gt; 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  &lt;dbl&gt; 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             &lt;dbl&gt; 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             &lt;dbl&gt; 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            &lt;dbl&gt; 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            &lt;dbl&gt; 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                &lt;dbl&gt; 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n\n\n\nsummary(gwr.adaptive$SDF$yhat)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901 \n\n\n\n\n13.9.5 Visualising local R2\nThe code chunks below is used to create an interactive point symbol map.\n\ntmap_mode(\"view\")\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\n\n13.9.6 Visualising coefficient estimates\nThe code chunks below is used to create an interactive point symbol map.\n\ntmap_mode(\"view\")\nAREA_SQM_SE &lt;- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV &lt;- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\n13.9.6.1 By URA Plannign Region\n\ntm_shape(mpsz_svy21[mpsz_svy21$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)"
  },
  {
    "objectID": "chap13.html#reference",
    "href": "chap13.html#reference",
    "title": "13  Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "13.10 Reference",
    "text": "13.10 Reference\nGollini I, Lu B, Charlton M, Brunsdon C, Harris P (2015) “GWmodel: an R Package for exploring Spatial Heterogeneity using Geographically Weighted Models”. Journal of Statistical Software, 63(17):1-50, http://www.jstatsoft.org/v63/i17/\nLu B, Harris P, Charlton M, Brunsdon C (2014) “The GWmodel R Package: further topics for exploring Spatial Heterogeneity using GeographicallyWeighted Models”. Geo-spatial Information Science 17(2): 85-101, http://www.tandfonline.com/doi/abs/10.1080/1009502.2014.917453"
  },
  {
    "objectID": "chap15.html#overview",
    "href": "chap15.html#overview",
    "title": "15  Processing and Visualising Flow Data",
    "section": "15.1 Overview",
    "text": "15.1 Overview\nSpatial interaction represent the flow of people, material, or information between locations in geographical space. It encompasses everything from freight shipments, energy flows, and the global trade in rare antiquities, to flight schedules, rush hour woes, and pedestrian foot traffic.\nEach spatial interaction, as an analogy for a set of movements, is composed of a discrete origin/destination pair. Each pair can be represented as a cell in a matrix where rows are related to the locations (centroids) of origin, while columns are related to locations (centroids) of destination. Such a matrix is commonly known as an origin/destination matrix, or a spatial interaction matrix.\nIn this hands-on exercise, you will learn how to build an OD matrix by using Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall. By the end of this hands-on exercise, you will be able:\n\nto import and extract OD data for a selected time interval,\nto import and save geospatial data (i.e. bus stops and mpsz) into sf tibble data frame objects,\nto populate planning subzone code into bus stops sf tibble data frame,\nto construct desire lines geospatial data from the OD data, and\nto visualise passenger volume by origin and destination bus stops by using the desire lines data."
  },
  {
    "objectID": "chap15.html#getting-started",
    "href": "chap15.html#getting-started",
    "title": "15  Processing and Visualising Flow Data",
    "section": "15.2 Getting Started",
    "text": "15.2 Getting Started\nFor the purpose of this exercise, four r packages will be used. They are:\n\nsf for importing, integrating, processing and transforming geospatial data.\ntidyverse for importing, integrating, wrangling and visualising data.\ntmap for creating thematic maps.\n\n\npacman::p_load(tmap, sf, DT, stplanr,\n               performance,\n               ggpubr, tidyverse)"
  },
  {
    "objectID": "chap15.html#preparing-the-flow-data",
    "href": "chap15.html#preparing-the-flow-data",
    "title": "15  Processing and Visualising Flow Data",
    "section": "15.3 Preparing the Flow Data",
    "text": "15.3 Preparing the Flow Data\n\n15.3.1 Importing the OD data\nFirstly, we will import the Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall by using read_csv() of readr package.\n\nodbus &lt;- read_csv(\"chap15/data/aspatial/origin_destination_bus_202210.csv\")\n\nLet use display the odbus tibble data table by using the code chunk below.\n\nglimpse(odbus)\n\nRows: 5,122,925\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2022-10\", \"2022-10\", \"2022-10\", \"2022-10\", \"2022-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 10, 10, 7, 11, 16, 16, 20, 7, 7, 11, 11, 8, 11, 11…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;dbl&gt; 65239, 65239, 23519, 52509, 54349, 54349, 43371, 8…\n$ DESTINATION_PT_CODE &lt;dbl&gt; 65159, 65159, 23311, 42041, 53241, 53241, 14139, 9…\n$ TOTAL_TRIPS         &lt;dbl&gt; 2, 1, 2, 1, 1, 4, 1, 3, 1, 5, 2, 5, 15, 40, 1, 1, …\n\n\nA quick check of odbus tibble data frame shows that the values in OROGIN_PT_CODE and DESTINATON_PT_CODE are in numeric data type. Hence, the code chunk below is used to convert these data values into character data type.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE) \n\n\n\n15.3.2 Extracting the study data\nFor the purpose of this exercise, we will extract commuting flows on weekday and between 6 and 9 o’clock.\n\nodbus6_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE,\n           DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\nTable below shows the content of odbus6_9\n\ndatatable(odbus6_9)\n\n\n\n\n\n\nWe will save the output in rds format for future used.\n\nwrite_rds(odbus6_9, \"chap15/data/rds/odbus6_9.rds\")\n\nThe code chunk below will be used to import the save odbus6_9.rds into R environment.\n\nodbus6_9 &lt;- read_rds(\"chap15/data/rds/odbus6_9.rds\")"
  },
  {
    "objectID": "chap15.html#working-with-geospatial-data",
    "href": "chap15.html#working-with-geospatial-data",
    "title": "15  Processing and Visualising Flow Data",
    "section": "15.4 Working with Geospatial Data",
    "text": "15.4 Working with Geospatial Data\nFor the purpose of this exercise, two geospatial data will be used. They are:\n\nBusStop: This data provides the location of bus stop as at last quarter of 2022.\nMPSZ-2019: This data provides the sub-zone boundary of URA Master Plan 2019.\n\nBoth data sets are in ESRI shapefile format.\n\n15.4.1 Importing geospatial data\nTwo geospatial data will be used in this exercise, they are:\n\nbusstop &lt;- st_read(dsn = \"chap15/data/geospatial\",\n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source `D:\\tskam\\r4gdsa\\chap15\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 5159 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\nmpsz &lt;- st_read(dsn = \"chap15/data/geospatial\",\n                   layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `D:\\tskam\\r4gdsa\\chap15\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26...\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nst_read() function of sf package is used to import the shapefile into R as sf data frame.\nst_transform() function of sf package is used to transform the projection to crs 3414.\n\n\n\nThe code chunk below will be used to write mpsz sf tibble data frame into an rds file for future use.\n\nmpsz &lt;- write_rds(mpsz, \"chap16/data/rds/mpsz.rds\")"
  },
  {
    "objectID": "chap15.html#geospatial-data-wrangling",
    "href": "chap15.html#geospatial-data-wrangling",
    "title": "15  Processing and Visualising Flow Data",
    "section": "15.5 Geospatial data wrangling",
    "text": "15.5 Geospatial data wrangling\n\n15.5.1 Combining Busstop and mpsz\nCode chunk below populates the planning subzone code (i.e. SUBZONE_C) of mpsz sf data frame into busstop sf data frame.\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\n\n\n\n\n\n\n\nNote\n\n\n\n\nst_intersection() is used to perform point and polygon overly and the output will be in point sf object.\nselect() of dplyr package is then use to retain only BUS_STOP_N and SUBZONE_C in the busstop_mpsz sf data frame.\nfive bus stops are excluded in the resultant data frame because they are outside of Singapore bpundary.\n\n\n\n\ndatatable(busstop_mpsz)\n\n\n\n\n\n\nBefore moving to the next step, it is wise to save the output into rds format.\n\nwrite_rds(busstop_mpsz, \"chap15/data/rds/busstop_mpsz.rds\")  \n\nNext, we are going to append the planning subzone code from busstop_mpsz data frame onto odbus6_9 data frame.\n\nod_data &lt;- left_join(odbus6_9 , busstop_mpsz,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C,\n         DESTIN_BS = DESTINATION_PT_CODE)\n\nBefore continue, it is a good practice for us to check for duplicating records.\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nIf duplicated records are found, the code chunk below will be used to retain the unique records.\n\nod_data &lt;- unique(od_data)\n\nIt will be a good practice to confirm if the duplicating records issue has been addressed fully.\nNext, we will update od_data data frame cwith the planning subzone codes.\n\nod_data &lt;- left_join(od_data , busstop_mpsz,\n            by = c(\"DESTIN_BS\" = \"BUS_STOP_N\")) \n\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\n\nod_data &lt;- unique(od_data)\n\n\nod_data &lt;- od_data %&gt;%\n  rename(DESTIN_SZ = SUBZONE_C) %&gt;%\n  drop_na() %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarise(MORNING_PEAK = sum(TRIPS))\n\nIt is time to save the output into an rds file format.\n\nwrite_rds(od_data, \"chap15/data/rds/od_data_fii.rds\")\n\n\nod_data_fii &lt;- read_rds(\"chap15/data/rds/od_data.rds\")"
  },
  {
    "objectID": "chap15.html#visualising-spatial-interaction",
    "href": "chap15.html#visualising-spatial-interaction",
    "title": "15  Processing and Visualising Flow Data",
    "section": "15.6 Visualising Spatial Interaction",
    "text": "15.6 Visualising Spatial Interaction\nIn this section, you will learn how to prepare a desire line by using stplanr package.\n\n15.6.1 Removing intra-zonal flows\nWe will not plot the intra-zonal flows. The code chunk below will be used to remove intra-zonal flows.\n\nod_data_fij &lt;- od_data[od_data$ORIGIN_SZ!=od_data$DESTIN_SZ,]\n\n\nwrite_rds(od_data_fij, \"chap15/data/rds/od_data_fij.rds\")\n\n\nod_data_fij &lt;- read_rds(\"chap15/data/rds/od_data_fij.rds\")\n\n\n\n15.6.2 Creating desire lines\nIn this code chunk below, od2line() of stplanr package is used to create the desire lines.\n\nflowLine &lt;- od2line(flow = od_data_fij, \n                    zones = mpsz,\n                    zone_code = \"SUBZONE_C\")\n\n\nwrite_rds(flowLine, \"chap15/data/rds/flowLine.rds\")\n\n\n\n15.6.3 Visualising the desire lines\nTo visualise the resulting desire lines, the code chunk below is used.\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nBe patient, the rendering process takes more time because of the transparency argument (i.e. alpha)\n\n\nWhen the flow data are very messy and highly skewed like the one shown above, it is wiser to focus on selected flows, for example flow greater than or equal to 5000 as shown below.\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \n  filter(MORNING_PEAK &gt;= 5000) %&gt;%\ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)"
  },
  {
    "objectID": "chap16.html#overview",
    "href": "chap16.html#overview",
    "title": "16  Calibrating Spatial Interaction Models with R",
    "section": "16.1 Overview",
    "text": "16.1 Overview\nSpatial Interaction Models (SIMs) are mathematical models for estimating flows between spatial entities developed by Alan Wilson in the late 1960s and early 1970, with considerable uptake and refinement for transport modelling since then Boyce and Williams (2015).\nThere are four main types of traditional SIMs (Wilson 1971):\n\nUnconstrained\nProduction-constrained\nAttraction-constrained\nDoubly-constrained\n\nOrdinary least square (OLS), log-normal, Poisson and negative binomial (NB) regression methods have been used extensively to calibrate OD flow models by processing flow data as different types of dependent variables. In this chapter, you will gain hands-on experiences on using appropriate R packages to calibrate SIM by using there four regression methods.\n\n\n\n\n\n\nNote\n\n\n\nCalibration is the process of adjusting parameters in the model to try and get the estimates to agree with the observed data as much as possible. Adjusting the parameters is the sort of iterative process that computers are particularly good at and the goodness-of-fit statistics can be used to indicate when the optimum solution is found. Historically this process required a researcher with the requisite programming skills to write a computer algorithm to iteratively adjust each parameter, check the goodness-of-fit, and then start all over again until the goodness-of-fit statistic was maximised/minimised. (Adam Dennett, 2018)"
  },
  {
    "objectID": "chap16.html#getting-started",
    "href": "chap16.html#getting-started",
    "title": "16  Calibrating Spatial Interaction Models with R",
    "section": "16.3 Getting Started",
    "text": "16.3 Getting Started\nFor the purpose of this exercise, four r packages will be used. They are:\n\nsf for importing, integrating, processing and transforming geospatial data.\ntidyverse for importing, integrating, wrangling and visualising data.\ntmap for creating thematic maps.\n\n\npacman::p_load(tmap, sf, sp,\n               performance, reshape2,\n               ggpubr, tidyverse)"
  },
  {
    "objectID": "chap16.html#preparing-the-flow-data",
    "href": "chap16.html#preparing-the-flow-data",
    "title": "16  Calibrating Spatial Interaction Models with R",
    "section": "16.4 Preparing the Flow Data",
    "text": "16.4 Preparing the Flow Data\n\n16.4.1 Importing the OD data\nFirstly, we will import the Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall by using read_csv() of readr package.\n\nodbus &lt;- read_csv(\"chap15/data/aspatial/origin_destination_bus_202210.csv\")\n\nLet use display the odbus tibble data table by using the code chunk below.\n\nglimpse(odbus)\n\nRows: 5,122,925\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2022-10\", \"2022-10\", \"2022-10\", \"2022-10\", \"2022-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 10, 10, 7, 11, 16, 16, 20, 7, 7, 11, 11, 8, 11, 11…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;dbl&gt; 65239, 65239, 23519, 52509, 54349, 54349, 43371, 8…\n$ DESTINATION_PT_CODE &lt;dbl&gt; 65159, 65159, 23311, 42041, 53241, 53241, 14139, 9…\n$ TOTAL_TRIPS         &lt;dbl&gt; 2, 1, 2, 1, 1, 4, 1, 3, 1, 5, 2, 5, 15, 40, 1, 1, …\n\n\nA quick check of odbus tibble data frame shows that the values in OROGIN_PT_CODE and DESTINATON_PT_CODE are in numeric data type. Hence, the code chunk below is used to convert these data values into character data type.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE) \n\n\n\n16.4.2 Extracting the study data\nFor the purpose of this exercise, we will extract commuting flows on weekday and between 6 and 9 o’clock.\n\nodbus6_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE,\n           DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\nTable below shows the content of odbus6_9\n\ndatatable(odbus6_9)\n\n\n\n\n\n\nWe will save the output in rds format for future used.\n\nwrite_rds(odbus6_9, \"chap15/data/rds/odbus6_9.rds\")\n\nThe code chunk below will be used to import the save odbus6_9.rds into R environment.\n\nodbus6_9 &lt;- read_rds(\"chap15/data/rds/odbus6_9.rds\")"
  },
  {
    "objectID": "chap16.html#working-with-geospatial-data",
    "href": "chap16.html#working-with-geospatial-data",
    "title": "16  Calibrating Spatial Interaction Models with R",
    "section": "16.5 Working with Geospatial Data",
    "text": "16.5 Working with Geospatial Data\nFor the purpose of this exercise, two geospatial data will be used. They are:\n\nBusStop: This data provides the location of bus stop as at last quarter of 2022.\nMPSZ-2019: This data provides the sub-zone boundary of URA Master Plan 2019.\n\nBoth data sets are in ESRI shapefile format.\n\n16.5.1 Importing geospatial data\nTwo geospatial data will be used in this exercise, they are:\n\nbusstop &lt;- st_read(dsn = \"chap15/data/geospatial\",\n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source `D:\\tskam\\r4gdsa\\chap15\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 5159 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\nmpsz &lt;- st_read(dsn = \"chap15/data/geospatial\",\n                   layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `D:\\tskam\\r4gdsa\\chap15\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26...\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nst_read() function of sf package is used to import the shapefile into R as sf data frame.\nst_transform() function of sf package is used to transform the projection to crs 3414."
  },
  {
    "objectID": "chap16.html#geospatial-data-wrangling",
    "href": "chap16.html#geospatial-data-wrangling",
    "title": "16  Calibrating Spatial Interaction Models with R",
    "section": "16.6 Geospatial data wrangling",
    "text": "16.6 Geospatial data wrangling\n\n16.6.1 Combining Busstop and mpsz\nCode chunk below populates the planning subzone code (i.e. SUBZONE_C) of mpsz sf data frame into busstop sf data frame.\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\n\n\n\n\n\n\n\nNote\n\n\n\n\nst_intersection() is used to perform point and polygon overly and the output will be in point sf object.\nselect() of dplyr package is then use to retain only BUS_STOP_N and SUBZONE_C in the busstop_mpsz sf data frame.\nfive bus stops are excluded in the resultant data frame because they are outside of Singapore bpundary.\n\n\n\n\ndatatable(busstop_mpsz)\n\n\n\n\n\n\nBefore moving to the next step, it is wise to save the output into rds format.\n\nwrite_rds(busstop_mpsz, \"chap15/data/rds/busstop_mpsz.rds\")  \n\nNext, we are going to append the planning subzone code from busstop_mpsz data frame onto odbus6_9 data frame.\n\nod_data &lt;- left_join(odbus6_9 , busstop_mpsz,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C,\n         DESTIN_BS = DESTINATION_PT_CODE)\n\nBefore continue, it is a good practice for us to check for duplicating records.\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nIf duplicated records are found, the code chunk below will be used to retain the unique records.\n\nod_data &lt;- unique(od_data)\n\nIt will be a good practice to confirm if the duplicating records issue has been addressed fully.\nNext, we will update od_data data frame cwith the planning subzone codes.\n\nod_data &lt;- left_join(od_data , busstop_mpsz,\n            by = c(\"DESTIN_BS\" = \"BUS_STOP_N\")) \n\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\n\nod_data &lt;- unique(od_data)\n\n\nod_data &lt;- od_data %&gt;%\n  rename(DESTIN_SZ = SUBZONE_C) %&gt;%\n  drop_na() %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarise(MORNING_PEAK = sum(TRIPS))\n\nIt is time to save the output into an rds file format.\n\nwrite_rds(od_data, \"chap15/data/rds/od_data.rds\")\n\n\nod_data &lt;- read_rds(\"chap15/data/rds/od_data.rds\")"
  },
  {
    "objectID": "chap16.html#visualising-spatial-interaction",
    "href": "chap16.html#visualising-spatial-interaction",
    "title": "16  Calibrating Spatial Interaction Models with R",
    "section": "16.7 Visualising Spatial Interaction",
    "text": "16.7 Visualising Spatial Interaction\nIn this section, you will learn how to prepare a desire line by using stplanr package.\n\n16.7.1 Removing intra-zonal flows\nWe will not plot the intra-zonal flows. The code chunk below will be used to remove intra-zonal flows.\n\nod_data1 &lt;- od_data[od_data$ORIGIN_SZ!=od_data$DESTIN_SZ,]\n\n\n\n16.7.2 Creating desire lines\nIn this code chunk below, od2line() of stplanr package is used to create the desire lines.\n\nflowLine &lt;- od2line(flow = od_data1, \n                    zones = mpsz,\n                    zone_code = \"SUBZONE_C\")\n\n\n\n16.7.3 Visualising the desire lines\nTo visualise the resulting desire lines, the code chunk below is used.\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \n  filter(MORNING_PEAK &gt;= 5000) %&gt;%\ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 10),\n           n = 5,\n           alpha = 0.3)\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nBe patient, the rendering process takes more time because of the transparency argument (i.e. alpha)"
  },
  {
    "objectID": "chap16.html#visualising-the-geospatial-data",
    "href": "chap16.html#visualising-the-geospatial-data",
    "title": "16  Calibrating Spatial Interaction Models with R",
    "section": "16.8 Visualising the Geospatial Data",
    "text": "16.8 Visualising the Geospatial Data\n\ntmap_mode(\"plot\")\ntmap_options(check.and.fix = TRUE)\nqtm(mpsz)"
  },
  {
    "objectID": "chap16.html#viewing-the-subzone-spatial-file",
    "href": "chap16.html#viewing-the-subzone-spatial-file",
    "title": "16  Calibrating Spatial Interaction Models with R",
    "section": "16.9 Viewing the Subzone spatial file",
    "text": "16.9 Viewing the Subzone spatial file\n\nhead(mpsz, 10)\n\nSimple feature collection with 10 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 8012.578 ymin: 15748.72 xmax: 35287.9 ymax: 31092.38\nProjected CRS: SVY21 / Singapore TM\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26..."
  },
  {
    "objectID": "chap16.html#isolating-subzone_c-subzone_code-into-a-new-df",
    "href": "chap16.html#isolating-subzone_c-subzone_code-into-a-new-df",
    "title": "16  Calibrating Spatial Interaction Models with R",
    "section": "16.10 Isolating SUBZONE_C (subzone_code) into a new df",
    "text": "16.10 Isolating SUBZONE_C (subzone_code) into a new df\n\nmpsz &lt;- mpsz[order(mpsz$SUBZONE_C),]\nhead(mpsz, 10)\n\nSimple feature collection with 10 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 26154.57 ymin: 37511.2 xmax: 31072.47 ymax: 41804.65\nProjected CRS: SVY21 / Singapore TM\n                 SUBZONE_N SUBZONE_C PLN_AREA_N PLN_AREA_C          REGION_N\n171 ANG MO KIO TOWN CENTRE    AMSZ01 ANG MO KIO         AM NORTH-EAST REGION\n170              CHENG SAN    AMSZ02 ANG MO KIO         AM NORTH-EAST REGION\n163             CHONG BOON    AMSZ03 ANG MO KIO         AM NORTH-EAST REGION\n330             TOWNSVILLE    AMSZ04 ANG MO KIO         AM NORTH-EAST REGION\n329             SHANGRI-LA    AMSZ05 ANG MO KIO         AM NORTH-EAST REGION\n172            KEBUN BAHRU    AMSZ06 ANG MO KIO         AM NORTH-EAST REGION\n233        SEMBAWANG HILLS    AMSZ07 ANG MO KIO         AM NORTH-EAST REGION\n254                 TAGORE    AMSZ08 ANG MO KIO         AM NORTH-EAST REGION\n242      YIO CHU KANG WEST    AMSZ09 ANG MO KIO         AM NORTH-EAST REGION\n252           YIO CHU KANG    AMSZ10 ANG MO KIO         AM NORTH-EAST REGION\n    REGION_C                       geometry\n171      NER MULTIPOLYGON (((29692.8 389...\n170      NER MULTIPOLYGON (((30384.33 39...\n163      NER MULTIPOLYGON (((30676.17 39...\n330      NER MULTIPOLYGON (((29649.88 38...\n329      NER MULTIPOLYGON (((28228.2 392...\n172      NER MULTIPOLYGON (((28491.21 39...\n233      NER MULTIPOLYGON (((27744.03 38...\n254      NER MULTIPOLYGON (((27193.46 41...\n242      NER MULTIPOLYGON (((29269.91 39...\n252      NER MULTIPOLYGON (((29598.36 39..."
  },
  {
    "objectID": "chap16.html#computing-distance-matrix",
    "href": "chap16.html#computing-distance-matrix",
    "title": "16  Calibrating Spatial Interaction Models with R",
    "section": "16.5 Computing Distance Matrix",
    "text": "16.5 Computing Distance Matrix\nIn spatial interaction, a distance matrix is a table that shows the distance between pairs of locations. For example, in the table below we can see an Euclidean distance of 3926.0025 between MESZ01 and RVSZ05, of 3939.1079 between MESZ01 and SRSZ01, and so on. By definition, an location’s distance from itself, which is shown in the main diagonal of the table, is 0.\n\nIn this section, you will learn how to compute a distance matrix by using URA Master Plan 2019 Planning Subzone boundary in which you saved as an rds file called mpsz.\nFirst, let us import mpsz.rds into R environemnt by using the code chunk below.\n\nmpsz &lt;- read_rds(\"chap16/data/rds/mpsz.rds\")\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26...\n\n\nNotice that it is a sf tibble dataframe object class.\n\n16.5.1 Converting from sf data.table to SpatialPolygonsDataFrame\nThere are at least two ways to compute the required distance matrix. One is based on sf and the other is based on sp. Past experience shown that computing distance matrix by using sf function took relatively longer time that sp method especially the data set is large. In view of this, sp method is used in the code chunks below.\nFirst as.Spatial() will be used to convert mpsz from sf tibble data frame to SpatialPolygonsDataFrame of sp object as shown in the code chunk below.\n\nmpsz_sp &lt;- as(mpsz, \"Spatial\")\nmpsz_sp\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 332 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 6\nnames       : SUBZONE_N, SUBZONE_C, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C \nmin values  : ADMIRALTY,    AMSZ01, ANG MO KIO,         AM, CENTRAL REGION,       CR \nmax values  :    YUNNAN,    YSSZ09,     YISHUN,         YS,    WEST REGION,       WR \n\n\n\n\n16.5.2 Computing the distance matrix\nNext, spDists() of sp package will be used to compute the Euclidean distance between the centroids of the planning subzones.\n\n\n\n\n\n\nQ&A\n\n\n\nDo you know why the distance is calculated between two centroids of a pair of spatial polygons?\n\n\n\ndist &lt;- spDists(mpsz_sp, \n                longlat = FALSE)\n\n\nhead(dist, n=c(10, 10))\n\n           [,1]       [,2]      [,3]      [,4]       [,5]      [,6]      [,7]\n [1,]     0.000  3926.0025  3939.108 20252.964  2989.9839  1431.330 19211.836\n [2,]  3926.003     0.0000   305.737 16513.865   951.8314  5254.066 16242.523\n [3,]  3939.108   305.7370     0.000 16412.062  1045.9088  5299.849 16026.146\n [4,] 20252.964 16513.8648 16412.062     0.000 17450.3044 21665.795  7229.017\n [5,]  2989.984   951.8314  1045.909 17450.304     0.0000  4303.232 17020.916\n [6,]  1431.330  5254.0664  5299.849 21665.795  4303.2323     0.000 20617.082\n [7,] 19211.836 16242.5230 16026.146  7229.017 17020.9161 20617.082     0.000\n [8,] 14960.942 12749.4101 12477.871 11284.279 13336.0421 16281.453  5606.082\n [9,]  7515.256  7934.8082  7649.776 18427.503  7801.6163  8403.896 14810.930\n[10,]  6391.342  4975.0021  4669.295 15469.566  5226.8731  7707.091 13111.391\n           [,8]      [,9]     [,10]\n [1,] 14960.942  7515.256  6391.342\n [2,] 12749.410  7934.808  4975.002\n [3,] 12477.871  7649.776  4669.295\n [4,] 11284.279 18427.503 15469.566\n [5,] 13336.042  7801.616  5226.873\n [6,] 16281.453  8403.896  7707.091\n [7,]  5606.082 14810.930 13111.391\n [8,]     0.000  9472.024  8575.490\n [9,]  9472.024     0.000  3780.800\n[10,]  8575.490  3780.800     0.000\n\n\nNotice that the output dist is a matrix object class of R. Also notice that the column heanders and row headers are not labeled with the planning subzone codes.\n\n\n16.5.3 Labelling column and row heanders of a distance matrix\nFirst, we will create a list sorted according to the the distance matrix by planning sub-zone code.\n\nsz_names &lt;- mpsz$SUBZONE_C\n\nNext we will attach SUBZONE_C to row and column for distance matrix matching ahead\n\ncolnames(dist) &lt;- paste0(sz_names)\nrownames(dist) &lt;- paste0(sz_names)\n\n\n\n16.5.4 Pivoting distance value by SUBZONE_C\nNext, we will pivot the distance matrix into a long table by using the row and column subzone codes as show in the code chunk below.\n\ndistPair &lt;- melt(dist) %&gt;%\n  rename(dist = value)\nhead(distPair, 10)\n\nNotice that the within zone distance is 0.\n\n\n16.5.5 Updating intra-zonal distances\nIn this section, we are going to append a constant value to replace the intra-zonal distance of 0.\nFirst, we will select and find out the minimum value of the distance by using summary().\n\ndistPair %&gt;%\n  filter(dist &gt; 0) %&gt;%\n  summary()\n\nNext, a constant distance value of 50m is added into intra-zones distance.\n\ndistPair$dist &lt;- ifelse(distPair$dist == 0,\n                        50, distPair$dist)\n\nThe code chunk below will be used to check the result data.frame.\n\ndistPair %&gt;%\n  summary()\n\nThe code chunk below is used to rename the origin and destination fields.\n\ndistPair &lt;- distPair %&gt;%\n  rename(orig = Var1,\n         dest = Var2)\n\nLastly, the code chunk below is used to save the dataframe for future use.\n\nwrite_rds(distPair, \"chap16/data/rds/distPair.rds\") \n\n\ndistPair &lt;- read_rds(\"chap16/data/rds/distPair.rds\")"
  },
  {
    "objectID": "chap16.html#preparing-flow-data",
    "href": "chap16.html#preparing-flow-data",
    "title": "16  Calibrating Spatial Interaction Models with R",
    "section": "16.6 Preparing flow data",
    "text": "16.6 Preparing flow data\nThe code chunk below is used import od_data save in Chapter 15 into R environment.\n\nod_data_fii &lt;- read_rds(\"chap15/data/rds/od_data_fii.rds\")\n\nNext, we will compute the total passenger trip between and within planning subzones by using the code chunk below. The output is all flow_data.\n\nflow_data &lt;- od_data_fii %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;% \n  summarize(TRIPS = sum(MORNING_PEAK)) \n\nUse the code chunk below to display flow_data dataframe.\n\nhead(flow_data, 10)\n\n\n16.6.1 Separating intra-flow from passenger volume df\nCode chunk below is used to add three new fields in flow_data dataframe.\n\nflow_data$FlowNoIntra &lt;- ifelse(\n  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, \n  0, flow_data$TRIPS)\nflow_data$offset &lt;- ifelse(\n  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, \n  0.000001, 1)\n\n\n\n16.6.2 Combining passenger volume data with distance value\nBefore we can join flow_data and distPair, we need to convert data value type of ORIGIN_SZ and DESTIN_SZ fields of flow_data dataframe into factor data type.\n\nflow_data$ORIGIN_SZ &lt;- as.factor(flow_data$ORIGIN_SZ)\nflow_data$DESTIN_SZ &lt;- as.factor(flow_data$DESTIN_SZ)\n\nNow, left_join() of dplyr will be used to flow_data dataframe and distPair dataframe. The output is called flow_data1.\n\nflow_data1 &lt;- flow_data %&gt;%\n  left_join (distPair,\n             by = c(\"ORIGIN_SZ\" = \"orig\",\n                    \"DESTIN_SZ\" = \"dest\"))"
  },
  {
    "objectID": "chap16.html#preparing-origin-and-destination-attributes",
    "href": "chap16.html#preparing-origin-and-destination-attributes",
    "title": "16  Calibrating Spatial Interaction Models with R",
    "section": "16.7 Preparing Origin and Destination Attributes",
    "text": "16.7 Preparing Origin and Destination Attributes\n\n16.7.1 Importing population data\n\npop &lt;- read_csv(\"chap16/data/aspatial/pop.csv\")\n\n\n\n16.7.2 Geospatial data wrangling\n\npop &lt;- pop %&gt;%\n  left_join(mpsz,\n            by = c(\"PA\" = \"PLN_AREA_N\",\n                   \"SZ\" = \"SUBZONE_N\")) %&gt;%\n  select(1:6) %&gt;%\n  rename(SZ_NAME = SZ,\n         SZ = SUBZONE_C)\n\n\n\n16.7.3 Preparing origin attribute\n\nflow_data1 &lt;- flow_data1 %&gt;%\n  left_join(pop,\n            by = c(ORIGIN_SZ = \"SZ\")) %&gt;%\n  rename(ORIGIN_AGE7_12 = AGE7_12,\n         ORIGIN_AGE13_24 = AGE13_24,\n         ORIGIN_AGE25_64 = AGE25_64) %&gt;%\n  select(-c(PA, SZ_NAME))\n\n\n\n16.7.4 Preparing destination attribute\n\nflow_data1 &lt;- flow_data1 %&gt;%\n  left_join(pop,\n            by = c(DESTIN_SZ = \"SZ\")) %&gt;%\n  rename(DESTIN_AGE7_12 = AGE7_12,\n         DESTIN_AGE13_24 = AGE13_24,\n         DESTIN_AGE25_64 = AGE25_64) %&gt;%\n  select(-c(PA, SZ_NAME))\n\nWe will called the output data file SIM_data. it is in rds data file format.\n\nwrite_rds(flow_data1, \"chap16/data/rds/flow_data_6-9.rds\")"
  },
  {
    "objectID": "chap16.html#calibrating-spatial-interaction-models",
    "href": "chap16.html#calibrating-spatial-interaction-models",
    "title": "16  Calibrating Spatial Interaction Models with R",
    "section": "16.8 Calibrating Spatial Interaction Models",
    "text": "16.8 Calibrating Spatial Interaction Models\nIn this section, you will learn how to calibrate Spatial Interaction Models by using Poisson Regression method.\n\n16.8.1 Importing the modelling data\nFirstly, let us import the modelling data by using the code chunk below.\n\nSIM_data &lt;- read_rds(\"chap16/data/rds/SIM_data.rds\")\n\n\n\n16.8.2 Visualising the dependent variable\nFirstly, let us plot the distribution of the dependent variable (i.e. TRIPS) by using histogram method by using the code chunk below.\n\nggplot(data = SIM_data,\n       aes(x = TRIPS)) +\n  geom_histogram()\n\n\n\n\nNotice that the distribution is highly skewed and not resemble bell shape or also known as normal distribution.\nNext, let us visualise the relation between the dependent variable and one of the key independent variable in Spatial Interaction Model, namely distance.\n\nggplot(data = SIM_data,\n       aes(x = dist,\n           y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\nNotice that their relationship hardly resemble linear relationship.\nOn the other hand, if we plot the scatter plot by using the log transformed version of both variables, we can see that their relationship is more resemble linear relationship.\n\nggplot(data = SIM_data,\n       aes(x = log(dist),\n           y = log(TRIPS))) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\n\n\n16.8.3 Checking for variables with zero values\nSince Poisson Regression is based of log and log 0 is undefined, it is important for us to ensure that no 0 values in the explanatory variables.\nIn the code chunk below, summary() of Base R is used to compute the summary statistics of all variables in SIM_data data frame.\n\nsummary(SIM_data)\n\n  ORIGIN_SZ          DESTIN_SZ             TRIPS           FlowNoIntra      \n Length:14274       Length:14274       Min.   :     1.0   Min.   :     1.0  \n Class :character   Class :character   1st Qu.:    11.0   1st Qu.:    11.0  \n Mode  :character   Mode  :character   Median :    56.0   Median :    56.0  \n                                       Mean   :   664.3   Mean   :   664.3  \n                                       3rd Qu.:   296.0   3rd Qu.:   296.0  \n                                       Max.   :104167.0   Max.   :104167.0  \n     offset       dist         ORIGIN_AGE7_12 ORIGIN_AGE13_24 ORIGIN_AGE25_64\n Min.   :1   Min.   :  173.8   Min.   :   0   Min.   :    0   Min.   :    0  \n 1st Qu.:1   1st Qu.: 3465.4   1st Qu.: 240   1st Qu.:  460   1st Qu.: 2210  \n Median :1   Median : 6121.0   Median : 710   Median : 1400   Median : 7030  \n Mean   :1   Mean   : 6951.8   Mean   :1037   Mean   : 2278   Mean   :10536  \n 3rd Qu.:1   3rd Qu.: 9725.1   3rd Qu.:1500   3rd Qu.: 3282   3rd Qu.:15830  \n Max.   :1   Max.   :26135.8   Max.   :6340   Max.   :16380   Max.   :74610  \n DESTIN_AGE7_12 DESTIN_AGE13_24 DESTIN_AGE25_64\n Min.   :   0   Min.   :    0   Min.   :    0  \n 1st Qu.: 250   1st Qu.:  460   1st Qu.: 2210  \n Median : 720   Median : 1430   Median : 7120  \n Mean   :1040   Mean   : 2305   Mean   :10648  \n 3rd Qu.:1500   3rd Qu.: 3290   3rd Qu.:15830  \n Max.   :6340   Max.   :16380   Max.   :74610  \n\n\nThe print report above reveals that variables ORIGIN_AGE7_12, ORIGIN_AGE13_24, ORIGIN_AGE25_64,DESTIN_AGE7_12, DESTIN_AGE13_24, DESTIN_AGE25_64 consist of 0 values.\nIn view of this, code chunk below will be used to replace zero values to 0.99.\n\nSIM_data$DESTIN_AGE7_12 &lt;- ifelse(\n  SIM_data$DESTIN_AGE7_12 == 0,\n  0.99, SIM_data$DESTIN_AGE7_12)\nSIM_data$DESTIN_AGE13_24 &lt;- ifelse(\n  SIM_data$DESTIN_AGE13_24 == 0,\n  0.99, SIM_data$DESTIN_AGE13_24)\nSIM_data$DESTIN_AGE25_64 &lt;- ifelse(\n  SIM_data$DESTIN_AGE25_64 == 0,\n  0.99, SIM_data$DESTIN_AGE25_64)\nSIM_data$ORIGIN_AGE7_12 &lt;- ifelse(\n  SIM_data$ORIGIN_AGE7_12 == 0,\n  0.99, SIM_data$ORIGIN_AGE7_12)\nSIM_data$ORIGIN_AGE13_24 &lt;- ifelse(\n  SIM_data$ORIGIN_AGE13_24 == 0,\n  0.99, SIM_data$ORIGIN_AGE13_24)\nSIM_data$ORIGIN_AGE25_64 &lt;- ifelse(\n  SIM_data$ORIGIN_AGE25_64 == 0,\n  0.99, SIM_data$ORIGIN_AGE25_64)\n\nYou can run the summary() again.\n\nsummary(SIM_data)\n\n  ORIGIN_SZ          DESTIN_SZ             TRIPS           FlowNoIntra      \n Length:14274       Length:14274       Min.   :     1.0   Min.   :     1.0  \n Class :character   Class :character   1st Qu.:    11.0   1st Qu.:    11.0  \n Mode  :character   Mode  :character   Median :    56.0   Median :    56.0  \n                                       Mean   :   664.3   Mean   :   664.3  \n                                       3rd Qu.:   296.0   3rd Qu.:   296.0  \n                                       Max.   :104167.0   Max.   :104167.0  \n     offset       dist         ORIGIN_AGE7_12    ORIGIN_AGE13_24   \n Min.   :1   Min.   :  173.8   Min.   :   0.99   Min.   :    0.99  \n 1st Qu.:1   1st Qu.: 3465.4   1st Qu.: 240.00   1st Qu.:  460.00  \n Median :1   Median : 6121.0   Median : 710.00   Median : 1400.00  \n Mean   :1   Mean   : 6951.8   Mean   :1036.73   Mean   : 2278.59  \n 3rd Qu.:1   3rd Qu.: 9725.1   3rd Qu.:1500.00   3rd Qu.: 3282.50  \n Max.   :1   Max.   :26135.8   Max.   :6340.00   Max.   :16380.00  \n ORIGIN_AGE25_64    DESTIN_AGE7_12    DESTIN_AGE13_24    DESTIN_AGE25_64   \n Min.   :    0.99   Min.   :   0.99   Min.   :    0.99   Min.   :    0.99  \n 1st Qu.: 2210.00   1st Qu.: 250.00   1st Qu.:  460.00   1st Qu.: 2210.00  \n Median : 7030.00   Median : 720.00   Median : 1430.00   Median : 7120.00  \n Mean   :10535.93   Mean   :1039.98   Mean   : 2305.33   Mean   :10647.95  \n 3rd Qu.:15830.00   3rd Qu.:1500.00   3rd Qu.: 3290.00   3rd Qu.:15830.00  \n Max.   :74610.00   Max.   :6340.00   Max.   :16380.00   Max.   :74610.00  \n\n\nNotice that all the 0 values have been replaced by 0.99.\n\n\n16.8.4 Unconstrained Spatial Interaction Model\nIn this section, you will learn how to calibrate an unconstrained spatial interaction model by using glm() of Base Stats. The explanatory variables are origin population by different age cohort, destination population by different age cohort (i.e. ORIGIN_AGE25_64) and distance between origin and destination in km (i.e. dist).\nThe general formula of Unconstrained Spatial Interaction Model\n\nThe code chunk used to calibrate to model is shown below:\n\nuncSIM &lt;- glm(formula = TRIPS ~ \n                log(ORIGIN_AGE25_64) + \n                log(DESTIN_AGE25_64) +\n                log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nuncSIM\n\n\nCall:  glm(formula = TRIPS ~ log(ORIGIN_AGE25_64) + log(DESTIN_AGE25_64) + \n    log(dist), family = poisson(link = \"log\"), data = SIM_data, \n    na.action = na.exclude)\n\nCoefficients:\n         (Intercept)  log(ORIGIN_AGE25_64)  log(DESTIN_AGE25_64)  \n            17.00287               0.21001               0.01289  \n           log(dist)  \n            -1.51785  \n\nDegrees of Freedom: 14273 Total (i.e. Null);  14270 Residual\nNull Deviance:      36120000 \nResidual Deviance: 19960000     AIC: 20040000\n\n\n\n\n16.8.5 R-squared function\nIn order to measure how much variation of the trips can be accounted by the model we will write a function to calculate R-Squared value as shown below.\n\nCalcRSquared &lt;- function(observed,estimated){\n  r &lt;- cor(observed,estimated)\n  R2 &lt;- r^2\n  R2\n}\n\nNext, we will compute the R-squared of the unconstrained SIM by using the code chunk below.\n\nCalcRSquared(uncSIM$data$TRIPS, uncSIM$fitted.values)\n\n[1] 0.1694734\n\n\n\nr2_mcfadden(uncSIM)\n\n# R2 for Generalized Linear Regression\n       R2: 0.446\n  adj. R2: 0.446\n\n\n\n\n16.8.6 Origin (Production) constrained SIM\nIn this section, we will fit an origin constrained SIM by using the code3 chunk below.\nThe general formula of Origin Constrained Spatial Interaction Model\n\n\norcSIM &lt;- glm(formula = TRIPS ~ \n                 ORIGIN_SZ +\n                 log(DESTIN_AGE25_64) +\n                 log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(orcSIM)\n\n\nCall:\nglm(formula = TRIPS ~ ORIGIN_SZ + log(DESTIN_AGE25_64) + log(dist), \n    family = poisson(link = \"log\"), data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                       Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)          19.9309957  0.0054015  3689.887  &lt; 2e-16 ***\nORIGIN_SZAMSZ02       0.6805710  0.0052686   129.175  &lt; 2e-16 ***\nORIGIN_SZAMSZ03       0.3597850  0.0054884    65.554  &lt; 2e-16 ***\nORIGIN_SZAMSZ04      -0.1106566  0.0060027   -18.434  &lt; 2e-16 ***\nORIGIN_SZAMSZ05      -0.3140561  0.0067998   -46.186  &lt; 2e-16 ***\nORIGIN_SZAMSZ06       0.0634425  0.0060258    10.528  &lt; 2e-16 ***\nORIGIN_SZAMSZ07      -1.1301580  0.0110298  -102.464  &lt; 2e-16 ***\nORIGIN_SZAMSZ08      -0.6330394  0.0102949   -61.491  &lt; 2e-16 ***\nORIGIN_SZAMSZ09       0.1064915  0.0063450    16.784  &lt; 2e-16 ***\nORIGIN_SZAMSZ10       0.5061899  0.0053889    93.931  &lt; 2e-16 ***\nORIGIN_SZAMSZ11      -1.3167911  0.0144870   -90.895  &lt; 2e-16 ***\nORIGIN_SZAMSZ12      -1.5103004  0.0127453  -118.499  &lt; 2e-16 ***\nORIGIN_SZBDSZ01       1.3626004  0.0051433   264.929  &lt; 2e-16 ***\nORIGIN_SZBDSZ02       0.9554084  0.0059655   160.156  &lt; 2e-16 ***\nORIGIN_SZBDSZ03       1.1476190  0.0054278   211.433  &lt; 2e-16 ***\nORIGIN_SZBDSZ04       2.0110410  0.0046344   433.940  &lt; 2e-16 ***\nORIGIN_SZBDSZ05       1.0658940  0.0053976   197.477  &lt; 2e-16 ***\nORIGIN_SZBDSZ06       1.2719222  0.0054774   232.213  &lt; 2e-16 ***\nORIGIN_SZBDSZ07      -0.5053039  0.0111553   -45.297  &lt; 2e-16 ***\nORIGIN_SZBDSZ08      -0.3556193  0.0102947   -34.544  &lt; 2e-16 ***\nORIGIN_SZBKSZ01      -0.3606399  0.0075473   -47.784  &lt; 2e-16 ***\nORIGIN_SZBKSZ02       0.1357265  0.0061394    22.107  &lt; 2e-16 ***\nORIGIN_SZBKSZ03       0.4101999  0.0058983    69.545  &lt; 2e-16 ***\nORIGIN_SZBKSZ04      -0.3418645  0.0070764   -48.310  &lt; 2e-16 ***\nORIGIN_SZBKSZ05      -0.2986750  0.0074073   -40.322  &lt; 2e-16 ***\nORIGIN_SZBKSZ06      -0.2637855  0.0068739   -38.375  &lt; 2e-16 ***\nORIGIN_SZBKSZ07       0.5498323  0.0051476   106.813  &lt; 2e-16 ***\nORIGIN_SZBKSZ08      -0.0527393  0.0061457    -8.582  &lt; 2e-16 ***\nORIGIN_SZBKSZ09      -0.1564691  0.0067300   -23.249  &lt; 2e-16 ***\nORIGIN_SZBLSZ01      -1.7551329  0.0176599   -99.385  &lt; 2e-16 ***\nORIGIN_SZBLSZ02      -1.9493637  0.0213859   -91.152  &lt; 2e-16 ***\nORIGIN_SZBLSZ03      -2.9057732  0.0535995   -54.213  &lt; 2e-16 ***\nORIGIN_SZBLSZ04      -1.4672066  0.0254726   -57.599  &lt; 2e-16 ***\nORIGIN_SZBMSZ01       0.1806064  0.0060563    29.821  &lt; 2e-16 ***\nORIGIN_SZBMSZ02      -1.4026549  0.0078244  -179.267  &lt; 2e-16 ***\nORIGIN_SZBMSZ03      -0.5976236  0.0063808   -93.660  &lt; 2e-16 ***\nORIGIN_SZBMSZ04      -0.5456513  0.0059061   -92.388  &lt; 2e-16 ***\nORIGIN_SZBMSZ05      -3.1095195  0.0188118  -165.297  &lt; 2e-16 ***\nORIGIN_SZBMSZ06      -3.0273827  0.0194319  -155.794  &lt; 2e-16 ***\nORIGIN_SZBMSZ07      -0.7378197  0.0066865  -110.345  &lt; 2e-16 ***\nORIGIN_SZBMSZ08      -0.9306150  0.0067188  -138.510  &lt; 2e-16 ***\nORIGIN_SZBMSZ09      -1.4137345  0.0101071  -139.876  &lt; 2e-16 ***\nORIGIN_SZBMSZ10      -1.7054195  0.0101582  -167.886  &lt; 2e-16 ***\nORIGIN_SZBMSZ11      -1.2418380  0.0076792  -161.714  &lt; 2e-16 ***\nORIGIN_SZBMSZ12      -1.3746537  0.0109769  -125.231  &lt; 2e-16 ***\nORIGIN_SZBMSZ13      -0.4339494  0.0069335   -62.587  &lt; 2e-16 ***\nORIGIN_SZBMSZ14      -0.9950458  0.0076302  -130.410  &lt; 2e-16 ***\nORIGIN_SZBMSZ15      -0.6544196  0.0068964   -94.892  &lt; 2e-16 ***\nORIGIN_SZBMSZ16      -1.5193747  0.0105329  -144.250  &lt; 2e-16 ***\nORIGIN_SZBMSZ17      -1.6536771  0.0180672   -91.529  &lt; 2e-16 ***\nORIGIN_SZBPSZ01       0.1484355  0.0064734    22.930  &lt; 2e-16 ***\nORIGIN_SZBPSZ02      -0.3602094  0.0073902   -48.741  &lt; 2e-16 ***\nORIGIN_SZBPSZ03      -0.1567975  0.0072226   -21.709  &lt; 2e-16 ***\nORIGIN_SZBPSZ04       0.4504873  0.0058418    77.115  &lt; 2e-16 ***\nORIGIN_SZBPSZ05       0.5028646  0.0053682    93.675  &lt; 2e-16 ***\nORIGIN_SZBPSZ06      -1.0125668  0.0105638   -95.853  &lt; 2e-16 ***\nORIGIN_SZBPSZ07      -0.3859065  0.0098561   -39.154  &lt; 2e-16 ***\nORIGIN_SZBSSZ01       0.1488497  0.0065504    22.724  &lt; 2e-16 ***\nORIGIN_SZBSSZ02       0.4269498  0.0055893    76.387  &lt; 2e-16 ***\nORIGIN_SZBSSZ03      -0.2437385  0.0062020   -39.300  &lt; 2e-16 ***\nORIGIN_SZBTSZ01       0.1987940  0.0066672    29.817  &lt; 2e-16 ***\nORIGIN_SZBTSZ02      -0.4571546  0.0090784   -50.356  &lt; 2e-16 ***\nORIGIN_SZBTSZ03      -0.2697243  0.0077941   -34.606  &lt; 2e-16 ***\nORIGIN_SZBTSZ04      -1.0997236  0.0115225   -95.441  &lt; 2e-16 ***\nORIGIN_SZBTSZ05      -1.0053122  0.0132594   -75.819  &lt; 2e-16 ***\nORIGIN_SZBTSZ06      -1.0841201  0.0102242  -106.035  &lt; 2e-16 ***\nORIGIN_SZBTSZ07      -2.3134497  0.0158499  -145.960  &lt; 2e-16 ***\nORIGIN_SZBTSZ08      -1.1581618  0.0121161   -95.589  &lt; 2e-16 ***\nORIGIN_SZCBSZ01      -1.0805930  0.0577831   -18.701  &lt; 2e-16 ***\nORIGIN_SZCCSZ01      -0.8145372  0.0152638   -53.364  &lt; 2e-16 ***\nORIGIN_SZCHSZ01       0.0377079  0.0133240     2.830 0.004654 ** \nORIGIN_SZCHSZ02      -0.6209553  0.0096388   -64.422  &lt; 2e-16 ***\nORIGIN_SZCHSZ03       1.6790244  0.0069559   241.381  &lt; 2e-16 ***\nORIGIN_SZCKSZ01       0.0839586  0.0059934    14.008  &lt; 2e-16 ***\nORIGIN_SZCKSZ02       0.4379511  0.0062289    70.309  &lt; 2e-16 ***\nORIGIN_SZCKSZ03       0.7956950  0.0051892   153.335  &lt; 2e-16 ***\nORIGIN_SZCKSZ04       1.2740323  0.0053165   239.637  &lt; 2e-16 ***\nORIGIN_SZCKSZ05       0.9326213  0.0061807   150.893  &lt; 2e-16 ***\nORIGIN_SZCKSZ06       0.3976273  0.0085639    46.431  &lt; 2e-16 ***\nORIGIN_SZCLSZ01      -0.7522917  0.0094655   -79.477  &lt; 2e-16 ***\nORIGIN_SZCLSZ02      -1.3937450  0.0153260   -90.940  &lt; 2e-16 ***\nORIGIN_SZCLSZ03      -0.7898683  0.0091016   -86.784  &lt; 2e-16 ***\nORIGIN_SZCLSZ04       0.8451512  0.0051258   164.882  &lt; 2e-16 ***\nORIGIN_SZCLSZ05      -1.6573818  0.0166091   -99.788  &lt; 2e-16 ***\nORIGIN_SZCLSZ06       0.9478181  0.0048182   196.716  &lt; 2e-16 ***\nORIGIN_SZCLSZ07      -0.2499753  0.0064632   -38.677  &lt; 2e-16 ***\nORIGIN_SZCLSZ08       0.1350119  0.0069296    19.483  &lt; 2e-16 ***\nORIGIN_SZCLSZ09      -1.3868782  0.0192743   -71.955  &lt; 2e-16 ***\nORIGIN_SZDTSZ02      -3.7535792  0.0871325   -43.079  &lt; 2e-16 ***\nORIGIN_SZDTSZ03      -3.8462041  0.0840156   -45.780  &lt; 2e-16 ***\nORIGIN_SZDTSZ13      -2.9738127  0.0349241   -85.151  &lt; 2e-16 ***\nORIGIN_SZGLSZ01      -1.5175198  0.0110135  -137.787  &lt; 2e-16 ***\nORIGIN_SZGLSZ02       0.2405712  0.0058742    40.954  &lt; 2e-16 ***\nORIGIN_SZGLSZ03       0.1940241  0.0061989    31.300  &lt; 2e-16 ***\nORIGIN_SZGLSZ04       1.0292572  0.0049028   209.931  &lt; 2e-16 ***\nORIGIN_SZGLSZ05       0.9864552  0.0050898   193.811  &lt; 2e-16 ***\nORIGIN_SZHGSZ01       0.3073609  0.0054307    56.597  &lt; 2e-16 ***\nORIGIN_SZHGSZ02       0.3827293  0.0054555    70.154  &lt; 2e-16 ***\nORIGIN_SZHGSZ03       0.2342580  0.0059240    39.544  &lt; 2e-16 ***\nORIGIN_SZHGSZ04       0.8750090  0.0049639   176.275  &lt; 2e-16 ***\nORIGIN_SZHGSZ05       1.1695280  0.0049468   236.420  &lt; 2e-16 ***\nORIGIN_SZHGSZ06      -0.0462411  0.0063805    -7.247 4.25e-13 ***\nORIGIN_SZHGSZ07       0.4488583  0.0055139    81.404  &lt; 2e-16 ***\nORIGIN_SZHGSZ08       0.2236095  0.0061279    36.490  &lt; 2e-16 ***\nORIGIN_SZHGSZ09      -1.6376674  0.0084442  -193.941  &lt; 2e-16 ***\nORIGIN_SZHGSZ10      -2.9849025  0.0501042   -59.574  &lt; 2e-16 ***\nORIGIN_SZJESZ01       0.3926525  0.0056268    69.783  &lt; 2e-16 ***\nORIGIN_SZJESZ02       0.1230160  0.0056864    21.633  &lt; 2e-16 ***\nORIGIN_SZJESZ03       0.0188276  0.0061020     3.085 0.002032 ** \nORIGIN_SZJESZ04      -1.3611618  0.0117184  -116.156  &lt; 2e-16 ***\nORIGIN_SZJESZ05      -2.0643662  0.0157083  -131.419  &lt; 2e-16 ***\nORIGIN_SZJESZ06       0.1556368  0.0055245    28.172  &lt; 2e-16 ***\nORIGIN_SZJESZ07      -1.7664532  0.0133171  -132.646  &lt; 2e-16 ***\nORIGIN_SZJESZ08      -0.9115981  0.0138203   -65.961  &lt; 2e-16 ***\nORIGIN_SZJESZ09       0.6121916  0.0060381   101.388  &lt; 2e-16 ***\nORIGIN_SZJESZ10      -1.1953045  0.0233216   -51.253  &lt; 2e-16 ***\nORIGIN_SZJESZ11      -1.4088748  0.0220921   -63.773  &lt; 2e-16 ***\nORIGIN_SZJWSZ01       0.5759093  0.0077741    74.081  &lt; 2e-16 ***\nORIGIN_SZJWSZ02       0.9769314  0.0053029   184.227  &lt; 2e-16 ***\nORIGIN_SZJWSZ03       1.3242695  0.0049068   269.882  &lt; 2e-16 ***\nORIGIN_SZJWSZ04       0.5621088  0.0057831    97.199  &lt; 2e-16 ***\nORIGIN_SZJWSZ05      -1.5744341  0.0146904  -107.174  &lt; 2e-16 ***\nORIGIN_SZJWSZ06      -0.9113320  0.0126913   -71.807  &lt; 2e-16 ***\nORIGIN_SZJWSZ07      -2.3083419  0.0357843   -64.507  &lt; 2e-16 ***\nORIGIN_SZJWSZ08       2.0114225  0.0047956   419.429  &lt; 2e-16 ***\nORIGIN_SZJWSZ09       1.9086705  0.0045255   421.759  &lt; 2e-16 ***\nORIGIN_SZKLSZ01       0.2743166  0.0056908    48.204  &lt; 2e-16 ***\nORIGIN_SZKLSZ02      -0.6443386  0.0074521   -86.463  &lt; 2e-16 ***\nORIGIN_SZKLSZ03      -0.3990113  0.0067213   -59.366  &lt; 2e-16 ***\nORIGIN_SZKLSZ04      -2.1413876  0.0138405  -154.719  &lt; 2e-16 ***\nORIGIN_SZKLSZ05      -1.0913697  0.0121512   -89.816  &lt; 2e-16 ***\nORIGIN_SZKLSZ06      -5.6240764  0.1857405   -30.279  &lt; 2e-16 ***\nORIGIN_SZKLSZ07      -1.1885897  0.0096830  -122.750  &lt; 2e-16 ***\nORIGIN_SZKLSZ08      -1.7018593  0.0114317  -148.872  &lt; 2e-16 ***\nORIGIN_SZLKSZ01      -1.6659670  0.0446420   -37.318  &lt; 2e-16 ***\nORIGIN_SZMDSZ01      -1.1210505  0.0318834   -35.161  &lt; 2e-16 ***\nORIGIN_SZMDSZ02      -0.5096299  0.0116645   -43.691  &lt; 2e-16 ***\nORIGIN_SZMDSZ03      -1.9187039  0.0198291   -96.762  &lt; 2e-16 ***\nORIGIN_SZMPSZ01      -0.5260512  0.0094201   -55.844  &lt; 2e-16 ***\nORIGIN_SZMPSZ02      -0.2905084  0.0077974   -37.257  &lt; 2e-16 ***\nORIGIN_SZMPSZ03       0.3342293  0.0063715    52.457  &lt; 2e-16 ***\nORIGIN_SZMUSZ02      -3.8337096  0.1105053   -34.693  &lt; 2e-16 ***\nORIGIN_SZNTSZ01      -2.9845040  0.0397028   -75.171  &lt; 2e-16 ***\nORIGIN_SZNTSZ02      -3.1812985  0.0249470  -127.522  &lt; 2e-16 ***\nORIGIN_SZNTSZ03      -0.9742991  0.0085424  -114.054  &lt; 2e-16 ***\nORIGIN_SZNTSZ05      -4.2086932  0.0579737   -72.597  &lt; 2e-16 ***\nORIGIN_SZNTSZ06      -4.5831822  0.0583494   -78.547  &lt; 2e-16 ***\nORIGIN_SZNVSZ01       0.3186962  0.0052944    60.195  &lt; 2e-16 ***\nORIGIN_SZNVSZ02      -0.5321136  0.0073747   -72.154  &lt; 2e-16 ***\nORIGIN_SZNVSZ03      -0.9911852  0.0090560  -109.451  &lt; 2e-16 ***\nORIGIN_SZNVSZ04      -0.8329721  0.0099590   -83.640  &lt; 2e-16 ***\nORIGIN_SZNVSZ05      -2.1460777  0.0182401  -117.657  &lt; 2e-16 ***\nORIGIN_SZPGSZ01      -0.5604078  0.0151515   -36.987  &lt; 2e-16 ***\nORIGIN_SZPGSZ02      -0.4025139  0.0085135   -47.279  &lt; 2e-16 ***\nORIGIN_SZPGSZ03       0.6975483  0.0055534   125.608  &lt; 2e-16 ***\nORIGIN_SZPGSZ04       1.2175486  0.0051080   238.363  &lt; 2e-16 ***\nORIGIN_SZPGSZ05       0.3895354  0.0069851    55.767  &lt; 2e-16 ***\nORIGIN_SZPLSZ01      -0.5572701  0.0134473   -41.441  &lt; 2e-16 ***\nORIGIN_SZPLSZ02      -0.9854214  0.0172337   -57.180  &lt; 2e-16 ***\nORIGIN_SZPLSZ03      -1.6991954  0.0472629   -35.952  &lt; 2e-16 ***\nORIGIN_SZPLSZ04      -2.2000217  0.0373580   -58.890  &lt; 2e-16 ***\nORIGIN_SZPLSZ05      -1.7086663  0.0260920   -65.486  &lt; 2e-16 ***\nORIGIN_SZPNSZ01       1.5292867  0.0055102   277.535  &lt; 2e-16 ***\nORIGIN_SZPNSZ02       0.7457519  0.0127815    58.346  &lt; 2e-16 ***\nORIGIN_SZPNSZ03      -1.3659046  0.0216180   -63.184  &lt; 2e-16 ***\nORIGIN_SZPNSZ04      -2.0025379  0.0360655   -55.525  &lt; 2e-16 ***\nORIGIN_SZPNSZ05      -0.9157959  0.0320955   -28.533  &lt; 2e-16 ***\nORIGIN_SZPRSZ01       0.0522611  0.0139142     3.756 0.000173 ***\nORIGIN_SZPRSZ02       1.3063371  0.0053809   242.774  &lt; 2e-16 ***\nORIGIN_SZPRSZ03       0.9963670  0.0054293   183.516  &lt; 2e-16 ***\nORIGIN_SZPRSZ04      -0.0300950  0.0088010    -3.419 0.000627 ***\nORIGIN_SZPRSZ05       1.6840313  0.0050839   331.245  &lt; 2e-16 ***\nORIGIN_SZPRSZ06      -0.8277202  0.0131296   -63.042  &lt; 2e-16 ***\nORIGIN_SZPRSZ07      -2.1698449  0.0177362  -122.340  &lt; 2e-16 ***\nORIGIN_SZPRSZ08       0.4559353  0.0072609    62.793  &lt; 2e-16 ***\nORIGIN_SZQTSZ01      -0.3517047  0.0078770   -44.650  &lt; 2e-16 ***\nORIGIN_SZQTSZ02      -0.8199353  0.0071544  -114.605  &lt; 2e-16 ***\nORIGIN_SZQTSZ03      -0.2457614  0.0065555   -37.490  &lt; 2e-16 ***\nORIGIN_SZQTSZ04      -1.2216614  0.0084050  -145.349  &lt; 2e-16 ***\nORIGIN_SZQTSZ05      -0.7219952  0.0072360   -99.778  &lt; 2e-16 ***\nORIGIN_SZQTSZ06      -0.6729363  0.0076658   -87.784  &lt; 2e-16 ***\nORIGIN_SZQTSZ07      -1.4497690  0.0109365  -132.563  &lt; 2e-16 ***\nORIGIN_SZQTSZ08      -0.2770151  0.0070193   -39.465  &lt; 2e-16 ***\nORIGIN_SZQTSZ09      -0.6157554  0.0078739   -78.202  &lt; 2e-16 ***\nORIGIN_SZQTSZ10      -0.3091547  0.0075471   -40.963  &lt; 2e-16 ***\nORIGIN_SZQTSZ11      -1.9698881  0.0151247  -130.243  &lt; 2e-16 ***\nORIGIN_SZQTSZ12      -2.6449643  0.0205857  -128.485  &lt; 2e-16 ***\nORIGIN_SZQTSZ13      -0.3754107  0.0088433   -42.452  &lt; 2e-16 ***\nORIGIN_SZQTSZ14      -1.6537473  0.0134378  -123.067  &lt; 2e-16 ***\nORIGIN_SZQTSZ15      -0.3435351  0.0131956   -26.034  &lt; 2e-16 ***\nORIGIN_SZRCSZ01      -1.7104390  0.0141179  -121.154  &lt; 2e-16 ***\nORIGIN_SZRCSZ06      -1.1250727  0.0094909  -118.542  &lt; 2e-16 ***\nORIGIN_SZRVSZ01      -3.0220116  0.0339694   -88.963  &lt; 2e-16 ***\nORIGIN_SZRVSZ02      -3.6040075  0.0297641  -121.086  &lt; 2e-16 ***\nORIGIN_SZRVSZ03      -3.2345594  0.0259149  -124.814  &lt; 2e-16 ***\nORIGIN_SZRVSZ04      -3.6900313  0.0575908   -64.073  &lt; 2e-16 ***\nORIGIN_SZRVSZ05      -2.9527570  0.0178582  -165.344  &lt; 2e-16 ***\nORIGIN_SZSBSZ01       0.0238445  0.0078563     3.035 0.002405 ** \nORIGIN_SZSBSZ02      -0.5780602  0.0093054   -62.121  &lt; 2e-16 ***\nORIGIN_SZSBSZ03       0.8961719  0.0054586   164.175  &lt; 2e-16 ***\nORIGIN_SZSBSZ04       0.8421798  0.0061888   136.080  &lt; 2e-16 ***\nORIGIN_SZSBSZ05      -0.1682984  0.0078342   -21.482  &lt; 2e-16 ***\nORIGIN_SZSBSZ06      -1.1482701  0.0196421   -58.460  &lt; 2e-16 ***\nORIGIN_SZSBSZ07      -0.8830317  0.0160709   -54.946  &lt; 2e-16 ***\nORIGIN_SZSBSZ08      -1.1039492  0.0174602   -63.226  &lt; 2e-16 ***\nORIGIN_SZSBSZ09      -0.5946691  0.0101961   -58.323  &lt; 2e-16 ***\nORIGIN_SZSESZ02       1.1144933  0.0050948   218.749  &lt; 2e-16 ***\nORIGIN_SZSESZ03       1.1058963  0.0049026   225.574  &lt; 2e-16 ***\nORIGIN_SZSESZ04       0.7427975  0.0056948   130.433  &lt; 2e-16 ***\nORIGIN_SZSESZ05      -0.2812684  0.0069596   -40.414  &lt; 2e-16 ***\nORIGIN_SZSESZ06       0.8168315  0.0055800   146.387  &lt; 2e-16 ***\nORIGIN_SZSESZ07      -2.2842043  0.0231232   -98.784  &lt; 2e-16 ***\nORIGIN_SZSGSZ01      -0.7313790  0.0098957   -73.909  &lt; 2e-16 ***\nORIGIN_SZSGSZ02      -1.1185406  0.0110919  -100.843  &lt; 2e-16 ***\nORIGIN_SZSGSZ03       0.1752618  0.0060508    28.965  &lt; 2e-16 ***\nORIGIN_SZSGSZ04       0.3764395  0.0056165    67.023  &lt; 2e-16 ***\nORIGIN_SZSGSZ05      -1.7203916  0.0118945  -144.637  &lt; 2e-16 ***\nORIGIN_SZSGSZ06       0.4630857  0.0052886    87.563  &lt; 2e-16 ***\nORIGIN_SZSGSZ07      -0.7051233  0.0073133   -96.417  &lt; 2e-16 ***\nORIGIN_SZSKSZ01       0.2053928  0.0100710    20.395  &lt; 2e-16 ***\nORIGIN_SZSKSZ02       1.2630428  0.0063490   198.935  &lt; 2e-16 ***\nORIGIN_SZSKSZ03      -0.3035297  0.0096788   -31.360  &lt; 2e-16 ***\nORIGIN_SZSKSZ04      -1.7952886  0.0359225   -49.977  &lt; 2e-16 ***\nORIGIN_SZSKSZ05      -0.3836861  0.0176686   -21.716  &lt; 2e-16 ***\nORIGIN_SZSLSZ01      -2.5916326  0.0348001   -74.472  &lt; 2e-16 ***\nORIGIN_SZSLSZ04      -0.2251549  0.0088517   -25.436  &lt; 2e-16 ***\nORIGIN_SZSRSZ01      -2.9590365  0.0173638  -170.414  &lt; 2e-16 ***\nORIGIN_SZTHSZ01      -1.9639893  0.0570321   -34.437  &lt; 2e-16 ***\nORIGIN_SZTHSZ03      -1.7281304  0.0272797   -63.349  &lt; 2e-16 ***\nORIGIN_SZTHSZ04      -2.7837906  0.0343179   -81.118  &lt; 2e-16 ***\nORIGIN_SZTHSZ06      -2.1800693  0.0205491  -106.091  &lt; 2e-16 ***\nORIGIN_SZTMSZ01       0.8228136  0.0066824   123.131  &lt; 2e-16 ***\nORIGIN_SZTMSZ02       2.3174781  0.0044978   515.243  &lt; 2e-16 ***\nORIGIN_SZTMSZ03       1.7061757  0.0048615   350.957  &lt; 2e-16 ***\nORIGIN_SZTMSZ04       1.2407899  0.0058389   212.504  &lt; 2e-16 ***\nORIGIN_SZTMSZ05      -0.1000526  0.0124079    -8.064 7.41e-16 ***\nORIGIN_SZTNSZ01      -2.0347519  0.0139596  -145.760  &lt; 2e-16 ***\nORIGIN_SZTNSZ02      -1.8682671  0.0107901  -173.146  &lt; 2e-16 ***\nORIGIN_SZTNSZ03      -2.1737183  0.0146759  -148.115  &lt; 2e-16 ***\nORIGIN_SZTNSZ04      -0.5006452  0.0081501   -61.428  &lt; 2e-16 ***\nORIGIN_SZTPSZ01      -0.6722487  0.0075606   -88.914  &lt; 2e-16 ***\nORIGIN_SZTPSZ02       0.4552916  0.0050191    90.711  &lt; 2e-16 ***\nORIGIN_SZTPSZ03      -0.7865781  0.0072250  -108.869  &lt; 2e-16 ***\nORIGIN_SZTPSZ04      -0.7049044  0.0066456  -106.071  &lt; 2e-16 ***\nORIGIN_SZTPSZ05      -0.5574925  0.0070366   -79.227  &lt; 2e-16 ***\nORIGIN_SZTPSZ06      -0.4247282  0.0068709   -61.815  &lt; 2e-16 ***\nORIGIN_SZTPSZ07      -0.2846984  0.0071030   -40.081  &lt; 2e-16 ***\nORIGIN_SZTPSZ08      -1.0898051  0.0110046   -99.031  &lt; 2e-16 ***\nORIGIN_SZTPSZ09      -0.8092746  0.0079160  -102.232  &lt; 2e-16 ***\nORIGIN_SZTPSZ10      -0.9332072  0.0086809  -107.502  &lt; 2e-16 ***\nORIGIN_SZTPSZ11      -0.0421981  0.0064343    -6.558 5.44e-11 ***\nORIGIN_SZTPSZ12      -0.6330081  0.0078324   -80.819  &lt; 2e-16 ***\nORIGIN_SZTSSZ01      -1.7650409  0.0517357   -34.116  &lt; 2e-16 ***\nORIGIN_SZTSSZ02       1.1707267  0.0094178   124.310  &lt; 2e-16 ***\nORIGIN_SZTSSZ03       0.6581679  0.0095894    68.635  &lt; 2e-16 ***\nORIGIN_SZTSSZ04       0.8736493  0.0104965    83.233  &lt; 2e-16 ***\nORIGIN_SZTSSZ05       0.0957248  0.0178709     5.356 8.49e-08 ***\nORIGIN_SZTSSZ06       1.7581609  0.0206810    85.013  &lt; 2e-16 ***\nORIGIN_SZWCSZ01       0.8097950  0.0105622    76.669  &lt; 2e-16 ***\nORIGIN_SZWCSZ02      -1.9966163  0.0345747   -57.748  &lt; 2e-16 ***\nORIGIN_SZWCSZ03      -5.0687420  0.1474971   -34.365  &lt; 2e-16 ***\nORIGIN_SZWDSZ01       1.4926003  0.0047216   316.124  &lt; 2e-16 ***\nORIGIN_SZWDSZ02       0.9916597  0.0055755   177.859  &lt; 2e-16 ***\nORIGIN_SZWDSZ03       1.5918065  0.0052180   305.062  &lt; 2e-16 ***\nORIGIN_SZWDSZ04       1.3717152  0.0060516   226.669  &lt; 2e-16 ***\nORIGIN_SZWDSZ05       0.6700111  0.0062287   107.569  &lt; 2e-16 ***\nORIGIN_SZWDSZ06       0.8115996  0.0060947   133.165  &lt; 2e-16 ***\nORIGIN_SZWDSZ07      -0.6488914  0.0093567   -69.351  &lt; 2e-16 ***\nORIGIN_SZWDSZ08      -0.3610234  0.0096440   -37.435  &lt; 2e-16 ***\nORIGIN_SZWDSZ09       1.4445461  0.0052279   276.317  &lt; 2e-16 ***\nORIGIN_SZYSSZ01      -0.2039272  0.0069548   -29.322  &lt; 2e-16 ***\nORIGIN_SZYSSZ02       0.8707707  0.0058957   147.697  &lt; 2e-16 ***\nORIGIN_SZYSSZ03       1.8348842  0.0050377   364.231  &lt; 2e-16 ***\nORIGIN_SZYSSZ04       1.0780641  0.0052960   203.564  &lt; 2e-16 ***\nORIGIN_SZYSSZ05       0.3222765  0.0069700    46.237  &lt; 2e-16 ***\nORIGIN_SZYSSZ06      -0.4424689  0.0124866   -35.435  &lt; 2e-16 ***\nORIGIN_SZYSSZ07      -1.0267883  0.0155821   -65.895  &lt; 2e-16 ***\nORIGIN_SZYSSZ08       0.1833117  0.0070935    25.842  &lt; 2e-16 ***\nORIGIN_SZYSSZ09       1.0766070  0.0050451   213.396  &lt; 2e-16 ***\nlog(DESTIN_AGE25_64)  0.0295428  0.0001051   280.998  &lt; 2e-16 ***\nlog(dist)            -1.7024691  0.0004625 -3681.042  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 36117615  on 14273  degrees of freedom\nResidual deviance: 12983718  on 13993  degrees of freedom\nAIC: 13068835\n\nNumber of Fisher Scoring iterations: 6\n\n\nWe can examine how the constraints hold for destinations this time.\n\nCalcRSquared(orcSIM$data$TRIPS, orcSIM$fitted.values)\n\n[1] 0.4029115\n\n\n\n\n16.8.7 Destination constrained\nIn this section, we will fit a destination constrained SIM by using the code chunk below.\nThe general formula of Destination Constrained Spatial Interaction Model\n\n\ndecSIM &lt;- glm(formula = TRIPS ~ \n                DESTIN_SZ + \n                log(ORIGIN_AGE25_64) + \n                log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(decSIM)\n\n\nCall:\nglm(formula = TRIPS ~ DESTIN_SZ + log(ORIGIN_AGE25_64) + log(dist), \n    family = poisson(link = \"log\"), data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                       Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)          19.4822997  0.0050784  3836.298  &lt; 2e-16 ***\nDESTIN_SZAMSZ02       0.1263056  0.0049743    25.392  &lt; 2e-16 ***\nDESTIN_SZAMSZ03       0.0421788  0.0049859     8.460  &lt; 2e-16 ***\nDESTIN_SZAMSZ04      -1.1668479  0.0074254  -157.143  &lt; 2e-16 ***\nDESTIN_SZAMSZ05      -1.2586639  0.0075854  -165.931  &lt; 2e-16 ***\nDESTIN_SZAMSZ06      -1.1414791  0.0073474  -155.359  &lt; 2e-16 ***\nDESTIN_SZAMSZ07      -1.5565804  0.0109476  -142.185  &lt; 2e-16 ***\nDESTIN_SZAMSZ08      -0.3990754  0.0074159   -53.813  &lt; 2e-16 ***\nDESTIN_SZAMSZ09      -1.0109118  0.0076802  -131.626  &lt; 2e-16 ***\nDESTIN_SZAMSZ10       0.0159285  0.0051765     3.077  0.00209 ** \nDESTIN_SZAMSZ11      -0.3653273  0.0094866   -38.510  &lt; 2e-16 ***\nDESTIN_SZAMSZ12       0.5297606  0.0053243    99.500  &lt; 2e-16 ***\nDESTIN_SZBDSZ01       1.0394822  0.0044226   235.037  &lt; 2e-16 ***\nDESTIN_SZBDSZ02       0.1956964  0.0059564    32.855  &lt; 2e-16 ***\nDESTIN_SZBDSZ03       0.3209267  0.0053718    59.742  &lt; 2e-16 ***\nDESTIN_SZBDSZ04       1.2429874  0.0043104   288.370  &lt; 2e-16 ***\nDESTIN_SZBDSZ05       0.8535842  0.0046360   184.122  &lt; 2e-16 ***\nDESTIN_SZBDSZ06       0.5181443  0.0053736    96.423  &lt; 2e-16 ***\nDESTIN_SZBDSZ07      -0.5849371  0.0110468   -52.951  &lt; 2e-16 ***\nDESTIN_SZBDSZ08      -1.2871050  0.0128623  -100.068  &lt; 2e-16 ***\nDESTIN_SZBKSZ01      -1.0633560  0.0077771  -136.730  &lt; 2e-16 ***\nDESTIN_SZBKSZ02      -0.4065316  0.0066712   -60.938  &lt; 2e-16 ***\nDESTIN_SZBKSZ03      -0.6815674  0.0066509  -102.477  &lt; 2e-16 ***\nDESTIN_SZBKSZ04      -0.4185485  0.0058306   -71.785  &lt; 2e-16 ***\nDESTIN_SZBKSZ05      -0.8887654  0.0073867  -120.319  &lt; 2e-16 ***\nDESTIN_SZBKSZ06      -0.9436078  0.0068625  -137.501  &lt; 2e-16 ***\nDESTIN_SZBKSZ07      -0.0067325  0.0048408    -1.391  0.16430    \nDESTIN_SZBKSZ08      -1.2680903  0.0079177  -160.160  &lt; 2e-16 ***\nDESTIN_SZBKSZ09      -0.0350151  0.0054287    -6.450 1.12e-10 ***\nDESTIN_SZBLSZ01      -0.3045203  0.0081978   -37.146  &lt; 2e-16 ***\nDESTIN_SZBLSZ02       0.6432424  0.0074449    86.400  &lt; 2e-16 ***\nDESTIN_SZBLSZ03       1.9595113  0.0084705   231.333  &lt; 2e-16 ***\nDESTIN_SZBLSZ04       0.0149756  0.0172081     0.870  0.38415    \nDESTIN_SZBMSZ01      -0.0378127  0.0055294    -6.838 8.00e-12 ***\nDESTIN_SZBMSZ02      -0.8458055  0.0054043  -156.505  &lt; 2e-16 ***\nDESTIN_SZBMSZ03      -1.1334399  0.0063720  -177.878  &lt; 2e-16 ***\nDESTIN_SZBMSZ04      -1.1164759  0.0057743  -193.353  &lt; 2e-16 ***\nDESTIN_SZBMSZ05      -1.1078742  0.0078703  -140.766  &lt; 2e-16 ***\nDESTIN_SZBMSZ06      -2.2787234  0.0155126  -146.895  &lt; 2e-16 ***\nDESTIN_SZBMSZ07      -0.2739089  0.0051924   -52.752  &lt; 2e-16 ***\nDESTIN_SZBMSZ08      -1.6825978  0.0071842  -234.209  &lt; 2e-16 ***\nDESTIN_SZBMSZ09      -3.0047801  0.0159980  -187.823  &lt; 2e-16 ***\nDESTIN_SZBMSZ10      -2.2232689  0.0096907  -229.423  &lt; 2e-16 ***\nDESTIN_SZBMSZ11      -1.9657136  0.0086445  -227.394  &lt; 2e-16 ***\nDESTIN_SZBMSZ12      -1.5359286  0.0089658  -171.310  &lt; 2e-16 ***\nDESTIN_SZBMSZ13      -0.5657561  0.0059960   -94.355  &lt; 2e-16 ***\nDESTIN_SZBMSZ14      -1.6904858  0.0084858  -199.214  &lt; 2e-16 ***\nDESTIN_SZBMSZ15      -1.5268383  0.0079959  -190.953  &lt; 2e-16 ***\nDESTIN_SZBMSZ16      -2.2045600  0.0130872  -168.452  &lt; 2e-16 ***\nDESTIN_SZBMSZ17      -2.2992381  0.0184895  -124.353  &lt; 2e-16 ***\nDESTIN_SZBPSZ01      -0.8549497  0.0065168  -131.191  &lt; 2e-16 ***\nDESTIN_SZBPSZ02      -1.7470549  0.0095751  -182.457  &lt; 2e-16 ***\nDESTIN_SZBPSZ03      -1.4015145  0.0090888  -154.203  &lt; 2e-16 ***\nDESTIN_SZBPSZ04      -0.5250632  0.0066496   -78.962  &lt; 2e-16 ***\nDESTIN_SZBPSZ05       0.3413171  0.0046404    73.553  &lt; 2e-16 ***\nDESTIN_SZBPSZ06      -0.8569188  0.0090795   -94.380  &lt; 2e-16 ***\nDESTIN_SZBPSZ07      -0.0751284  0.0089704    -8.375  &lt; 2e-16 ***\nDESTIN_SZBSSZ01       0.1015228  0.0055735    18.215  &lt; 2e-16 ***\nDESTIN_SZBSSZ02      -0.7066412  0.0063845  -110.682  &lt; 2e-16 ***\nDESTIN_SZBSSZ03       0.1622730  0.0046689    34.756  &lt; 2e-16 ***\nDESTIN_SZBTSZ01       0.5470615  0.0047984   114.009  &lt; 2e-16 ***\nDESTIN_SZBTSZ02      -0.1393371  0.0078266   -17.803  &lt; 2e-16 ***\nDESTIN_SZBTSZ03       0.1474771  0.0059428    24.816  &lt; 2e-16 ***\nDESTIN_SZBTSZ04      -1.2857827  0.0122000  -105.392  &lt; 2e-16 ***\nDESTIN_SZBTSZ05      -0.2629188  0.0081769   -32.154  &lt; 2e-16 ***\nDESTIN_SZBTSZ06      -0.8319920  0.0081401  -102.209  &lt; 2e-16 ***\nDESTIN_SZBTSZ07      -1.8829448  0.0121227  -155.324  &lt; 2e-16 ***\nDESTIN_SZBTSZ08      -1.5732123  0.0116752  -134.748  &lt; 2e-16 ***\nDESTIN_SZCBSZ01      -3.5334327  0.3333510   -10.600  &lt; 2e-16 ***\nDESTIN_SZCCSZ01      -0.2129306  0.0093782   -22.705  &lt; 2e-16 ***\nDESTIN_SZCHSZ01      -0.1494972  0.0113078   -13.221  &lt; 2e-16 ***\nDESTIN_SZCHSZ02       0.0041774  0.0063195     0.661  0.50860    \nDESTIN_SZCHSZ03       2.5565450  0.0046495   549.857  &lt; 2e-16 ***\nDESTIN_SZCKSZ01       0.0489719  0.0053801     9.102  &lt; 2e-16 ***\nDESTIN_SZCKSZ02      -0.3548993  0.0060671   -58.496  &lt; 2e-16 ***\nDESTIN_SZCKSZ03       0.5386351  0.0044913   119.928  &lt; 2e-16 ***\nDESTIN_SZCKSZ04      -0.4425512  0.0073837   -59.936  &lt; 2e-16 ***\nDESTIN_SZCKSZ05      -0.4092591  0.0077267   -52.967  &lt; 2e-16 ***\nDESTIN_SZCKSZ06       0.2207041  0.0074252    29.724  &lt; 2e-16 ***\nDESTIN_SZCLSZ01       0.2851460  0.0052362    54.457  &lt; 2e-16 ***\nDESTIN_SZCLSZ02      -1.9270528  0.0147688  -130.482  &lt; 2e-16 ***\nDESTIN_SZCLSZ03      -0.6266521  0.0086780   -72.212  &lt; 2e-16 ***\nDESTIN_SZCLSZ04      -0.1335581  0.0054216   -24.634  &lt; 2e-16 ***\nDESTIN_SZCLSZ05      -0.8912963  0.0096015   -92.829  &lt; 2e-16 ***\nDESTIN_SZCLSZ06       0.1781234  0.0048150    36.993  &lt; 2e-16 ***\nDESTIN_SZCLSZ07      -0.5609619  0.0062277   -90.075  &lt; 2e-16 ***\nDESTIN_SZCLSZ08      -0.3875308  0.0068390   -56.665  &lt; 2e-16 ***\nDESTIN_SZCLSZ09       0.2539453  0.0072623    34.968  &lt; 2e-16 ***\nDESTIN_SZDTSZ02      -2.5036295  0.0373421   -67.046  &lt; 2e-16 ***\nDESTIN_SZDTSZ03      -0.8956407  0.0149971   -59.721  &lt; 2e-16 ***\nDESTIN_SZDTSZ13      -1.6562176  0.0175441   -94.403  &lt; 2e-16 ***\nDESTIN_SZGLSZ01      -0.2716152  0.0056553   -48.029  &lt; 2e-16 ***\nDESTIN_SZGLSZ02      -0.1735665  0.0055548   -31.246  &lt; 2e-16 ***\nDESTIN_SZGLSZ03       0.7029507  0.0044934   156.441  &lt; 2e-16 ***\nDESTIN_SZGLSZ04       0.5788027  0.0045449   127.351  &lt; 2e-16 ***\nDESTIN_SZGLSZ05       0.6865291  0.0045131   152.118  &lt; 2e-16 ***\nDESTIN_SZHGSZ01       0.3275950  0.0043866    74.681  &lt; 2e-16 ***\nDESTIN_SZHGSZ02      -0.6326974  0.0063517   -99.610  &lt; 2e-16 ***\nDESTIN_SZHGSZ03      -1.0597982  0.0073914  -143.382  &lt; 2e-16 ***\nDESTIN_SZHGSZ04      -0.2267013  0.0052178   -43.448  &lt; 2e-16 ***\nDESTIN_SZHGSZ05      -0.3063050  0.0055452   -55.238  &lt; 2e-16 ***\nDESTIN_SZHGSZ06      -0.7483961  0.0065544  -114.182  &lt; 2e-16 ***\nDESTIN_SZHGSZ07       0.1096958  0.0051309    21.379  &lt; 2e-16 ***\nDESTIN_SZHGSZ08      -0.1374201  0.0056692   -24.240  &lt; 2e-16 ***\nDESTIN_SZHGSZ09       0.0775400  0.0060230    12.874  &lt; 2e-16 ***\nDESTIN_SZHGSZ10      -3.3017475  0.0289292  -114.132  &lt; 2e-16 ***\nDESTIN_SZJESZ01      -0.0489065  0.0057246    -8.543  &lt; 2e-16 ***\nDESTIN_SZJESZ02      -0.5101614  0.0060074   -84.921  &lt; 2e-16 ***\nDESTIN_SZJESZ03      -0.5328921  0.0064129   -83.097  &lt; 2e-16 ***\nDESTIN_SZJESZ04      -0.7348953  0.0082249   -89.351  &lt; 2e-16 ***\nDESTIN_SZJESZ05      -1.0864570  0.0111740   -97.231  &lt; 2e-16 ***\nDESTIN_SZJESZ06       0.2407920  0.0046801    51.451  &lt; 2e-16 ***\nDESTIN_SZJESZ07      -1.1523093  0.0090103  -127.888  &lt; 2e-16 ***\nDESTIN_SZJESZ08      -0.4627356  0.0094529   -48.952  &lt; 2e-16 ***\nDESTIN_SZJESZ09       0.0528616  0.0068126     7.759 8.53e-15 ***\nDESTIN_SZJESZ10       1.0240660  0.0084045   121.848  &lt; 2e-16 ***\nDESTIN_SZJESZ11       0.7875517  0.0076251   103.284  &lt; 2e-16 ***\nDESTIN_SZJWSZ01      -0.1533418  0.0076198   -20.124  &lt; 2e-16 ***\nDESTIN_SZJWSZ02      -0.0011019  0.0059389    -0.186  0.85280    \nDESTIN_SZJWSZ03       0.9063789  0.0046747   193.892  &lt; 2e-16 ***\nDESTIN_SZJWSZ04       0.7019286  0.0049743   141.112  &lt; 2e-16 ***\nDESTIN_SZJWSZ05      -0.5197057  0.0072971   -71.220  &lt; 2e-16 ***\nDESTIN_SZJWSZ06       0.3350986  0.0061171    54.780  &lt; 2e-16 ***\nDESTIN_SZJWSZ07      -0.5961960  0.0328336   -18.158  &lt; 2e-16 ***\nDESTIN_SZJWSZ08       0.8054662  0.0056006   143.819  &lt; 2e-16 ***\nDESTIN_SZJWSZ09       1.5860146  0.0040282   393.723  &lt; 2e-16 ***\nDESTIN_SZKLSZ01      -0.6500838  0.0063560  -102.279  &lt; 2e-16 ***\nDESTIN_SZKLSZ02      -0.7039434  0.0064465  -109.197  &lt; 2e-16 ***\nDESTIN_SZKLSZ03      -1.1972384  0.0075577  -158.413  &lt; 2e-16 ***\nDESTIN_SZKLSZ04      -1.7172228  0.0097573  -175.993  &lt; 2e-16 ***\nDESTIN_SZKLSZ05      -0.6042386  0.0093730   -64.466  &lt; 2e-16 ***\nDESTIN_SZKLSZ06      -3.0201496  0.0389503   -77.539  &lt; 2e-16 ***\nDESTIN_SZKLSZ07      -1.1522413  0.0076607  -150.409  &lt; 2e-16 ***\nDESTIN_SZKLSZ08      -0.6977825  0.0057610  -121.122  &lt; 2e-16 ***\nDESTIN_SZLKSZ01      -0.6895952  0.0268661   -25.668  &lt; 2e-16 ***\nDESTIN_SZMDSZ01      -0.7155951  0.0228203   -31.358  &lt; 2e-16 ***\nDESTIN_SZMDSZ02      -0.8153643  0.0123003   -66.288  &lt; 2e-16 ***\nDESTIN_SZMDSZ03      -2.7745226  0.0301326   -92.077  &lt; 2e-16 ***\nDESTIN_SZMPSZ01      -0.5492095  0.0087198   -62.984  &lt; 2e-16 ***\nDESTIN_SZMPSZ02      -0.6104744  0.0069346   -88.033  &lt; 2e-16 ***\nDESTIN_SZMPSZ03       0.2775047  0.0054964    50.489  &lt; 2e-16 ***\nDESTIN_SZMUSZ02      -2.6322870  0.0214943  -122.464  &lt; 2e-16 ***\nDESTIN_SZNTSZ01      -4.0762008  0.0531046   -76.758  &lt; 2e-16 ***\nDESTIN_SZNTSZ02      -1.9765545  0.0125659  -157.296  &lt; 2e-16 ***\nDESTIN_SZNTSZ03      -1.4563069  0.0085433  -170.462  &lt; 2e-16 ***\nDESTIN_SZNTSZ05      -2.0125598  0.0270737   -74.336  &lt; 2e-16 ***\nDESTIN_SZNTSZ06      -3.0145357  0.0504986   -59.695  &lt; 2e-16 ***\nDESTIN_SZNVSZ01      -0.4693625  0.0053866   -87.135  &lt; 2e-16 ***\nDESTIN_SZNVSZ02      -0.4525631  0.0060428   -74.894  &lt; 2e-16 ***\nDESTIN_SZNVSZ03      -0.4821492  0.0064725   -74.492  &lt; 2e-16 ***\nDESTIN_SZNVSZ04      -1.8929756  0.0128397  -147.432  &lt; 2e-16 ***\nDESTIN_SZNVSZ05      -1.4501752  0.0099737  -145.400  &lt; 2e-16 ***\nDESTIN_SZPGSZ01      -1.2305867  0.0174321   -70.593  &lt; 2e-16 ***\nDESTIN_SZPGSZ02      -0.8232919  0.0080153  -102.715  &lt; 2e-16 ***\nDESTIN_SZPGSZ03       0.2138480  0.0050850    42.054  &lt; 2e-16 ***\nDESTIN_SZPGSZ04       0.1045757  0.0053579    19.518  &lt; 2e-16 ***\nDESTIN_SZPGSZ05      -0.7542450  0.0088883   -84.858  &lt; 2e-16 ***\nDESTIN_SZPLSZ01      -0.0098642  0.0080428    -1.226  0.22003    \nDESTIN_SZPLSZ02      -1.2630412  0.0152594   -82.771  &lt; 2e-16 ***\nDESTIN_SZPLSZ03      -0.1554479  0.0108611   -14.312  &lt; 2e-16 ***\nDESTIN_SZPLSZ04      -1.5505819  0.0114768  -135.105  &lt; 2e-16 ***\nDESTIN_SZPLSZ05      -0.2417805  0.0130391   -18.543  &lt; 2e-16 ***\nDESTIN_SZPNSZ01       0.7926715  0.0073628   107.659  &lt; 2e-16 ***\nDESTIN_SZPNSZ02       2.1914920  0.0073537   298.013  &lt; 2e-16 ***\nDESTIN_SZPNSZ03       1.0246845  0.0086874   117.951  &lt; 2e-16 ***\nDESTIN_SZPNSZ04       2.5522612  0.0091789   278.057  &lt; 2e-16 ***\nDESTIN_SZPNSZ05       1.7995301  0.0138562   129.872  &lt; 2e-16 ***\nDESTIN_SZPRSZ01      -0.6576686  0.0096037   -68.481  &lt; 2e-16 ***\nDESTIN_SZPRSZ02       0.3113532  0.0059851    52.021  &lt; 2e-16 ***\nDESTIN_SZPRSZ03       0.9255296  0.0044779   206.687  &lt; 2e-16 ***\nDESTIN_SZPRSZ04      -0.0028578  0.0093218    -0.307  0.75917    \nDESTIN_SZPRSZ05       0.2457863  0.0058261    42.187  &lt; 2e-16 ***\nDESTIN_SZPRSZ06       0.3692137  0.0064542    57.205  &lt; 2e-16 ***\nDESTIN_SZPRSZ07      -1.6733306  0.0138440  -120.871  &lt; 2e-16 ***\nDESTIN_SZPRSZ08      -0.2221048  0.0074846   -29.675  &lt; 2e-16 ***\nDESTIN_SZQTSZ01      -1.0185488  0.0093179  -109.311  &lt; 2e-16 ***\nDESTIN_SZQTSZ02      -1.2802688  0.0081670  -156.761  &lt; 2e-16 ***\nDESTIN_SZQTSZ03      -1.3322708  0.0079106  -168.415  &lt; 2e-16 ***\nDESTIN_SZQTSZ04      -1.1803631  0.0077366  -152.568  &lt; 2e-16 ***\nDESTIN_SZQTSZ05      -1.2215818  0.0072829  -167.734  &lt; 2e-16 ***\nDESTIN_SZQTSZ06      -1.3213145  0.0074858  -176.509  &lt; 2e-16 ***\nDESTIN_SZQTSZ07      -1.6426306  0.0123347  -133.171  &lt; 2e-16 ***\nDESTIN_SZQTSZ08      -0.2224169  0.0058405   -38.082  &lt; 2e-16 ***\nDESTIN_SZQTSZ09      -0.8142678  0.0069796  -116.665  &lt; 2e-16 ***\nDESTIN_SZQTSZ10      -0.1090496  0.0062573   -17.428  &lt; 2e-16 ***\nDESTIN_SZQTSZ11      -0.0108951  0.0061145    -1.782  0.07477 .  \nDESTIN_SZQTSZ12      -0.8582515  0.0090243   -95.105  &lt; 2e-16 ***\nDESTIN_SZQTSZ13       0.1834409  0.0065231    28.122  &lt; 2e-16 ***\nDESTIN_SZQTSZ14       0.1994454  0.0073615    27.093  &lt; 2e-16 ***\nDESTIN_SZQTSZ15       0.6740197  0.0088699    75.990  &lt; 2e-16 ***\nDESTIN_SZRCSZ01      -0.7746427  0.0079375   -97.593  &lt; 2e-16 ***\nDESTIN_SZRCSZ06      -1.4394098  0.0209931   -68.566  &lt; 2e-16 ***\nDESTIN_SZRVSZ01      -2.6060495  0.0175759  -148.274  &lt; 2e-16 ***\nDESTIN_SZRVSZ02      -2.5823769  0.0354706   -72.803  &lt; 2e-16 ***\nDESTIN_SZRVSZ03      -2.5890601  0.0152644  -169.614  &lt; 2e-16 ***\nDESTIN_SZRVSZ04      -2.2277482  0.0165661  -134.477  &lt; 2e-16 ***\nDESTIN_SZRVSZ05      -3.8610445  0.0298251  -129.456  &lt; 2e-16 ***\nDESTIN_SZSBSZ01      -1.2035529  0.0103954  -115.777  &lt; 2e-16 ***\nDESTIN_SZSBSZ02      -1.0267199  0.0085239  -120.452  &lt; 2e-16 ***\nDESTIN_SZSBSZ03       0.5977382  0.0050336   118.750  &lt; 2e-16 ***\nDESTIN_SZSBSZ04       0.5362769  0.0060573    88.534  &lt; 2e-16 ***\nDESTIN_SZSBSZ05      -1.0440525  0.0089622  -116.495  &lt; 2e-16 ***\nDESTIN_SZSBSZ06      -1.3939595  0.0246679   -56.509  &lt; 2e-16 ***\nDESTIN_SZSBSZ07       0.1029116  0.0235414     4.372 1.23e-05 ***\nDESTIN_SZSBSZ08       1.3564902  0.0060529   224.105  &lt; 2e-16 ***\nDESTIN_SZSBSZ09       0.4573712  0.0056585    80.829  &lt; 2e-16 ***\nDESTIN_SZSESZ02      -0.1553609  0.0056716   -27.393  &lt; 2e-16 ***\nDESTIN_SZSESZ03       0.5412776  0.0043801   123.576  &lt; 2e-16 ***\nDESTIN_SZSESZ04      -0.6382091  0.0065411   -97.568  &lt; 2e-16 ***\nDESTIN_SZSESZ05      -0.3332093  0.0055002   -60.581  &lt; 2e-16 ***\nDESTIN_SZSESZ06      -0.3085951  0.0072340   -42.659  &lt; 2e-16 ***\nDESTIN_SZSESZ07      -2.6237684  0.0245753  -106.764  &lt; 2e-16 ***\nDESTIN_SZSGSZ01      -0.1062372  0.0066634   -15.943  &lt; 2e-16 ***\nDESTIN_SZSGSZ02      -0.0475568  0.0058908    -8.073 6.85e-16 ***\nDESTIN_SZSGSZ03      -0.2118402  0.0055056   -38.477  &lt; 2e-16 ***\nDESTIN_SZSGSZ04      -0.1099618  0.0054841   -20.051  &lt; 2e-16 ***\nDESTIN_SZSGSZ05      -2.1556963  0.0113821  -189.394  &lt; 2e-16 ***\nDESTIN_SZSGSZ06       0.4416352  0.0043842   100.734  &lt; 2e-16 ***\nDESTIN_SZSGSZ07      -0.3949335  0.0059250   -66.655  &lt; 2e-16 ***\nDESTIN_SZSISZ01      -1.2847094  0.0288610   -44.514  &lt; 2e-16 ***\nDESTIN_SZSKSZ01       0.3089834  0.0082924    37.261  &lt; 2e-16 ***\nDESTIN_SZSKSZ02       1.4139309  0.0059981   235.729  &lt; 2e-16 ***\nDESTIN_SZSKSZ03       0.2427688  0.0067373    36.034  &lt; 2e-16 ***\nDESTIN_SZSKSZ04      -0.2527488  0.0161286   -15.671  &lt; 2e-16 ***\nDESTIN_SZSKSZ05       0.6046051  0.0122766    49.249  &lt; 2e-16 ***\nDESTIN_SZSLSZ01      -0.3927387  0.0099790   -39.356  &lt; 2e-16 ***\nDESTIN_SZSLSZ04      -0.5942110  0.0086225   -68.914  &lt; 2e-16 ***\nDESTIN_SZSRSZ01      -2.6855766  0.0138707  -193.615  &lt; 2e-16 ***\nDESTIN_SZTHSZ01      -3.2750084  0.0402668   -81.333  &lt; 2e-16 ***\nDESTIN_SZTHSZ03      -1.7964408  0.0261810   -68.616  &lt; 2e-16 ***\nDESTIN_SZTHSZ04      -2.6323994  0.0241831  -108.853  &lt; 2e-16 ***\nDESTIN_SZTHSZ06      -1.9444390  0.0166052  -117.098  &lt; 2e-16 ***\nDESTIN_SZTMSZ01       0.3856054  0.0063086    61.123  &lt; 2e-16 ***\nDESTIN_SZTMSZ02       1.8586526  0.0039229   473.790  &lt; 2e-16 ***\nDESTIN_SZTMSZ03       1.2601385  0.0044018   286.278  &lt; 2e-16 ***\nDESTIN_SZTMSZ04       1.5884327  0.0043362   366.316  &lt; 2e-16 ***\nDESTIN_SZTMSZ05       1.0377553  0.0063271   164.018  &lt; 2e-16 ***\nDESTIN_SZTNSZ01      -0.9954275  0.0080345  -123.895  &lt; 2e-16 ***\nDESTIN_SZTNSZ02      -2.1032696  0.0109228  -192.557  &lt; 2e-16 ***\nDESTIN_SZTNSZ03      -2.0044892  0.0129215  -155.128  &lt; 2e-16 ***\nDESTIN_SZTNSZ04      -0.9750326  0.0081677  -119.377  &lt; 2e-16 ***\nDESTIN_SZTPSZ01      -0.7788383  0.0068769  -113.254  &lt; 2e-16 ***\nDESTIN_SZTPSZ02       0.2866080  0.0042843    66.898  &lt; 2e-16 ***\nDESTIN_SZTPSZ03      -0.8749841  0.0065470  -133.646  &lt; 2e-16 ***\nDESTIN_SZTPSZ04      -1.6852792  0.0081488  -206.812  &lt; 2e-16 ***\nDESTIN_SZTPSZ05      -1.3721346  0.0068230  -201.104  &lt; 2e-16 ***\nDESTIN_SZTPSZ06      -0.7832133  0.0069164  -113.239  &lt; 2e-16 ***\nDESTIN_SZTPSZ07      -2.3109126  0.0130830  -176.635  &lt; 2e-16 ***\nDESTIN_SZTPSZ08      -1.6406531  0.0104897  -156.406  &lt; 2e-16 ***\nDESTIN_SZTPSZ09      -0.5636273  0.0076848   -73.343  &lt; 2e-16 ***\nDESTIN_SZTPSZ10      -1.5640843  0.0099984  -156.433  &lt; 2e-16 ***\nDESTIN_SZTPSZ11      -0.3700482  0.0059834   -61.846  &lt; 2e-16 ***\nDESTIN_SZTPSZ12      -0.8828228  0.0072302  -122.102  &lt; 2e-16 ***\nDESTIN_SZTSSZ01       0.3529526  0.0221887    15.907  &lt; 2e-16 ***\nDESTIN_SZTSSZ02       1.0265792  0.0153515    66.871  &lt; 2e-16 ***\nDESTIN_SZTSSZ03       1.9647347  0.0092388   212.662  &lt; 2e-16 ***\nDESTIN_SZTSSZ04       1.8649836  0.0089976   207.275  &lt; 2e-16 ***\nDESTIN_SZTSSZ05       2.8437058  0.0085738   331.673  &lt; 2e-16 ***\nDESTIN_SZTSSZ06       3.4238870  0.0161304   212.263  &lt; 2e-16 ***\nDESTIN_SZWCSZ01       2.9550693  0.0051690   571.689  &lt; 2e-16 ***\nDESTIN_SZWCSZ02      -0.8214103  0.0129213   -63.570  &lt; 2e-16 ***\nDESTIN_SZWCSZ03      -1.7393427  0.0347472   -50.057  &lt; 2e-16 ***\nDESTIN_SZWDSZ01       1.3424417  0.0039957   335.972  &lt; 2e-16 ***\nDESTIN_SZWDSZ02      -0.2103694  0.0068601   -30.666  &lt; 2e-16 ***\nDESTIN_SZWDSZ03       0.8268551  0.0051363   160.983  &lt; 2e-16 ***\nDESTIN_SZWDSZ04      -0.0643997  0.0079076    -8.144 3.82e-16 ***\nDESTIN_SZWDSZ05       0.0451985  0.0075732     5.968 2.40e-09 ***\nDESTIN_SZWDSZ06       0.6981330  0.0051936   134.423  &lt; 2e-16 ***\nDESTIN_SZWDSZ07      -0.0403233  0.0067749    -5.952 2.65e-09 ***\nDESTIN_SZWDSZ08       0.2850631  0.0069225    41.179  &lt; 2e-16 ***\nDESTIN_SZWDSZ09       1.3016106  0.0050365   258.433  &lt; 2e-16 ***\nDESTIN_SZYSSZ01       0.7598564  0.0044144   172.133  &lt; 2e-16 ***\nDESTIN_SZYSSZ02       0.2648061  0.0058239    45.469  &lt; 2e-16 ***\nDESTIN_SZYSSZ03      -0.0412163  0.0068337    -6.031 1.63e-09 ***\nDESTIN_SZYSSZ04      -0.0561054  0.0060829    -9.223  &lt; 2e-16 ***\nDESTIN_SZYSSZ05      -0.9970159  0.0121827   -81.839  &lt; 2e-16 ***\nDESTIN_SZYSSZ06      -1.3808376  0.0125738  -109.819  &lt; 2e-16 ***\nDESTIN_SZYSSZ07      -0.7128364  0.0165296   -43.125  &lt; 2e-16 ***\nDESTIN_SZYSSZ08       0.9409510  0.0045886   205.064  &lt; 2e-16 ***\nDESTIN_SZYSSZ09       0.3738436  0.0047971    77.930  &lt; 2e-16 ***\nlog(ORIGIN_AGE25_64)  0.1928847  0.0001667  1157.214  &lt; 2e-16 ***\nlog(dist)            -1.7828141  0.0004794 -3718.501  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 36117615  on 14273  degrees of freedom\nResidual deviance: 12319763  on 13992  degrees of freedom\nAIC: 12404881\n\nNumber of Fisher Scoring iterations: 7\n\n\nWe can examine how the constraints hold for destinations this time.\n\nCalcRSquared(decSIM$data$TRIPS, decSIM$fitted.values)\n\n[1] 0.496166\n\n\n\n\n16.8.8 Doubly constrained\nIn this section, we will fit a doubly constrained SIM by using the code chunk below.\nThe general formula of Doubly Constrained Spatial Interaction Model\n\n\ndbcSIM &lt;- glm(formula = TRIPS ~ \n                ORIGIN_SZ + \n                DESTIN_SZ + \n                log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(dbcSIM)\n\n\nCall:\nglm(formula = TRIPS ~ ORIGIN_SZ + DESTIN_SZ + log(dist), family = poisson(link = \"log\"), \n    data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                  Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)     21.9587595  0.0066831  3285.715  &lt; 2e-16 ***\nORIGIN_SZAMSZ02  0.4778050  0.0054127    88.275  &lt; 2e-16 ***\nORIGIN_SZAMSZ03  0.2895973  0.0055517    52.163  &lt; 2e-16 ***\nORIGIN_SZAMSZ04 -0.2628080  0.0060720   -43.282  &lt; 2e-16 ***\nORIGIN_SZAMSZ05 -0.2631404  0.0069008   -38.132  &lt; 2e-16 ***\nORIGIN_SZAMSZ06  0.1722337  0.0062028    27.767  &lt; 2e-16 ***\nORIGIN_SZAMSZ07 -0.9883200  0.0111224   -88.859  &lt; 2e-16 ***\nORIGIN_SZAMSZ08 -0.4052821  0.0104095   -38.934  &lt; 2e-16 ***\nORIGIN_SZAMSZ09  0.0356290  0.0064816     5.497 3.86e-08 ***\nORIGIN_SZAMSZ10  0.4815569  0.0055521    86.735  &lt; 2e-16 ***\nORIGIN_SZAMSZ11 -1.4440079  0.0146079   -98.851  &lt; 2e-16 ***\nORIGIN_SZAMSZ12 -1.7862677  0.0128071  -139.475  &lt; 2e-16 ***\nORIGIN_SZBDSZ01  0.8653749  0.0054381   159.132  &lt; 2e-16 ***\nORIGIN_SZBDSZ02  0.0841000  0.0062834    13.385  &lt; 2e-16 ***\nORIGIN_SZBDSZ03  0.3158343  0.0057510    54.918  &lt; 2e-16 ***\nORIGIN_SZBDSZ04  1.4556701  0.0049986   291.215  &lt; 2e-16 ***\nORIGIN_SZBDSZ05  0.6363125  0.0057193   111.257  &lt; 2e-16 ***\nORIGIN_SZBDSZ06  0.6749341  0.0058650   115.078  &lt; 2e-16 ***\nORIGIN_SZBDSZ07 -1.2176407  0.0113698  -107.095  &lt; 2e-16 ***\nORIGIN_SZBDSZ08 -0.9803580  0.0105604   -92.833  &lt; 2e-16 ***\nORIGIN_SZBKSZ01 -0.2919642  0.0080763   -36.151  &lt; 2e-16 ***\nORIGIN_SZBKSZ02  0.4609570  0.0067997    67.791  &lt; 2e-16 ***\nORIGIN_SZBKSZ03  0.6273448  0.0065989    95.068  &lt; 2e-16 ***\nORIGIN_SZBKSZ04 -0.2499063  0.0076555   -32.644  &lt; 2e-16 ***\nORIGIN_SZBKSZ05 -0.2628428  0.0078905   -33.311  &lt; 2e-16 ***\nORIGIN_SZBKSZ06 -0.2174034  0.0075134   -28.936  &lt; 2e-16 ***\nORIGIN_SZBKSZ07  0.7094093  0.0058574   121.114  &lt; 2e-16 ***\nORIGIN_SZBKSZ08 -0.1614362  0.0067626   -23.872  &lt; 2e-16 ***\nORIGIN_SZBKSZ09 -0.2739085  0.0072969   -37.537  &lt; 2e-16 ***\nORIGIN_SZBLSZ01 -2.4281074  0.0181172  -134.022  &lt; 2e-16 ***\nORIGIN_SZBLSZ02 -2.7305447  0.0219341  -124.489  &lt; 2e-16 ***\nORIGIN_SZBLSZ03 -3.3071431  0.0540398   -61.198  &lt; 2e-16 ***\nORIGIN_SZBLSZ04 -2.4550671  0.0263946   -93.014  &lt; 2e-16 ***\nORIGIN_SZBMSZ01  0.1198976  0.0065964    18.176  &lt; 2e-16 ***\nORIGIN_SZBMSZ02 -1.3908667  0.0083230  -167.112  &lt; 2e-16 ***\nORIGIN_SZBMSZ03 -0.6999122  0.0069754  -100.339  &lt; 2e-16 ***\nORIGIN_SZBMSZ04 -0.2691159  0.0066184   -40.662  &lt; 2e-16 ***\nORIGIN_SZBMSZ05 -2.6163780  0.0190989  -136.991  &lt; 2e-16 ***\nORIGIN_SZBMSZ06 -2.9729956  0.0197182  -150.774  &lt; 2e-16 ***\nORIGIN_SZBMSZ07 -0.7309916  0.0072407  -100.956  &lt; 2e-16 ***\nORIGIN_SZBMSZ08 -1.0019514  0.0073169  -136.936  &lt; 2e-16 ***\nORIGIN_SZBMSZ09 -1.3667460  0.0105325  -129.764  &lt; 2e-16 ***\nORIGIN_SZBMSZ10 -1.6907268  0.0106687  -158.476  &lt; 2e-16 ***\nORIGIN_SZBMSZ11 -1.2288802  0.0082919  -148.202  &lt; 2e-16 ***\nORIGIN_SZBMSZ12 -1.6517767  0.0115101  -143.507  &lt; 2e-16 ***\nORIGIN_SZBMSZ13 -0.7251351  0.0075289   -96.314  &lt; 2e-16 ***\nORIGIN_SZBMSZ14 -1.1534912  0.0082629  -139.599  &lt; 2e-16 ***\nORIGIN_SZBMSZ15 -0.5476774  0.0075710   -72.339  &lt; 2e-16 ***\nORIGIN_SZBMSZ16 -1.5195034  0.0111459  -136.329  &lt; 2e-16 ***\nORIGIN_SZBMSZ17 -1.6026767  0.0184419   -86.904  &lt; 2e-16 ***\nORIGIN_SZBPSZ01  0.5571291  0.0071866    77.523  &lt; 2e-16 ***\nORIGIN_SZBPSZ02  0.0523197  0.0082259     6.360 2.01e-10 ***\nORIGIN_SZBPSZ03  0.2942047  0.0080482    36.555  &lt; 2e-16 ***\nORIGIN_SZBPSZ04  0.6246296  0.0065878    94.816  &lt; 2e-16 ***\nORIGIN_SZBPSZ05  0.8663708  0.0060852   142.372  &lt; 2e-16 ***\nORIGIN_SZBPSZ06 -0.9896182  0.0109551   -90.334  &lt; 2e-16 ***\nORIGIN_SZBPSZ07 -0.5219250  0.0101830   -51.255  &lt; 2e-16 ***\nORIGIN_SZBSSZ01  0.3299588  0.0066440    49.663  &lt; 2e-16 ***\nORIGIN_SZBSSZ02  0.2851357  0.0057077    49.956  &lt; 2e-16 ***\nORIGIN_SZBSSZ03 -0.2084740  0.0063364   -32.901  &lt; 2e-16 ***\nORIGIN_SZBTSZ01  0.1425664  0.0071103    20.051  &lt; 2e-16 ***\nORIGIN_SZBTSZ02 -0.5591999  0.0093616   -59.733  &lt; 2e-16 ***\nORIGIN_SZBTSZ03 -0.3648190  0.0081677   -44.666  &lt; 2e-16 ***\nORIGIN_SZBTSZ04 -1.4555078  0.0120138  -121.152  &lt; 2e-16 ***\nORIGIN_SZBTSZ05 -0.8635510  0.0133848   -64.517  &lt; 2e-16 ***\nORIGIN_SZBTSZ06 -1.1383111  0.0106421  -106.963  &lt; 2e-16 ***\nORIGIN_SZBTSZ07 -2.3477669  0.0160858  -145.953  &lt; 2e-16 ***\nORIGIN_SZBTSZ08 -1.2918779  0.0124862  -103.464  &lt; 2e-16 ***\nORIGIN_SZCBSZ01 -3.3713588  0.0578683   -58.259  &lt; 2e-16 ***\nORIGIN_SZCCSZ01 -0.6029242  0.0153385   -39.308  &lt; 2e-16 ***\nORIGIN_SZCHSZ01 -0.7641380  0.0135100   -56.561  &lt; 2e-16 ***\nORIGIN_SZCHSZ02 -0.8400736  0.0101951   -82.400  &lt; 2e-16 ***\nORIGIN_SZCHSZ03  1.2753127  0.0072576   175.720  &lt; 2e-16 ***\nORIGIN_SZCKSZ01  0.2470943  0.0067135    36.806  &lt; 2e-16 ***\nORIGIN_SZCKSZ02  0.5793581  0.0070498    82.181  &lt; 2e-16 ***\nORIGIN_SZCKSZ03  1.0795767  0.0060642   178.025  &lt; 2e-16 ***\nORIGIN_SZCKSZ04  1.4947920  0.0063122   236.808  &lt; 2e-16 ***\nORIGIN_SZCKSZ05  0.7457580  0.0074071   100.681  &lt; 2e-16 ***\nORIGIN_SZCKSZ06  0.5760952  0.0094861    60.730  &lt; 2e-16 ***\nORIGIN_SZCLSZ01 -0.9061335  0.0098617   -91.884  &lt; 2e-16 ***\nORIGIN_SZCLSZ02 -1.7609479  0.0156124  -112.791  &lt; 2e-16 ***\nORIGIN_SZCLSZ03 -1.0081325  0.0095171  -105.929  &lt; 2e-16 ***\nORIGIN_SZCLSZ04  0.6181200  0.0057953   106.659  &lt; 2e-16 ***\nORIGIN_SZCLSZ05 -2.0462335  0.0168934  -121.127  &lt; 2e-16 ***\nORIGIN_SZCLSZ06  0.7902389  0.0055680   141.924  &lt; 2e-16 ***\nORIGIN_SZCLSZ07 -0.5472929  0.0071001   -77.082  &lt; 2e-16 ***\nORIGIN_SZCLSZ08 -0.2197650  0.0077460   -28.372  &lt; 2e-16 ***\nORIGIN_SZCLSZ09 -1.8175782  0.0195989   -92.739  &lt; 2e-16 ***\nORIGIN_SZDTSZ02 -3.7618796  0.0872098   -43.136  &lt; 2e-16 ***\nORIGIN_SZDTSZ03 -3.4514766  0.0840812   -41.049  &lt; 2e-16 ***\nORIGIN_SZDTSZ13 -3.0627578  0.0352485   -86.891  &lt; 2e-16 ***\nORIGIN_SZGLSZ01 -1.8055929  0.0111938  -161.303  &lt; 2e-16 ***\nORIGIN_SZGLSZ02 -0.1588829  0.0061413   -25.871  &lt; 2e-16 ***\nORIGIN_SZGLSZ03 -0.2508524  0.0064276   -39.027  &lt; 2e-16 ***\nORIGIN_SZGLSZ04  0.8819358  0.0051993   169.627  &lt; 2e-16 ***\nORIGIN_SZGLSZ05  0.6062778  0.0053735   112.828  &lt; 2e-16 ***\nORIGIN_SZHGSZ01  0.3841503  0.0056776    67.660  &lt; 2e-16 ***\nORIGIN_SZHGSZ02  0.3962330  0.0057579    68.815  &lt; 2e-16 ***\nORIGIN_SZHGSZ03  0.2159531  0.0061671    35.017  &lt; 2e-16 ***\nORIGIN_SZHGSZ04  0.7831941  0.0052216   149.992  &lt; 2e-16 ***\nORIGIN_SZHGSZ05  1.1741558  0.0051799   226.677  &lt; 2e-16 ***\nORIGIN_SZHGSZ06 -0.1891403  0.0065556   -28.852  &lt; 2e-16 ***\nORIGIN_SZHGSZ07  0.3105421  0.0057186    54.304  &lt; 2e-16 ***\nORIGIN_SZHGSZ08 -0.0766364  0.0063474   -12.074  &lt; 2e-16 ***\nORIGIN_SZHGSZ09 -1.2211107  0.0101434  -120.384  &lt; 2e-16 ***\nORIGIN_SZHGSZ10 -3.4844709  0.0504793   -69.028  &lt; 2e-16 ***\nORIGIN_SZJESZ01  0.4916496  0.0063444    77.493  &lt; 2e-16 ***\nORIGIN_SZJESZ02  0.1343893  0.0063762    21.077  &lt; 2e-16 ***\nORIGIN_SZJESZ03 -0.2761723  0.0068085   -40.563  &lt; 2e-16 ***\nORIGIN_SZJESZ04 -1.5932744  0.0121402  -131.240  &lt; 2e-16 ***\nORIGIN_SZJESZ05 -2.3041311  0.0160245  -143.788  &lt; 2e-16 ***\nORIGIN_SZJESZ06  0.2811076  0.0062495    44.981  &lt; 2e-16 ***\nORIGIN_SZJESZ07 -1.9413956  0.0136276  -142.461  &lt; 2e-16 ***\nORIGIN_SZJESZ08 -1.3315645  0.0143168   -93.007  &lt; 2e-16 ***\nORIGIN_SZJESZ09  0.4418314  0.0069208    63.841  &lt; 2e-16 ***\nORIGIN_SZJESZ10 -1.5551555  0.0236523   -65.751  &lt; 2e-16 ***\nORIGIN_SZJESZ11 -1.8888230  0.0224630   -84.086  &lt; 2e-16 ***\nORIGIN_SZJWSZ01  0.2564586  0.0084699    30.279  &lt; 2e-16 ***\nORIGIN_SZJWSZ02  0.6899398  0.0061751   111.729  &lt; 2e-16 ***\nORIGIN_SZJWSZ03  1.4761229  0.0057392   257.198  &lt; 2e-16 ***\nORIGIN_SZJWSZ04  0.5701272  0.0065749    86.713  &lt; 2e-16 ***\nORIGIN_SZJWSZ05 -2.1253657  0.0150769  -140.968  &lt; 2e-16 ***\nORIGIN_SZJWSZ06 -1.5307265  0.0131906  -116.047  &lt; 2e-16 ***\nORIGIN_SZJWSZ07 -2.8801618  0.0360772   -79.833  &lt; 2e-16 ***\nORIGIN_SZJWSZ08  1.4428820  0.0059638   241.938  &lt; 2e-16 ***\nORIGIN_SZJWSZ09  1.8968475  0.0055649   340.860  &lt; 2e-16 ***\nORIGIN_SZKLSZ01  0.1116580  0.0059844    18.658  &lt; 2e-16 ***\nORIGIN_SZKLSZ02 -0.9618787  0.0077344  -124.364  &lt; 2e-16 ***\nORIGIN_SZKLSZ03 -0.7070626  0.0070275  -100.613  &lt; 2e-16 ***\nORIGIN_SZKLSZ04 -2.2742765  0.0139991  -162.459  &lt; 2e-16 ***\nORIGIN_SZKLSZ05 -1.1907262  0.0123719   -96.244  &lt; 2e-16 ***\nORIGIN_SZKLSZ06 -5.9774897  0.1857994   -32.172  &lt; 2e-16 ***\nORIGIN_SZKLSZ07 -1.4258369  0.0103083  -138.320  &lt; 2e-16 ***\nORIGIN_SZKLSZ08 -1.7625888  0.0116107  -151.808  &lt; 2e-16 ***\nORIGIN_SZLKSZ01 -2.0541388  0.0448216   -45.829  &lt; 2e-16 ***\nORIGIN_SZMDSZ01 -0.8571117  0.0321054   -26.697  &lt; 2e-16 ***\nORIGIN_SZMDSZ02 -0.6034597  0.0120724   -49.987  &lt; 2e-16 ***\nORIGIN_SZMDSZ03 -2.1681163  0.0201078  -107.825  &lt; 2e-16 ***\nORIGIN_SZMPSZ01 -0.9331562  0.0096218   -96.984  &lt; 2e-16 ***\nORIGIN_SZMPSZ02 -1.0268229  0.0081379  -126.178  &lt; 2e-16 ***\nORIGIN_SZMPSZ03  0.0054001  0.0066875     0.807 0.419385    \nORIGIN_SZMUSZ02 -3.6269863  0.1105492   -32.809  &lt; 2e-16 ***\nORIGIN_SZNTSZ01 -3.0593717  0.0399843   -76.514  &lt; 2e-16 ***\nORIGIN_SZNTSZ02 -3.3331415  0.0251754  -132.397  &lt; 2e-16 ***\nORIGIN_SZNTSZ03 -0.8351522  0.0090372   -92.413  &lt; 2e-16 ***\nORIGIN_SZNTSZ05 -4.2082472  0.0583343   -72.140  &lt; 2e-16 ***\nORIGIN_SZNTSZ06 -3.8549296  0.0593793   -64.920  &lt; 2e-16 ***\nORIGIN_SZNVSZ01  0.2789069  0.0056024    49.784  &lt; 2e-16 ***\nORIGIN_SZNVSZ02 -0.6036857  0.0077126   -78.273  &lt; 2e-16 ***\nORIGIN_SZNVSZ03 -1.0072683  0.0092678  -108.685  &lt; 2e-16 ***\nORIGIN_SZNVSZ04 -0.8723996  0.0101399   -86.037  &lt; 2e-16 ***\nORIGIN_SZNVSZ05 -2.1552928  0.0183064  -117.734  &lt; 2e-16 ***\nORIGIN_SZPGSZ01  0.0520607  0.0157846     3.298 0.000973 ***\nORIGIN_SZPGSZ02 -0.3481687  0.0089328   -38.976  &lt; 2e-16 ***\nORIGIN_SZPGSZ03  0.9095292  0.0058835   154.590  &lt; 2e-16 ***\nORIGIN_SZPGSZ04  1.3653717  0.0054727   249.489  &lt; 2e-16 ***\nORIGIN_SZPGSZ05  0.3762720  0.0073841    50.957  &lt; 2e-16 ***\nORIGIN_SZPLSZ01 -0.9142754  0.0136552   -66.954  &lt; 2e-16 ***\nORIGIN_SZPLSZ02 -1.0987582  0.0175891   -62.468  &lt; 2e-16 ***\nORIGIN_SZPLSZ03 -2.3427113  0.0474176   -49.406  &lt; 2e-16 ***\nORIGIN_SZPLSZ04 -2.9140779  0.0374458   -77.821  &lt; 2e-16 ***\nORIGIN_SZPLSZ05 -2.2381965  0.0261572   -85.567  &lt; 2e-16 ***\nORIGIN_SZPNSZ01  0.9659006  0.0075177   128.484  &lt; 2e-16 ***\nORIGIN_SZPNSZ02 -0.0158348  0.0143869    -1.101 0.271053    \nORIGIN_SZPNSZ03 -2.1837321  0.0224396   -97.316  &lt; 2e-16 ***\nORIGIN_SZPNSZ04 -3.2481509  0.0370762   -87.608  &lt; 2e-16 ***\nORIGIN_SZPNSZ05 -2.0450679  0.0328165   -62.318  &lt; 2e-16 ***\nORIGIN_SZPRSZ01 -0.6701245  0.0141567   -47.336  &lt; 2e-16 ***\nORIGIN_SZPRSZ02  0.7931907  0.0058079   136.570  &lt; 2e-16 ***\nORIGIN_SZPRSZ03  0.4249094  0.0058610    72.498  &lt; 2e-16 ***\nORIGIN_SZPRSZ04 -0.8529967  0.0090997   -93.739  &lt; 2e-16 ***\nORIGIN_SZPRSZ05  0.7865479  0.0055282   142.278  &lt; 2e-16 ***\nORIGIN_SZPRSZ06 -1.3303664  0.0134512   -98.903  &lt; 2e-16 ***\nORIGIN_SZPRSZ07 -3.0458370  0.0181514  -167.802  &lt; 2e-16 ***\nORIGIN_SZPRSZ08 -0.5342399  0.0075966   -70.327  &lt; 2e-16 ***\nORIGIN_SZQTSZ01 -0.2548930  0.0086485   -29.473  &lt; 2e-16 ***\nORIGIN_SZQTSZ02 -0.8662439  0.0076549  -113.162  &lt; 2e-16 ***\nORIGIN_SZQTSZ03 -0.0890168  0.0072455   -12.286  &lt; 2e-16 ***\nORIGIN_SZQTSZ04 -1.4634370  0.0089384  -163.724  &lt; 2e-16 ***\nORIGIN_SZQTSZ05 -0.6535669  0.0077612   -84.210  &lt; 2e-16 ***\nORIGIN_SZQTSZ06 -0.8275765  0.0081835  -101.128  &lt; 2e-16 ***\nORIGIN_SZQTSZ07 -1.5369800  0.0112808  -136.248  &lt; 2e-16 ***\nORIGIN_SZQTSZ08 -0.4437979  0.0075302   -58.936  &lt; 2e-16 ***\nORIGIN_SZQTSZ09 -0.8184934  0.0083589   -97.918  &lt; 2e-16 ***\nORIGIN_SZQTSZ10 -0.6906597  0.0080980   -85.288  &lt; 2e-16 ***\nORIGIN_SZQTSZ11 -2.3251162  0.0154191  -150.795  &lt; 2e-16 ***\nORIGIN_SZQTSZ12 -3.0442790  0.0208985  -145.670  &lt; 2e-16 ***\nORIGIN_SZQTSZ13 -0.7241013  0.0093441   -77.493  &lt; 2e-16 ***\nORIGIN_SZQTSZ14 -1.8225351  0.0138207  -131.870  &lt; 2e-16 ***\nORIGIN_SZQTSZ15 -0.8720806  0.0138589   -62.926  &lt; 2e-16 ***\nORIGIN_SZRCSZ01 -1.8063415  0.0144295  -125.184  &lt; 2e-16 ***\nORIGIN_SZRCSZ06 -0.5370905  0.0101573   -52.877  &lt; 2e-16 ***\nORIGIN_SZRVSZ01 -2.7426167  0.0341386   -80.338  &lt; 2e-16 ***\nORIGIN_SZRVSZ02 -3.0827269  0.0302299  -101.976  &lt; 2e-16 ***\nORIGIN_SZRVSZ03 -2.9133853  0.0262543  -110.968  &lt; 2e-16 ***\nORIGIN_SZRVSZ04 -3.4220022  0.0582209   -58.776  &lt; 2e-16 ***\nORIGIN_SZRVSZ05 -2.6206257  0.0197470  -132.710  &lt; 2e-16 ***\nORIGIN_SZSBSZ01  0.1010337  0.0085117    11.870  &lt; 2e-16 ***\nORIGIN_SZSBSZ02 -0.8810456  0.0098244   -89.680  &lt; 2e-16 ***\nORIGIN_SZSBSZ03  0.8303668  0.0063009   131.785  &lt; 2e-16 ***\nORIGIN_SZSBSZ04  0.3489128  0.0071456    48.829  &lt; 2e-16 ***\nORIGIN_SZSBSZ05 -0.3182914  0.0085560   -37.201  &lt; 2e-16 ***\nORIGIN_SZSBSZ06 -0.9074308  0.0200035   -45.364  &lt; 2e-16 ***\nORIGIN_SZSBSZ07 -0.2217124  0.0167188   -13.261  &lt; 2e-16 ***\nORIGIN_SZSBSZ08 -1.3007367  0.0178771   -72.760  &lt; 2e-16 ***\nORIGIN_SZSBSZ09 -0.9813703  0.0107885   -90.965  &lt; 2e-16 ***\nORIGIN_SZSESZ02  1.1283424  0.0054209   208.146  &lt; 2e-16 ***\nORIGIN_SZSESZ03  1.2389996  0.0051926   238.610  &lt; 2e-16 ***\nORIGIN_SZSESZ04  0.7535119  0.0060371   124.814  &lt; 2e-16 ***\nORIGIN_SZSESZ05 -0.2347978  0.0071482   -32.847  &lt; 2e-16 ***\nORIGIN_SZSESZ06  0.9520620  0.0057572   165.368  &lt; 2e-16 ***\nORIGIN_SZSESZ07 -2.4296685  0.0231677  -104.873  &lt; 2e-16 ***\nORIGIN_SZSGSZ01 -0.6995899  0.0099969   -69.980  &lt; 2e-16 ***\nORIGIN_SZSGSZ02 -1.2602157  0.0111471  -113.053  &lt; 2e-16 ***\nORIGIN_SZSGSZ03  0.0725860  0.0061970    11.713  &lt; 2e-16 ***\nORIGIN_SZSGSZ04  0.2738315  0.0057524    47.603  &lt; 2e-16 ***\nORIGIN_SZSGSZ05 -2.0207710  0.0119838  -168.625  &lt; 2e-16 ***\nORIGIN_SZSGSZ06  0.4885608  0.0054646    89.404  &lt; 2e-16 ***\nORIGIN_SZSGSZ07 -0.8892155  0.0075074  -118.445  &lt; 2e-16 ***\nORIGIN_SZSKSZ01 -0.3682754  0.0108025   -34.092  &lt; 2e-16 ***\nORIGIN_SZSKSZ02  1.1826086  0.0071388   165.659  &lt; 2e-16 ***\nORIGIN_SZSKSZ03 -0.3230177  0.0101683   -31.767  &lt; 2e-16 ***\nORIGIN_SZSKSZ04 -1.8504236  0.0362400   -51.060  &lt; 2e-16 ***\nORIGIN_SZSKSZ05 -0.2759035  0.0185157   -14.901  &lt; 2e-16 ***\nORIGIN_SZSLSZ01 -2.2757902  0.0348766   -65.253  &lt; 2e-16 ***\nORIGIN_SZSLSZ04 -0.0899820  0.0090356    -9.959  &lt; 2e-16 ***\nORIGIN_SZSRSZ01 -2.1460151  0.0187871  -114.228  &lt; 2e-16 ***\nORIGIN_SZTHSZ01 -2.6851549  0.0571841   -46.956  &lt; 2e-16 ***\nORIGIN_SZTHSZ03 -1.0121495  0.0275551   -36.732  &lt; 2e-16 ***\nORIGIN_SZTHSZ04 -2.6129645  0.0345167   -75.701  &lt; 2e-16 ***\nORIGIN_SZTHSZ06 -1.7229100  0.0208134   -82.779  &lt; 2e-16 ***\nORIGIN_SZTMSZ01 -0.2254986  0.0070312   -32.071  &lt; 2e-16 ***\nORIGIN_SZTMSZ02  1.7271575  0.0049219   350.914  &lt; 2e-16 ***\nORIGIN_SZTMSZ03  0.9891319  0.0052266   189.250  &lt; 2e-16 ***\nORIGIN_SZTMSZ04  0.2018090  0.0062114    32.490  &lt; 2e-16 ***\nORIGIN_SZTMSZ05 -1.1882870  0.0125842   -94.427  &lt; 2e-16 ***\nORIGIN_SZTNSZ01 -1.6122620  0.0141911  -113.611  &lt; 2e-16 ***\nORIGIN_SZTNSZ02 -1.5630967  0.0112227  -139.280  &lt; 2e-16 ***\nORIGIN_SZTNSZ03 -2.0739538  0.0149298  -138.914  &lt; 2e-16 ***\nORIGIN_SZTNSZ04 -0.2816960  0.0085295   -33.026  &lt; 2e-16 ***\nORIGIN_SZTPSZ01 -0.7822239  0.0077901  -100.412  &lt; 2e-16 ***\nORIGIN_SZTPSZ02  0.5735478  0.0053042   108.131  &lt; 2e-16 ***\nORIGIN_SZTPSZ03 -0.8748650  0.0074202  -117.903  &lt; 2e-16 ***\nORIGIN_SZTPSZ04 -0.8537831  0.0069792  -122.332  &lt; 2e-16 ***\nORIGIN_SZTPSZ05 -0.5581114  0.0077012   -72.471  &lt; 2e-16 ***\nORIGIN_SZTPSZ06  0.0262001  0.0075241     3.482 0.000497 ***\nORIGIN_SZTPSZ07 -0.5969952  0.0074272   -80.380  &lt; 2e-16 ***\nORIGIN_SZTPSZ08 -1.0537959  0.0111297   -94.683  &lt; 2e-16 ***\nORIGIN_SZTPSZ09 -0.9588508  0.0081314  -117.920  &lt; 2e-16 ***\nORIGIN_SZTPSZ10 -1.1177249  0.0089403  -125.021  &lt; 2e-16 ***\nORIGIN_SZTPSZ11 -0.2799677  0.0067135   -41.702  &lt; 2e-16 ***\nORIGIN_SZTPSZ12 -0.8898871  0.0080215  -110.938  &lt; 2e-16 ***\nORIGIN_SZTSSZ01 -2.6146463  0.0521606   -50.127  &lt; 2e-16 ***\nORIGIN_SZTSSZ02  0.1682588  0.0119965    14.026  &lt; 2e-16 ***\nORIGIN_SZTSSZ03  0.2587653  0.0123809    20.900  &lt; 2e-16 ***\nORIGIN_SZTSSZ04 -0.5473825  0.0135215   -40.482  &lt; 2e-16 ***\nORIGIN_SZTSSZ05 -0.9967379  0.0206068   -48.369  &lt; 2e-16 ***\nORIGIN_SZTSSZ06  0.4933147  0.0229597    21.486  &lt; 2e-16 ***\nORIGIN_SZWCSZ01  1.2524706  0.0111133   112.700  &lt; 2e-16 ***\nORIGIN_SZWCSZ02 -2.8544820  0.0347805   -82.071  &lt; 2e-16 ***\nORIGIN_SZWCSZ03 -5.1277334  0.1475585   -34.751  &lt; 2e-16 ***\nORIGIN_SZWDSZ01  1.4725308  0.0056496   260.645  &lt; 2e-16 ***\nORIGIN_SZWDSZ02  0.1571680  0.0064909    24.214  &lt; 2e-16 ***\nORIGIN_SZWDSZ03  1.2584097  0.0061471   204.717  &lt; 2e-16 ***\nORIGIN_SZWDSZ04  0.8578765  0.0069277   123.833  &lt; 2e-16 ***\nORIGIN_SZWDSZ05  0.1702728  0.0069687    24.434  &lt; 2e-16 ***\nORIGIN_SZWDSZ06  0.1736910  0.0069507    24.989  &lt; 2e-16 ***\nORIGIN_SZWDSZ07 -1.5610176  0.0100803  -154.859  &lt; 2e-16 ***\nORIGIN_SZWDSZ08 -0.9490906  0.0102047   -93.005  &lt; 2e-16 ***\nORIGIN_SZWDSZ09  1.2107011  0.0062294   194.354  &lt; 2e-16 ***\nORIGIN_SZYSSZ01 -0.3324158  0.0074537   -44.598  &lt; 2e-16 ***\nORIGIN_SZYSSZ02  0.8177113  0.0066108   123.693  &lt; 2e-16 ***\nORIGIN_SZYSSZ03  1.6751777  0.0058470   286.503  &lt; 2e-16 ***\nORIGIN_SZYSSZ04  0.8130044  0.0059025   137.738  &lt; 2e-16 ***\nORIGIN_SZYSSZ05  0.3678420  0.0072431    50.785  &lt; 2e-16 ***\nORIGIN_SZYSSZ06 -0.6024384  0.0126722   -47.540  &lt; 2e-16 ***\nORIGIN_SZYSSZ07 -0.7631918  0.0158478   -48.157  &lt; 2e-16 ***\nORIGIN_SZYSSZ08  0.2141930  0.0076154    28.126  &lt; 2e-16 ***\nORIGIN_SZYSSZ09  1.0809368  0.0057973   186.457  &lt; 2e-16 ***\nDESTIN_SZAMSZ02  0.0761304  0.0051207    14.867  &lt; 2e-16 ***\nDESTIN_SZAMSZ03  0.0143394  0.0050755     2.825 0.004724 ** \nDESTIN_SZAMSZ04 -1.2516780  0.0074947  -167.008  &lt; 2e-16 ***\nDESTIN_SZAMSZ05 -1.2312375  0.0076598  -160.741  &lt; 2e-16 ***\nDESTIN_SZAMSZ06 -1.0333412  0.0075283  -137.261  &lt; 2e-16 ***\nDESTIN_SZAMSZ07 -1.5338249  0.0110036  -139.392  &lt; 2e-16 ***\nDESTIN_SZAMSZ08 -0.3751665  0.0075358   -49.784  &lt; 2e-16 ***\nDESTIN_SZAMSZ09 -1.1633493  0.0077556  -150.001  &lt; 2e-16 ***\nDESTIN_SZAMSZ10  0.1017717  0.0053151    19.148  &lt; 2e-16 ***\nDESTIN_SZAMSZ11 -0.8840362  0.0097007   -91.131  &lt; 2e-16 ***\nDESTIN_SZAMSZ12  0.1628123  0.0055220    29.484  &lt; 2e-16 ***\nDESTIN_SZBDSZ01  1.0040794  0.0047922   209.523  &lt; 2e-16 ***\nDESTIN_SZBDSZ02 -0.2478149  0.0063085   -39.283  &lt; 2e-16 ***\nDESTIN_SZBDSZ03  0.1016088  0.0057420    17.696  &lt; 2e-16 ***\nDESTIN_SZBDSZ04  1.1082928  0.0047747   232.116  &lt; 2e-16 ***\nDESTIN_SZBDSZ05  0.8737933  0.0050593   172.712  &lt; 2e-16 ***\nDESTIN_SZBDSZ06  0.2897032  0.0058244    49.740  &lt; 2e-16 ***\nDESTIN_SZBDSZ07 -0.9026193  0.0113656   -79.416  &lt; 2e-16 ***\nDESTIN_SZBDSZ08 -1.7063577  0.0131234  -130.024  &lt; 2e-16 ***\nDESTIN_SZBKSZ01 -1.3892839  0.0083307  -166.767  &lt; 2e-16 ***\nDESTIN_SZBKSZ02 -0.6661120  0.0073464   -90.672  &lt; 2e-16 ***\nDESTIN_SZBKSZ03 -0.9536826  0.0073196  -130.292  &lt; 2e-16 ***\nDESTIN_SZBKSZ04 -0.6655610  0.0065868  -101.044  &lt; 2e-16 ***\nDESTIN_SZBKSZ05 -0.9053119  0.0079264  -114.215  &lt; 2e-16 ***\nDESTIN_SZBKSZ06 -1.2622159  0.0075079  -168.119  &lt; 2e-16 ***\nDESTIN_SZBKSZ07 -0.0423370  0.0056686    -7.469 8.10e-14 ***\nDESTIN_SZBKSZ08 -1.3811240  0.0084985  -162.515  &lt; 2e-16 ***\nDESTIN_SZBKSZ09 -0.0797012  0.0061428   -12.975  &lt; 2e-16 ***\nDESTIN_SZBLSZ01 -0.8859670  0.0088108  -100.555  &lt; 2e-16 ***\nDESTIN_SZBLSZ02  0.1362723  0.0082167    16.585  &lt; 2e-16 ***\nDESTIN_SZBLSZ03  1.2037396  0.0093508   128.732  &lt; 2e-16 ***\nDESTIN_SZBLSZ04 -0.9316219  0.0178080   -52.315  &lt; 2e-16 ***\nDESTIN_SZBMSZ01  0.7188470  0.0061160   117.536  &lt; 2e-16 ***\nDESTIN_SZBMSZ02 -0.0597895  0.0061206    -9.769  &lt; 2e-16 ***\nDESTIN_SZBMSZ03 -0.2427075  0.0069937   -34.704  &lt; 2e-16 ***\nDESTIN_SZBMSZ04 -0.0622494  0.0065569    -9.494  &lt; 2e-16 ***\nDESTIN_SZBMSZ05 -0.2857019  0.0086450   -33.048  &lt; 2e-16 ***\nDESTIN_SZBMSZ06 -1.3486558  0.0158904   -84.872  &lt; 2e-16 ***\nDESTIN_SZBMSZ07  0.4549687  0.0058315    78.020  &lt; 2e-16 ***\nDESTIN_SZBMSZ08 -0.8730268  0.0077814  -112.195  &lt; 2e-16 ***\nDESTIN_SZBMSZ09 -2.0319890  0.0163038  -124.633  &lt; 2e-16 ***\nDESTIN_SZBMSZ10 -1.4319101  0.0102616  -139.541  &lt; 2e-16 ***\nDESTIN_SZBMSZ11 -1.2429176  0.0092250  -134.733  &lt; 2e-16 ***\nDESTIN_SZBMSZ12 -0.8526549  0.0096009   -88.810  &lt; 2e-16 ***\nDESTIN_SZBMSZ13  0.1399907  0.0066885    20.930  &lt; 2e-16 ***\nDESTIN_SZBMSZ14 -1.0103155  0.0091377  -110.566  &lt; 2e-16 ***\nDESTIN_SZBMSZ15 -0.6819769  0.0086179   -79.135  &lt; 2e-16 ***\nDESTIN_SZBMSZ16 -1.4468308  0.0134051  -107.931  &lt; 2e-16 ***\nDESTIN_SZBMSZ17 -1.5312175  0.0186843   -81.952  &lt; 2e-16 ***\nDESTIN_SZBPSZ01 -1.1726725  0.0073257  -160.077  &lt; 2e-16 ***\nDESTIN_SZBPSZ02 -2.1072012  0.0103320  -203.949  &lt; 2e-16 ***\nDESTIN_SZBPSZ03 -1.6944911  0.0098520  -171.995  &lt; 2e-16 ***\nDESTIN_SZBPSZ04 -0.7664610  0.0074458  -102.939  &lt; 2e-16 ***\nDESTIN_SZBPSZ05  0.1358370  0.0056258    24.145  &lt; 2e-16 ***\nDESTIN_SZBPSZ06 -1.2425471  0.0096942  -128.175  &lt; 2e-16 ***\nDESTIN_SZBPSZ07 -0.1666192  0.0094969   -17.545  &lt; 2e-16 ***\nDESTIN_SZBSSZ01  0.3857894  0.0057261    67.374  &lt; 2e-16 ***\nDESTIN_SZBSSZ02 -0.5293265  0.0064886   -81.578  &lt; 2e-16 ***\nDESTIN_SZBSSZ03  0.3909966  0.0048540    80.551  &lt; 2e-16 ***\nDESTIN_SZBTSZ01  0.7114965  0.0054528   130.482  &lt; 2e-16 ***\nDESTIN_SZBTSZ02 -0.0487084  0.0082474    -5.906 3.51e-09 ***\nDESTIN_SZBTSZ03  0.5539032  0.0064423    85.979  &lt; 2e-16 ***\nDESTIN_SZBTSZ04 -0.7120734  0.0128676   -55.339  &lt; 2e-16 ***\nDESTIN_SZBTSZ05  0.2176097  0.0086791    25.073  &lt; 2e-16 ***\nDESTIN_SZBTSZ06 -0.2167084  0.0084925   -25.518  &lt; 2e-16 ***\nDESTIN_SZBTSZ07 -1.4045618  0.0124363  -112.940  &lt; 2e-16 ***\nDESTIN_SZBTSZ08 -0.8213918  0.0120793   -68.000  &lt; 2e-16 ***\nDESTIN_SZCBSZ01 -5.7340877  0.3333916   -17.199  &lt; 2e-16 ***\nDESTIN_SZCCSZ01 -0.0304192  0.0095920    -3.171 0.001518 ** \nDESTIN_SZCHSZ01 -0.2598507  0.0115311   -22.535  &lt; 2e-16 ***\nDESTIN_SZCHSZ02  0.3497750  0.0068334    51.186  &lt; 2e-16 ***\nDESTIN_SZCHSZ03  2.4550172  0.0050883   482.481  &lt; 2e-16 ***\nDESTIN_SZCKSZ01 -0.4691744  0.0063130   -74.319  &lt; 2e-16 ***\nDESTIN_SZCKSZ02 -0.9557084  0.0069331  -137.847  &lt; 2e-16 ***\nDESTIN_SZCKSZ03  0.0442112  0.0057117     7.740 9.91e-15 ***\nDESTIN_SZCKSZ04 -0.8592063  0.0081238  -105.764  &lt; 2e-16 ***\nDESTIN_SZCKSZ05 -1.1745333  0.0087305  -134.532  &lt; 2e-16 ***\nDESTIN_SZCKSZ06 -0.4982877  0.0085514   -58.269  &lt; 2e-16 ***\nDESTIN_SZCLSZ01  0.2665065  0.0059712    44.632  &lt; 2e-16 ***\nDESTIN_SZCLSZ02 -1.9758876  0.0150823  -131.007  &lt; 2e-16 ***\nDESTIN_SZCLSZ03 -0.9051310  0.0091479   -98.944  &lt; 2e-16 ***\nDESTIN_SZCLSZ04 -0.0828732  0.0061559   -13.462  &lt; 2e-16 ***\nDESTIN_SZCLSZ05 -1.1414780  0.0100760  -113.287  &lt; 2e-16 ***\nDESTIN_SZCLSZ06  0.3229402  0.0056269    57.392  &lt; 2e-16 ***\nDESTIN_SZCLSZ07 -0.4833612  0.0069777   -69.272  &lt; 2e-16 ***\nDESTIN_SZCLSZ08 -0.3219670  0.0075615   -42.580  &lt; 2e-16 ***\nDESTIN_SZCLSZ09  0.0564166  0.0080703     6.991 2.74e-12 ***\nDESTIN_SZDTSZ02 -1.6384236  0.0374725   -43.723  &lt; 2e-16 ***\nDESTIN_SZDTSZ03 -0.4021571  0.0152716   -26.334  &lt; 2e-16 ***\nDESTIN_SZDTSZ13 -1.2799441  0.0177095   -72.274  &lt; 2e-16 ***\nDESTIN_SZGLSZ01 -0.0190303  0.0060665    -3.137 0.001707 ** \nDESTIN_SZGLSZ02 -0.0308469  0.0058724    -5.253 1.50e-07 ***\nDESTIN_SZGLSZ03  0.6927638  0.0048456   142.969  &lt; 2e-16 ***\nDESTIN_SZGLSZ04  0.9325848  0.0049183   189.616  &lt; 2e-16 ***\nDESTIN_SZGLSZ05  0.8480056  0.0048801   173.768  &lt; 2e-16 ***\nDESTIN_SZHGSZ01  0.0652969  0.0047795    13.662  &lt; 2e-16 ***\nDESTIN_SZHGSZ02 -0.9498251  0.0066577  -142.667  &lt; 2e-16 ***\nDESTIN_SZHGSZ03 -1.4372499  0.0076387  -188.154  &lt; 2e-16 ***\nDESTIN_SZHGSZ04 -0.5236292  0.0055353   -94.599  &lt; 2e-16 ***\nDESTIN_SZHGSZ05 -0.5420295  0.0058099   -93.295  &lt; 2e-16 ***\nDESTIN_SZHGSZ06 -0.9054730  0.0067581  -133.983  &lt; 2e-16 ***\nDESTIN_SZHGSZ07  0.0215109  0.0054019     3.982 6.83e-05 ***\nDESTIN_SZHGSZ08 -0.0490979  0.0059206    -8.293  &lt; 2e-16 ***\nDESTIN_SZHGSZ09 -0.0711560  0.0062875   -11.317  &lt; 2e-16 ***\nDESTIN_SZHGSZ10 -3.5807154  0.0290642  -123.200  &lt; 2e-16 ***\nDESTIN_SZJESZ01 -0.4023638  0.0065057   -61.848  &lt; 2e-16 ***\nDESTIN_SZJESZ02 -0.7654353  0.0067096  -114.081  &lt; 2e-16 ***\nDESTIN_SZJESZ03 -0.8778812  0.0071238  -123.232  &lt; 2e-16 ***\nDESTIN_SZJESZ04 -1.1998075  0.0088733  -135.215  &lt; 2e-16 ***\nDESTIN_SZJESZ05 -1.5623652  0.0116898  -133.652  &lt; 2e-16 ***\nDESTIN_SZJESZ06  0.2311474  0.0055595    41.577  &lt; 2e-16 ***\nDESTIN_SZJESZ07 -1.2753348  0.0094838  -134.475  &lt; 2e-16 ***\nDESTIN_SZJESZ08 -0.7654533  0.0099306   -77.081  &lt; 2e-16 ***\nDESTIN_SZJESZ09  0.1637628  0.0074164    22.081  &lt; 2e-16 ***\nDESTIN_SZJESZ10  0.7394958  0.0091249    81.041  &lt; 2e-16 ***\nDESTIN_SZJESZ11  0.5157364  0.0086546    59.591  &lt; 2e-16 ***\nDESTIN_SZJWSZ01 -1.0165204  0.0083025  -122.435  &lt; 2e-16 ***\nDESTIN_SZJWSZ02 -0.8530646  0.0067851  -125.727  &lt; 2e-16 ***\nDESTIN_SZJWSZ03  0.5176135  0.0056449    91.695  &lt; 2e-16 ***\nDESTIN_SZJWSZ04  0.3427105  0.0058499    58.584  &lt; 2e-16 ***\nDESTIN_SZJWSZ05 -1.1695940  0.0080069  -146.073  &lt; 2e-16 ***\nDESTIN_SZJWSZ06 -0.7466462  0.0070240  -106.299  &lt; 2e-16 ***\nDESTIN_SZJWSZ07 -3.0124535  0.0333481   -90.334  &lt; 2e-16 ***\nDESTIN_SZJWSZ08 -0.4253502  0.0066584   -63.881  &lt; 2e-16 ***\nDESTIN_SZJWSZ09  0.9428005  0.0053190   177.251  &lt; 2e-16 ***\nDESTIN_SZKLSZ01 -0.2965013  0.0066422   -44.639  &lt; 2e-16 ***\nDESTIN_SZKLSZ02 -0.4921137  0.0067689   -72.702  &lt; 2e-16 ***\nDESTIN_SZKLSZ03 -0.8489213  0.0078294  -108.427  &lt; 2e-16 ***\nDESTIN_SZKLSZ04 -1.2656342  0.0099918  -126.667  &lt; 2e-16 ***\nDESTIN_SZKLSZ05 -0.3570126  0.0096300   -37.073  &lt; 2e-16 ***\nDESTIN_SZKLSZ06 -2.4764906  0.0390868   -63.359  &lt; 2e-16 ***\nDESTIN_SZKLSZ07 -0.7316189  0.0080994   -90.330  &lt; 2e-16 ***\nDESTIN_SZKLSZ08 -0.1115398  0.0061168   -18.235  &lt; 2e-16 ***\nDESTIN_SZLKSZ01 -1.4940710  0.0271518   -55.027  &lt; 2e-16 ***\nDESTIN_SZMDSZ01 -1.6101440  0.0231238   -69.631  &lt; 2e-16 ***\nDESTIN_SZMDSZ02 -0.9339318  0.0126277   -73.959  &lt; 2e-16 ***\nDESTIN_SZMDSZ03 -3.4868547  0.0303657  -114.829  &lt; 2e-16 ***\nDESTIN_SZMPSZ01 -0.4518483  0.0089869   -50.279  &lt; 2e-16 ***\nDESTIN_SZMPSZ02 -0.5868264  0.0073193   -80.176  &lt; 2e-16 ***\nDESTIN_SZMPSZ03  0.4805365  0.0059041    81.391  &lt; 2e-16 ***\nDESTIN_SZMUSZ02 -1.3837581  0.0218713   -63.268  &lt; 2e-16 ***\nDESTIN_SZNTSZ01 -3.0694691  0.0533346   -57.551  &lt; 2e-16 ***\nDESTIN_SZNTSZ02 -1.4992973  0.0130358  -115.014  &lt; 2e-16 ***\nDESTIN_SZNTSZ03 -0.5221236  0.0089923   -58.064  &lt; 2e-16 ***\nDESTIN_SZNTSZ05 -1.9751162  0.0282369   -69.948  &lt; 2e-16 ***\nDESTIN_SZNTSZ06 -3.9959411  0.0511214   -78.166  &lt; 2e-16 ***\nDESTIN_SZNVSZ01 -0.1126966  0.0057077   -19.745  &lt; 2e-16 ***\nDESTIN_SZNVSZ02 -0.0259250  0.0064427    -4.024 5.72e-05 ***\nDESTIN_SZNVSZ03 -0.0123214  0.0067692    -1.820 0.068725 .  \nDESTIN_SZNVSZ04 -1.3371298  0.0130261  -102.650  &lt; 2e-16 ***\nDESTIN_SZNVSZ05 -0.9686333  0.0101539   -95.395  &lt; 2e-16 ***\nDESTIN_SZPGSZ01 -1.1798309  0.0180543   -65.349  &lt; 2e-16 ***\nDESTIN_SZPGSZ02 -1.3289737  0.0085335  -155.736  &lt; 2e-16 ***\nDESTIN_SZPGSZ03 -0.1661373  0.0055166   -30.116  &lt; 2e-16 ***\nDESTIN_SZPGSZ04 -0.3046408  0.0058469   -52.103  &lt; 2e-16 ***\nDESTIN_SZPGSZ05 -1.5412612  0.0093261  -165.264  &lt; 2e-16 ***\nDESTIN_SZPLSZ01 -0.3439667  0.0083504   -41.192  &lt; 2e-16 ***\nDESTIN_SZPLSZ02 -1.7574919  0.0154244  -113.942  &lt; 2e-16 ***\nDESTIN_SZPLSZ03 -0.3455776  0.0112089   -30.831  &lt; 2e-16 ***\nDESTIN_SZPLSZ04 -2.0749385  0.0141153  -146.999  &lt; 2e-16 ***\nDESTIN_SZPLSZ05 -0.4855216  0.0134069   -36.214  &lt; 2e-16 ***\nDESTIN_SZPNSZ01  0.0117816  0.0083558     1.410 0.158543    \nDESTIN_SZPNSZ02  0.7389858  0.0089823    82.272  &lt; 2e-16 ***\nDESTIN_SZPNSZ03 -0.4708719  0.0098588   -47.761  &lt; 2e-16 ***\nDESTIN_SZPNSZ04  1.3156771  0.0111200   118.316  &lt; 2e-16 ***\nDESTIN_SZPNSZ05  0.9881886  0.0153169    64.516  &lt; 2e-16 ***\nDESTIN_SZPRSZ01 -1.0678999  0.0098295  -108.642  &lt; 2e-16 ***\nDESTIN_SZPRSZ02  0.0650279  0.0063927    10.172  &lt; 2e-16 ***\nDESTIN_SZPRSZ03  0.6348138  0.0050147   126.592  &lt; 2e-16 ***\nDESTIN_SZPRSZ04 -0.3640286  0.0097572   -37.309  &lt; 2e-16 ***\nDESTIN_SZPRSZ05  0.0380410  0.0062577     6.079 1.21e-09 ***\nDESTIN_SZPRSZ06  0.3153712  0.0068742    45.877  &lt; 2e-16 ***\nDESTIN_SZPRSZ07 -1.6669973  0.0145573  -114.513  &lt; 2e-16 ***\nDESTIN_SZPRSZ08 -0.6170648  0.0078424   -78.683  &lt; 2e-16 ***\nDESTIN_SZQTSZ01 -0.5496582  0.0098285   -55.925  &lt; 2e-16 ***\nDESTIN_SZQTSZ02 -0.7318114  0.0086807   -84.303  &lt; 2e-16 ***\nDESTIN_SZQTSZ03 -0.5893064  0.0084789   -69.503  &lt; 2e-16 ***\nDESTIN_SZQTSZ04 -0.7103906  0.0085341   -83.242  &lt; 2e-16 ***\nDESTIN_SZQTSZ05 -0.4721472  0.0078164   -60.405  &lt; 2e-16 ***\nDESTIN_SZQTSZ06 -0.6591466  0.0080069   -82.322  &lt; 2e-16 ***\nDESTIN_SZQTSZ07 -0.9540454  0.0126807   -75.236  &lt; 2e-16 ***\nDESTIN_SZQTSZ08  0.4508867  0.0064870    69.507  &lt; 2e-16 ***\nDESTIN_SZQTSZ09 -0.4061810  0.0075485   -53.810  &lt; 2e-16 ***\nDESTIN_SZQTSZ10  0.1351889  0.0068202    19.822  &lt; 2e-16 ***\nDESTIN_SZQTSZ11  0.3181553  0.0067958    46.816  &lt; 2e-16 ***\nDESTIN_SZQTSZ12 -0.1055766  0.0095576   -11.046  &lt; 2e-16 ***\nDESTIN_SZQTSZ13  0.5199663  0.0071928    72.290  &lt; 2e-16 ***\nDESTIN_SZQTSZ14  0.6086332  0.0078537    77.496  &lt; 2e-16 ***\nDESTIN_SZQTSZ15  1.3906866  0.0092250   150.753  &lt; 2e-16 ***\nDESTIN_SZRCSZ01 -0.0862091  0.0085363   -10.099  &lt; 2e-16 ***\nDESTIN_SZRCSZ06 -1.0186282  0.0211113   -48.250  &lt; 2e-16 ***\nDESTIN_SZRVSZ01 -1.5294454  0.0179337   -85.283  &lt; 2e-16 ***\nDESTIN_SZRVSZ02 -2.3607754  0.0355628   -66.383  &lt; 2e-16 ***\nDESTIN_SZRVSZ03 -1.5266254  0.0156276   -97.688  &lt; 2e-16 ***\nDESTIN_SZRVSZ04 -1.0986565  0.0168695   -65.127  &lt; 2e-16 ***\nDESTIN_SZRVSZ05 -2.4004418  0.0320917   -74.799  &lt; 2e-16 ***\nDESTIN_SZSBSZ01 -1.4023966  0.0109496  -128.078  &lt; 2e-16 ***\nDESTIN_SZSBSZ02 -1.3899893  0.0090891  -152.929  &lt; 2e-16 ***\nDESTIN_SZSBSZ03  0.4509008  0.0059864    75.321  &lt; 2e-16 ***\nDESTIN_SZSBSZ04  0.1796309  0.0070142    25.610  &lt; 2e-16 ***\nDESTIN_SZSBSZ05 -1.3159699  0.0096485  -136.391  &lt; 2e-16 ***\nDESTIN_SZSBSZ06 -1.7705263  0.0253064   -69.964  &lt; 2e-16 ***\nDESTIN_SZSBSZ07 -0.7471529  0.0238628   -31.310  &lt; 2e-16 ***\nDESTIN_SZSBSZ08  0.7884520  0.0069638   113.221  &lt; 2e-16 ***\nDESTIN_SZSBSZ09  0.0131702  0.0066350     1.985 0.047150 *  \nDESTIN_SZSESZ02 -0.7247347  0.0060626  -119.541  &lt; 2e-16 ***\nDESTIN_SZSESZ03  0.1032728  0.0048330    21.368  &lt; 2e-16 ***\nDESTIN_SZSESZ04 -1.0992420  0.0068328  -160.878  &lt; 2e-16 ***\nDESTIN_SZSESZ05 -0.8374712  0.0058155  -144.006  &lt; 2e-16 ***\nDESTIN_SZSESZ06 -0.5531619  0.0074766   -73.985  &lt; 2e-16 ***\nDESTIN_SZSESZ07 -3.0328672  0.0246371  -123.101  &lt; 2e-16 ***\nDESTIN_SZSGSZ01 -0.1933777  0.0068235   -28.340  &lt; 2e-16 ***\nDESTIN_SZSGSZ02 -0.3000845  0.0060284   -49.779  &lt; 2e-16 ***\nDESTIN_SZSGSZ03 -0.4322879  0.0057308   -75.433  &lt; 2e-16 ***\nDESTIN_SZSGSZ04 -0.1214792  0.0056548   -21.482  &lt; 2e-16 ***\nDESTIN_SZSGSZ05 -2.0309074  0.0114993  -176.611  &lt; 2e-16 ***\nDESTIN_SZSGSZ06  0.6592095  0.0046364   142.182  &lt; 2e-16 ***\nDESTIN_SZSGSZ07 -0.4618538  0.0062027   -74.460  &lt; 2e-16 ***\nDESTIN_SZSISZ01 -0.5227257  0.0293399   -17.816  &lt; 2e-16 ***\nDESTIN_SZSKSZ01 -0.4797341  0.0091087   -52.668  &lt; 2e-16 ***\nDESTIN_SZSKSZ02  0.8477357  0.0067821   124.996  &lt; 2e-16 ***\nDESTIN_SZSKSZ03 -0.2477566  0.0074817   -33.115  &lt; 2e-16 ***\nDESTIN_SZSKSZ04 -1.3315992  0.0167055   -79.710  &lt; 2e-16 ***\nDESTIN_SZSKSZ05 -0.3519096  0.0131326   -26.797  &lt; 2e-16 ***\nDESTIN_SZSLSZ01 -0.8570431  0.0102100   -83.941  &lt; 2e-16 ***\nDESTIN_SZSLSZ04 -0.9949105  0.0088280  -112.699  &lt; 2e-16 ***\nDESTIN_SZSRSZ01 -1.0260696  0.0154393   -66.458  &lt; 2e-16 ***\nDESTIN_SZTHSZ01 -4.2040410  0.0404795  -103.856  &lt; 2e-16 ***\nDESTIN_SZTHSZ03 -2.4907000  0.0264056   -94.325  &lt; 2e-16 ***\nDESTIN_SZTHSZ04 -3.0701470  0.0244975  -125.325  &lt; 2e-16 ***\nDESTIN_SZTHSZ06 -2.5308161  0.0169699  -149.135  &lt; 2e-16 ***\nDESTIN_SZTMSZ01 -0.2354889  0.0067201   -35.042  &lt; 2e-16 ***\nDESTIN_SZTMSZ02  1.7379292  0.0044573   389.906  &lt; 2e-16 ***\nDESTIN_SZTMSZ03  0.9112458  0.0048718   187.043  &lt; 2e-16 ***\nDESTIN_SZTMSZ04  1.0731075  0.0048626   220.685  &lt; 2e-16 ***\nDESTIN_SZTMSZ05  0.6398583  0.0067321    95.046  &lt; 2e-16 ***\nDESTIN_SZTNSZ01 -0.3500456  0.0083835   -41.754  &lt; 2e-16 ***\nDESTIN_SZTNSZ02 -1.0573515  0.0112412   -94.060  &lt; 2e-16 ***\nDESTIN_SZTNSZ03 -1.4069979  0.0132733  -106.002  &lt; 2e-16 ***\nDESTIN_SZTNSZ04 -0.3616604  0.0085207   -42.445  &lt; 2e-16 ***\nDESTIN_SZTPSZ01 -0.5919243  0.0071153   -83.190  &lt; 2e-16 ***\nDESTIN_SZTPSZ02  0.7083350  0.0046540   152.198  &lt; 2e-16 ***\nDESTIN_SZTPSZ03 -0.5746433  0.0069625   -82.534  &lt; 2e-16 ***\nDESTIN_SZTPSZ04 -1.5821259  0.0084517  -187.196  &lt; 2e-16 ***\nDESTIN_SZTPSZ05 -1.1796256  0.0073039  -161.505  &lt; 2e-16 ***\nDESTIN_SZTPSZ06 -0.3968272  0.0077295   -51.339  &lt; 2e-16 ***\nDESTIN_SZTPSZ07 -2.1796617  0.0135199  -161.219  &lt; 2e-16 ***\nDESTIN_SZTPSZ08 -1.2568483  0.0107267  -117.170  &lt; 2e-16 ***\nDESTIN_SZTPSZ09 -0.2446623  0.0080840   -30.265  &lt; 2e-16 ***\nDESTIN_SZTPSZ10 -1.2542191  0.0102049  -122.904  &lt; 2e-16 ***\nDESTIN_SZTPSZ11 -0.0886883  0.0062888   -14.102  &lt; 2e-16 ***\nDESTIN_SZTPSZ12 -0.7211823  0.0075086   -96.048  &lt; 2e-16 ***\nDESTIN_SZTSSZ01 -1.6271921  0.0238498   -68.227  &lt; 2e-16 ***\nDESTIN_SZTSSZ02 -0.3340439  0.0169137   -19.750  &lt; 2e-16 ***\nDESTIN_SZTSSZ03  0.3924580  0.0111060    35.338  &lt; 2e-16 ***\nDESTIN_SZTSSZ04  0.4169932  0.0114926    36.283  &lt; 2e-16 ***\nDESTIN_SZTSSZ05  1.3206287  0.0120381   109.704  &lt; 2e-16 ***\nDESTIN_SZTSSZ06  2.4023725  0.0192840   124.579  &lt; 2e-16 ***\nDESTIN_SZWCSZ01  2.0697378  0.0061379   337.206  &lt; 2e-16 ***\nDESTIN_SZWCSZ02 -2.0934025  0.0134782  -155.318  &lt; 2e-16 ***\nDESTIN_SZWCSZ03 -3.0670149  0.0349748   -87.692  &lt; 2e-16 ***\nDESTIN_SZWDSZ01  1.0113215  0.0051461   196.522  &lt; 2e-16 ***\nDESTIN_SZWDSZ02 -1.3383793  0.0076482  -174.993  &lt; 2e-16 ***\nDESTIN_SZWDSZ03  0.3394361  0.0060396    56.202  &lt; 2e-16 ***\nDESTIN_SZWDSZ04 -0.8324928  0.0086019   -96.780  &lt; 2e-16 ***\nDESTIN_SZWDSZ05 -0.8279090  0.0083251   -99.447  &lt; 2e-16 ***\nDESTIN_SZWDSZ06 -0.2252899  0.0061074   -36.888  &lt; 2e-16 ***\nDESTIN_SZWDSZ07 -1.3638599  0.0077990  -174.877  &lt; 2e-16 ***\nDESTIN_SZWDSZ08 -0.4350176  0.0077566   -56.083  &lt; 2e-16 ***\nDESTIN_SZWDSZ09  0.5461048  0.0060745    89.901  &lt; 2e-16 ***\nDESTIN_SZYSSZ01  0.0243093  0.0053476     4.546 5.47e-06 ***\nDESTIN_SZYSSZ02 -0.3398962  0.0065947   -51.540  &lt; 2e-16 ***\nDESTIN_SZYSSZ03 -0.3694187  0.0074032   -49.900  &lt; 2e-16 ***\nDESTIN_SZYSSZ04 -0.5222848  0.0067396   -77.495  &lt; 2e-16 ***\nDESTIN_SZYSSZ05 -1.5460539  0.0124899  -123.784  &lt; 2e-16 ***\nDESTIN_SZYSSZ06 -1.5556892  0.0127640  -121.881  &lt; 2e-16 ***\nDESTIN_SZYSSZ07 -0.8673403  0.0167723   -51.713  &lt; 2e-16 ***\nDESTIN_SZYSSZ08  0.5389364  0.0052540   102.577  &lt; 2e-16 ***\nDESTIN_SZYSSZ09  0.1199483  0.0055235    21.716  &lt; 2e-16 ***\nlog(dist)       -1.8906989  0.0005319 -3554.786  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 36117615  on 14273  degrees of freedom\nResidual deviance:  8091747  on 13715  degrees of freedom\nAIC: 8177420\n\nNumber of Fisher Scoring iterations: 7\n\n\nWe can examine how the constraints hold for destinations this time.\n\nCalcRSquared(dbcSIM$data$TRIPS, dbcSIM$fitted.values)\n\n[1] 0.6883675\n\n\nNotice that there is a relatively greater improvement in the R^2 value.\n\n\n16.8.9 Model comparison\nAnother useful model performance measure for continuous dependent variable is Root Mean Squared Error. In this sub-section, you will learn how to use compare_performance() of performance package\nFirst of all, let us create a list called model_list by using the code chun below.\n\nmodel_list &lt;- list(unconstrained=uncSIM,\n                   originConstrained=orcSIM,\n                   destinationConstrained=decSIM,\n                   doublyConstrained=dbcSIM)\n\nNext, we will compute the RMSE of all the models in model_list file by using the code chunk below.\n\ncompare_performance(model_list,\n                    metrics = \"RMSE\")\n\n# Comparison of Model Performance Indices\n\nName                   | Model |     RMSE\n-----------------------------------------\nunconstrained          |   glm | 2429.978\noriginConstrained      |   glm | 2057.579\ndestinationConstrained |   glm | 1891.724\ndoublyConstrained      |   glm | 1487.111\n\n\nThe print above reveals that doubly constrained SIM is the best model among all the four SIMs because it has the smallest RMSE value of 1487.111.\n\n\n16.8.10 Visualising fitted values\nIn this section, you will learn how to visualise the observed values and the fitted values.\nFirstly we will extract the fitted values from each model by using the code chunk below.\n\ndf &lt;- as.data.frame(uncSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\nNext, we will join the values to SIM_data data frame.\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(uncTRIPS = \"uncSIM$fitted.values\")\n\nRepeat the same step by for Origin Constrained SIM (i.e. orcSIM)\n\ndf &lt;- as.data.frame(orcSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(orcTRIPS = \"orcSIM$fitted.values\")\n\nRepeat the same step by for Destination Constrained SIM (i.e. decSIM)\n\ndf &lt;- as.data.frame(decSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(decTRIPS = \"decSIM$fitted.values\")\n\nRepeat the same step by for Doubly Constrained SIM (i.e. dbcSIM)\n\ndf &lt;- as.data.frame(dbcSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(dbcTRIPS = \"dbcSIM$fitted.values\")\n\n\nunc_p &lt;- ggplot(data = SIM_data,\n                aes(x = uncTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\norc_p &lt;- ggplot(data = SIM_data,\n                aes(x = orcTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\ndec_p &lt;- ggplot(data = SIM_data,\n                aes(x = decTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\ndbc_p &lt;- ggplot(data = SIM_data,\n                aes(x = dbcTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\nNow, we will put all the graphs into a single visual for better comparison by using the code chunk below.\n\nggarrange(unc_p, orc_p, dec_p, dbc_p,\n          ncol = 2,\n          nrow = 2)"
  },
  {
    "objectID": "chap17.html#introduction",
    "href": "chap17.html#introduction",
    "title": "17  Modelling Geographical Accessibility",
    "section": "17.1 Introduction",
    "text": "17.1 Introduction\nIn this hands-on exercise, you will gain hands-on experience on how to model geographical accessibility by using R’s geospatial analysis packages.\n\n17.1.1 Learning Outcome\nBy the end of this hands-on exercise, you will be able:\n\nto import GIS polygon data into R and save them as simple feature data frame by using appropriate functions of sf package of R;\nto import aspatial data into R and save them as simple feature data frame by using appropriate functions of sf package of R;\nto computer accessibility measure by using Hansen’s potential model and Spatial Accessibility Measure (SAM); and\nto visualise the accessibility measures by using tmap and ggplot2 packages."
  },
  {
    "objectID": "chap17.html#the-data",
    "href": "chap17.html#the-data",
    "title": "17  Modelling Geographical Accessibility",
    "section": "17.2 The data",
    "text": "17.2 The data\nFour data sets will be used in this hands-on exercise, they are:\n\nMP14_SUBZONE_NO_SEA_PL: URA Master Plan 2014 subzone boundary GIS data. This data set is downloaded from data.gov.sg.\nhexagons: A 250m radius hexagons GIS data. This data set was created by using st_make_grid() of sf package. It is in ESRI shapefile format.\nELDERCARE: GIS data showing location of eldercare service. This data is downloaded from data.gov.sg. There are two versions. One in ESRI shapefile format. The other one in Google kml file format. For the purpose of this hands-on exercise, ESRI shapefile format is provided.\nOD_Matrix: a distance matrix in csv format. There are six fields in the data file. They are:\n\norigin_id: the unique id values of the origin (i.e. fid of hexagon data set.),\ndestination_id: the unique id values of the destination (i.e. fid of ELDERCARE data set.),\nentry_cost: the perpendicular distance between the origins and the nearest road),\nnetwork_cost: the actual network distance from the origin and destination,\nexit_cost: the perpendicular distance between the destination and the nearest road), and\ntotal_cost: the summation of entry_cost, network_cost and exit_cost.\n\n\nAll the values of the cost related fields are in metres.\nReminder: Except MP14_SUBZONE_NO_SEA_PL data set, the other three data set are specially prepared by Prof. Kam for teaching and research purpose. Students taking IS415 Geospatial Analytics and Applications are allowed to use them for hands-on exercise purpose. Please obtain formal approval from Prof. Kam if you want to use them for other courses or usage."
  },
  {
    "objectID": "chap17.html#getting-started",
    "href": "chap17.html#getting-started",
    "title": "17  Modelling Geographical Accessibility",
    "section": "17.3 Getting Started",
    "text": "17.3 Getting Started\nBefore we getting started, it is important for us to install the necessary R packages and launch them into RStudio environment.\nThe R packages need for this exercise are as follows:\n\nSpatial data handling\n\nsf\n\nModelling geographical accessibility\n\nspatialAcc\n\nAttribute data handling\n\ntidyverse, especially readr and dplyr\n\nthematic mapping\n\ntmap\n\nStaistical graphic\n\nggplot2\n\nStatistical analysis\n\nggstatsplot\n\n\nThe code chunk below installs and launches these R packages into RStudio environment.\n\npacman::p_load(tmap, SpatialAcc, sf, \n               ggstatsplot, reshape2,\n               tidyverse)\n\nNotice that with tidyverse, we do not have to install readr, dplyr and ggplots packages separately. In fact, tidyverse also installs other R packages such as tidyr, stringr, forcats, tibble, purrr and magrittr."
  },
  {
    "objectID": "chap17.html#geospatial-data-wrangling",
    "href": "chap17.html#geospatial-data-wrangling",
    "title": "17  Modelling Geographical Accessibility",
    "section": "17.4 Geospatial Data Wrangling",
    "text": "17.4 Geospatial Data Wrangling\n\n17.4.1 Importing geospatial data\nThree geospatial data will be imported from the data/geospatial sub-folder. They are MP14_SUBZONE_NO_SEA_PL, hexagons and ELDERCARE.\nThe code chunk below is used to import these three data sets shapefile by using st_read() of sf packages.\n\nmpsz &lt;- st_read(dsn = \"chap17/data/geospatial\", layer = \"MP14_SUBZONE_NO_SEA_PL\")\n\nReading layer `MP14_SUBZONE_NO_SEA_PL' from data source \n  `D:\\tskam\\r4gdsa\\chap17\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\nhexagons &lt;- st_read(dsn = \"chap17/data/geospatial\", layer = \"hexagons\") \n\nReading layer `hexagons' from data source `D:\\tskam\\r4gdsa\\chap17\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 3125 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 21506.33 xmax: 50010.26 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\n\neldercare &lt;- st_read(dsn = \"chap17/data/geospatial\", layer = \"ELDERCARE\") \n\nReading layer `ELDERCARE' from data source \n  `D:\\tskam\\r4gdsa\\chap17\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 120 features and 19 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21 / Singapore TM\n\n\nThe report above shows that the R object used to contain the imported MP14_SUBZONE_WEB_PL shapefile is called mpsz and it is a simple feature object. The geometry type is multipolygon. it is also important to note that mpsz simple feature object does not have EPSG information.\n\n\n17.4.2 Updating CRS information\nThe code chunk below updates the newly imported mpsz with the correct ESPG code (i.e. 3414)\n\nmpsz &lt;- st_transform(mpsz, 3414)\neldercare &lt;- st_transform(eldercare, 3414)\nhexagons &lt;- st_transform(hexagons, 3414)\n\nAfter transforming the projection metadata, you can verify the projection of the newly transformed mpsz_svy21 by using st_crs() of sf package.\nThe code chunk below will be used to varify the newly transformed mpsz_svy21.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG: is indicated as 3414 now.\n\n\n17.4.3 Cleaning and updating attribute fields of the geospatial data\nThere are many redundant fields in the data tables of both eldercare and hexagons. The code chunks below will be used to exclude those redundant fields. At the same time, a new field called demand and a new field called capacity will be added into the data table of hexagons and eldercare sf data frame respectively. Both fields are derive using mutate() of dplyr package.\n\neldercare &lt;- eldercare %&gt;%\n  select(fid, ADDRESSPOS) %&gt;%\n  mutate(capacity = 100)\n\n\nhexagons &lt;- hexagons %&gt;%\n  select(fid) %&gt;%\n  mutate(demand = 100)\n\nNotice that for the purpose of this hands-on exercise, a constant value of 100 is used. In practice, actual demand of the hexagon and capacity of the eldercare centre should be used."
  },
  {
    "objectID": "chap17.html#apsaital-data-handling-and-wrangling",
    "href": "chap17.html#apsaital-data-handling-and-wrangling",
    "title": "17  Modelling Geographical Accessibility",
    "section": "17.5 Apsaital Data Handling and Wrangling",
    "text": "17.5 Apsaital Data Handling and Wrangling\n\n17.5.1 Importing Distance Matrix\nThe code chunk below uses read_cvs() of readr package to import OD_Matrix.csv into RStudio. The imported object is a tibble data.frame called ODMatrix.\n\nODMatrix &lt;- read_csv(\"chap17/data/aspatial/OD_Matrix.csv\", skip = 0)\n\n\n\n17.5.2 Tidying distance matrix\nThe imported ODMatrix organised the distance matrix columnwise.\n\nOn the other hands, most of the modelling packages in R is expecting a matrix look similar to the figure below.\n\nThe rows represent origins (i.e. also know as from field) and the columns represent destination (i.e. also known as to field.)\nThe code chunk below uses spread() of tidyr package is used to transform the O-D matrix from a thin format into a fat format.\n\ndistmat &lt;- ODMatrix %&gt;%\n  select(origin_id, destination_id, total_cost) %&gt;%\n  spread(destination_id, total_cost)%&gt;%\n  select(c(-c('origin_id')))\n\nNote: Since tidyr version 1.0 a new function called pivot_wider() is introduce. You should use pivot_wider() instead of spread()\nCurrently, the distance is measured in metre because SVY21 projected coordinate system is used. The code chunk below will be used to convert the unit f measurement from metre to kilometre.\n\ndistmat_km &lt;- as.matrix(distmat/1000)"
  },
  {
    "objectID": "chap17.html#modelling-and-visualising-accessibility-using-hansen-method",
    "href": "chap17.html#modelling-and-visualising-accessibility-using-hansen-method",
    "title": "17  Modelling Geographical Accessibility",
    "section": "17.6 Modelling and Visualising Accessibility using Hansen Method",
    "text": "17.6 Modelling and Visualising Accessibility using Hansen Method\n\n17.6.1 Computing Hansen’s accessibility\nNow, we ready to compute Hansen’s accessibility by using ac() of SpatialAcc package. Before getting started, you are encourage to read the arguments of the function at least once in order to ensure that the required inputs are available.\nThe code chunk below calculates Hansen’s accessibility using ac() of SpatialAcc and data.frame() is used to save the output in a data frame called acc_Handsen.\n\nacc_Hansen &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            #d0 = 50,\n                            power = 2, \n                            family = \"Hansen\"))\n\n\nThe default field name is very messy, we will rename it to accHansen by using the code chunk below.\n\ncolnames(acc_Hansen) &lt;- \"accHansen\"\n\nNotice that the field name is much more tidier now.\n\nNext, we will convert the data table into tibble format by using the code chunk below.\n\nacc_Hansen &lt;- tbl_df(acc_Hansen)\n\nLastly, bind_cols() of dplyr will be used to join the acc_Hansen tibble data frame with the hexagons simple feature data frame. The output is called hexagon_Hansen.\n\nhexagon_Hansen &lt;- bind_cols(hexagons, acc_Hansen)\n\nNotice that hexagon_Hansen is a simple feature data frame and not a typical tibble data frame.\n\nActually, the steps above can be perform by using a single code chunk as shown below.\n\nacc_Hansen &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            #d0 = 50,\n                            power = 0.5, \n                            family = \"Hansen\"))\n\ncolnames(acc_Hansen) &lt;- \"accHansen\"\nacc_Hansen &lt;- tbl_df(acc_Hansen)\nhexagon_Hansen &lt;- bind_cols(hexagons, acc_Hansen)\n\n\n\n17.6.2 Visualising Hansen’s accessibility\n\n17.6.2.1 Extracting map extend\nFirstly, we will extract the extend of hexagons simple feature data frame by by using st_bbox() of sf package.\n\nmapex &lt;- st_bbox(hexagons)\n\nThe code chunk below uses a collection of mapping fucntions of tmap package to create a high cartographic quality accessibility to eldercare centre in Singapore.\n\ntmap_mode(\"plot\")\ntm_shape(hexagon_Hansen,\n         bbox = mapex) + \n  tm_fill(col = \"accHansen\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: Hansen method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 6),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)\n\n\n\n\n\n\n\n17.6.3 Statistical graphic visualisation\nIn this section, we are going to compare the distribution of Hansen’s accessibility values by URA Planning Region.\nFirstly, we need to add the planning region field into haxegon_Hansen simple feature data frame by using the code chunk below.\n\nhexagon_Hansen &lt;- st_join(hexagon_Hansen, mpsz, \n                          join = st_intersects)\n\nNext, ggplot() will be used to plot the distribution by using boxplot graphical method.\n\nggplot(data=hexagon_Hansen, \n       aes(y = log(accHansen), \n           x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)"
  },
  {
    "objectID": "chap17.html#modelling-and-visualising-accessibility-using-kd2sfca-method",
    "href": "chap17.html#modelling-and-visualising-accessibility-using-kd2sfca-method",
    "title": "17  Modelling Geographical Accessibility",
    "section": "17.7 Modelling and Visualising Accessibility using KD2SFCA Method",
    "text": "17.7 Modelling and Visualising Accessibility using KD2SFCA Method\n\n17.7.1 Computing KD2SFCA’s accessibility\nIn this section, you are going to repeat most of the steps you had learned in previous section to perform the analysis. However, some of the codes will be combined into one code chunk.\nThe code chunk below calculates Hansen’s accessibility using ac() of SpatialAcc and data.frame() is used to save the output in a data frame called acc_KD2SFCA. Notice that KD2SFCA is used for family argument.\n\nacc_KD2SFCA &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            d0 = 50,\n                            power = 2, \n                            family = \"KD2SFCA\"))\n\ncolnames(acc_KD2SFCA) &lt;- \"accKD2SFCA\"\nacc_KD2SFCA &lt;- tbl_df(acc_KD2SFCA)\nhexagon_KD2SFCA &lt;- bind_cols(hexagons, acc_KD2SFCA)\n\n\n\n17.7.2 Visualising KD2SFCA’s accessibility\nThe code chunk below uses a collection of mapping fucntions of tmap package to create a high cartographic quality accessibility to eldercare centre in Singapore. Notice that mapex is reused for bbox argument.\n\ntmap_mode(\"plot\")\ntm_shape(hexagon_KD2SFCA,\n         bbox = mapex) + \n  tm_fill(col = \"accKD2SFCA\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: KD2SFCA method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 6),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)\n\n\n\n\n\n\n17.7.3 Statistical graphic visualisation\nNow, we are going to compare the distribution of KD2CFA accessibility values by URA Planning Region.\nFirstly, we need to add the planning region field into hexagon_KD2SFCA simple feature data frame by using the code chunk below.\n\nhexagon_KD2SFCA &lt;- st_join(hexagon_KD2SFCA, mpsz, \n                          join = st_intersects)\n\nNext, ggplot() will be used to plot the distribution by using boxplot graphical method.\n\nggplot(data=hexagon_KD2SFCA, \n       aes(y = accKD2SFCA, \n           x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)"
  },
  {
    "objectID": "chap17.html#modelling-and-visualising-accessibility-using-spatial-accessibility-measure-sam-method",
    "href": "chap17.html#modelling-and-visualising-accessibility-using-spatial-accessibility-measure-sam-method",
    "title": "17  Modelling Geographical Accessibility",
    "section": "17.8 Modelling and Visualising Accessibility using Spatial Accessibility Measure (SAM) Method",
    "text": "17.8 Modelling and Visualising Accessibility using Spatial Accessibility Measure (SAM) Method\n\n17.8.1 Computing SAM accessibility\nIn this section, you are going to repeat most of the steps you had learned in previous section to perform the analysis. However, some of the codes will be combined into one code chunk.\nThe code chunk below calculates Hansen’s accessibility using ac() of SpatialAcc and data.frame() is used to save the output in a data frame called acc_SAM. Notice that SAM is used for family argument.\n\nacc_SAM &lt;- data.frame(ac(hexagons$demand,\n                         eldercare$capacity,\n                         distmat_km, \n                         d0 = 50,\n                         power = 2, \n                         family = \"SAM\"))\n\ncolnames(acc_SAM) &lt;- \"accSAM\"\nacc_SAM &lt;- tbl_df(acc_SAM)\nhexagon_SAM &lt;- bind_cols(hexagons, acc_SAM)\n\n\n\n17.8.2 Visualising SAM’s accessibility\nThe code chunk below uses a collection of mapping fucntions of tmap package to create a high cartographic quality accessibility to eldercare centre in Singapore. Notice that mapex is reused for bbox argument.\n\ntmap_mode(\"plot\")\ntm_shape(hexagon_SAM,\n         bbox = mapex) + \n  tm_fill(col = \"accSAM\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: SAM method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 3),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)\n\n\n\n\n\n\n17.8.3 Statistical graphic visualisation\nNow, we are going to compare the distribution of SAM accessibility values by URA Planning Region.\nFirstly, we need to add the planning region field into hexagon_SAM simple feature data frame by using the code chunk below.\n\nhexagon_SAM &lt;- st_join(hexagon_SAM, mpsz, \n                       join = st_intersects)\n\nNext, ggplot() will be used to plot the distribution by using boxplot graphical method.\n\nggplot(data=hexagon_SAM, \n       aes(y = accSAM, \n           x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "18  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "chap16.html#the-case-study-and-data",
    "href": "chap16.html#the-case-study-and-data",
    "title": "16  Calibrating Spatial Interaction Models with R",
    "section": "16.2 The Case Study and Data",
    "text": "16.2 The Case Study and Data\nIn this exercise, we are going to calibrate SIM to determine factors affecting the public bus passenger flows during the morning peak in Singapore."
  },
  {
    "objectID": "chap16.html#the-data",
    "href": "chap16.html#the-data",
    "title": "16  Calibrating Spatial Interaction Models with R",
    "section": "16.4 The Data",
    "text": "16.4 The Data\nThis exercise is a continuation of Chapter 15: Processing and Visualising Flow Data and the following data will be used:\n\nod_data.rds, weekday morning peak passenger flows at planning subzone level.\nmpsz.rds, URA Master Plan 2019 Planning Subzone boundary in simple feature tibble data frame format.\n\nBeside these two data sets, an additional attribute data file called pop.csv will be provided. It"
  }
]